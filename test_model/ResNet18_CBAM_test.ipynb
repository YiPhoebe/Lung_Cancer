{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "\n",
    "# 환경 설정\n",
    "SLICE_ROOT = \"/data1/lidc-idri/slices\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 레이블 추출\n",
    "def extract_label_from_filename(filename):\n",
    "    try:\n",
    "        score = int(filename.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        if score == 3: return None\n",
    "        return 1 if score >= 4 else 0\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# 파일 리스트 정리\n",
    "all_files = glob(os.path.join(SLICE_ROOT, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "files, labels = zip(*file_label_pairs)\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(files, labels, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch [1/100] Step [100/267], Loss: 0.7556, Accuracy: 67.69\n",
      "Epoch [1/100] Step [200/267], Loss: 0.4023, Accuracy: 68.75\n",
      "Epoch [1/100] Done, Loss: 0.5918, Accuracy: 69.64\n",
      "Test Loss: 0.6297, Test Accuracy: 68.51\n",
      "✅ Best model saved!\n",
      "Epoch [2/100] Step [100/267], Loss: 0.8439, Accuracy: 77.25\n",
      "Epoch [2/100] Step [200/267], Loss: 0.4959, Accuracy: 78.66\n",
      "Epoch [2/100] Done, Loss: 0.4488, Accuracy: 79.32\n",
      "Test Loss: 0.5813, Test Accuracy: 72.35\n",
      "✅ Best model saved!\n",
      "Epoch [3/100] Step [100/267], Loss: 0.2602, Accuracy: 88.94\n",
      "Epoch [3/100] Step [200/267], Loss: 0.7221, Accuracy: 88.72\n",
      "Epoch [3/100] Done, Loss: 0.2779, Accuracy: 88.93\n",
      "Test Loss: 0.4131, Test Accuracy: 81.63\n",
      "✅ Best model saved!\n",
      "Epoch [4/100] Step [100/267], Loss: 0.3009, Accuracy: 93.38\n",
      "Epoch [4/100] Step [200/267], Loss: 0.2111, Accuracy: 93.16\n",
      "Epoch [4/100] Done, Loss: 0.1757, Accuracy: 93.39\n",
      "Test Loss: 0.4415, Test Accuracy: 83.41\n",
      "✅ Best model saved!\n",
      "Epoch [5/100] Step [100/267], Loss: 0.0479, Accuracy: 95.75\n",
      "Epoch [5/100] Step [200/267], Loss: 0.3016, Accuracy: 95.44\n",
      "Epoch [5/100] Done, Loss: 0.1243, Accuracy: 95.59\n",
      "Test Loss: 0.3976, Test Accuracy: 85.85\n",
      "✅ Best model saved!\n",
      "Epoch [6/100] Step [100/267], Loss: 0.0099, Accuracy: 98.25\n",
      "Epoch [6/100] Step [200/267], Loss: 0.0090, Accuracy: 97.59\n",
      "Epoch [6/100] Done, Loss: 0.0849, Accuracy: 96.88\n",
      "Test Loss: 0.4817, Test Accuracy: 82.38\n",
      "✅ Best model saved!\n",
      "Epoch [7/100] Step [100/267], Loss: 0.2167, Accuracy: 97.62\n",
      "Epoch [7/100] Step [200/267], Loss: 0.0727, Accuracy: 97.50\n",
      "Epoch [7/100] Done, Loss: 0.0716, Accuracy: 97.51\n",
      "Test Loss: 0.7943, Test Accuracy: 81.44\n",
      "✅ Best model saved!\n",
      "Epoch [8/100] Step [100/267], Loss: 0.0325, Accuracy: 98.38\n",
      "Epoch [8/100] Step [200/267], Loss: 0.0048, Accuracy: 98.09\n",
      "Epoch [8/100] Done, Loss: 0.0614, Accuracy: 97.96\n",
      "Test Loss: 0.4555, Test Accuracy: 85.10\n",
      "✅ Best model saved!\n",
      "Epoch [9/100] Step [100/267], Loss: 0.0136, Accuracy: 97.94\n",
      "Epoch [9/100] Step [200/267], Loss: 0.1872, Accuracy: 97.84\n",
      "Epoch [9/100] Done, Loss: 0.0687, Accuracy: 97.51\n",
      "Test Loss: 0.5085, Test Accuracy: 86.88\n",
      "✅ Best model saved!\n",
      "Epoch [10/100] Step [100/267], Loss: 0.0013, Accuracy: 99.50\n",
      "Epoch [10/100] Step [200/267], Loss: 0.0698, Accuracy: 98.84\n",
      "Epoch [10/100] Done, Loss: 0.0437, Accuracy: 98.66\n",
      "Test Loss: 0.4742, Test Accuracy: 87.07\n",
      "✅ Best model saved!\n",
      "Epoch [11/100] Step [100/267], Loss: 0.0065, Accuracy: 98.44\n",
      "Epoch [11/100] Step [200/267], Loss: 0.0103, Accuracy: 98.38\n",
      "Epoch [11/100] Done, Loss: 0.0567, Accuracy: 98.15\n",
      "Test Loss: 0.5720, Test Accuracy: 81.82\n",
      "✅ Best model saved!\n",
      "Epoch [12/100] Step [100/267], Loss: 0.0039, Accuracy: 99.12\n",
      "Epoch [12/100] Step [200/267], Loss: 0.0171, Accuracy: 98.94\n",
      "Epoch [12/100] Done, Loss: 0.0332, Accuracy: 98.83\n",
      "Test Loss: 0.5742, Test Accuracy: 86.04\n",
      "✅ Best model saved!\n",
      "Epoch [13/100] Step [100/267], Loss: 0.0107, Accuracy: 99.00\n",
      "Epoch [13/100] Step [200/267], Loss: 0.0043, Accuracy: 99.00\n",
      "Epoch [13/100] Done, Loss: 0.0472, Accuracy: 98.73\n",
      "Test Loss: 0.5896, Test Accuracy: 88.10\n",
      "✅ Best model saved!\n",
      "Epoch [14/100] Step [100/267], Loss: 0.0102, Accuracy: 97.94\n",
      "Epoch [14/100] Step [200/267], Loss: 0.0183, Accuracy: 98.03\n",
      "Epoch [14/100] Done, Loss: 0.0559, Accuracy: 98.17\n",
      "Test Loss: 0.4764, Test Accuracy: 87.91\n",
      "✅ Best model saved!\n",
      "Epoch [15/100] Step [100/267], Loss: 0.0012, Accuracy: 99.06\n",
      "Epoch [15/100] Step [200/267], Loss: 0.0014, Accuracy: 99.28\n",
      "Epoch [15/100] Done, Loss: 0.0241, Accuracy: 99.30\n",
      "Test Loss: 0.4598, Test Accuracy: 88.10\n",
      "✅ Best model saved!\n",
      "Epoch [16/100] Step [100/267], Loss: 0.0015, Accuracy: 99.19\n",
      "Epoch [16/100] Step [200/267], Loss: 0.0325, Accuracy: 99.12\n",
      "Epoch [16/100] Done, Loss: 0.0270, Accuracy: 99.27\n",
      "Test Loss: 0.4643, Test Accuracy: 89.32\n",
      "✅ Best model saved!\n",
      "Epoch [17/100] Step [100/267], Loss: 0.0397, Accuracy: 99.69\n",
      "Epoch [17/100] Step [200/267], Loss: 0.0120, Accuracy: 99.59\n",
      "Epoch [17/100] Done, Loss: 0.0203, Accuracy: 99.41\n",
      "Test Loss: 0.5000, Test Accuracy: 88.19\n",
      "✅ Best model saved!\n",
      "Epoch [18/100] Step [100/267], Loss: 0.0010, Accuracy: 99.12\n",
      "Epoch [18/100] Step [200/267], Loss: 0.0268, Accuracy: 98.88\n",
      "Epoch [18/100] Done, Loss: 0.0376, Accuracy: 98.78\n",
      "Test Loss: 0.4584, Test Accuracy: 86.88\n",
      "✅ Best model saved!\n",
      "Epoch [19/100] Step [100/267], Loss: 0.0004, Accuracy: 99.56\n",
      "Epoch [19/100] Step [200/267], Loss: 0.0249, Accuracy: 98.91\n",
      "Epoch [19/100] Done, Loss: 0.0351, Accuracy: 98.92\n",
      "Test Loss: 0.4743, Test Accuracy: 87.16\n",
      "✅ Best model saved!\n",
      "Epoch [20/100] Step [100/267], Loss: 0.0054, Accuracy: 99.56\n",
      "Epoch [20/100] Step [200/267], Loss: 0.0024, Accuracy: 99.56\n",
      "Epoch [20/100] Done, Loss: 0.0284, Accuracy: 99.37\n",
      "Test Loss: 0.5739, Test Accuracy: 85.85\n",
      "✅ Best model saved!\n",
      "Epoch [21/100] Step [100/267], Loss: 0.0041, Accuracy: 98.75\n",
      "Epoch [21/100] Step [200/267], Loss: 0.0123, Accuracy: 99.03\n",
      "Epoch [21/100] Done, Loss: 0.0292, Accuracy: 99.11\n",
      "Test Loss: 0.4994, Test Accuracy: 87.35\n",
      "✅ Best model saved!\n",
      "Epoch [22/100] Step [100/267], Loss: 0.0021, Accuracy: 99.06\n",
      "Epoch [22/100] Step [200/267], Loss: 0.0211, Accuracy: 98.75\n",
      "Epoch [22/100] Done, Loss: 0.0369, Accuracy: 98.90\n",
      "Test Loss: 0.4966, Test Accuracy: 87.72\n",
      "✅ Best model saved!\n",
      "Epoch [23/100] Step [100/267], Loss: 0.0056, Accuracy: 99.44\n",
      "Epoch [23/100] Step [200/267], Loss: 0.0010, Accuracy: 99.44\n",
      "Epoch [23/100] Done, Loss: 0.0158, Accuracy: 99.46\n",
      "Test Loss: 0.4561, Test Accuracy: 87.44\n",
      "✅ Best model saved!\n",
      "Epoch [24/100] Step [100/267], Loss: 0.0019, Accuracy: 99.62\n",
      "Epoch [24/100] Step [200/267], Loss: 0.0002, Accuracy: 99.59\n",
      "Epoch [24/100] Done, Loss: 0.0149, Accuracy: 99.44\n",
      "Test Loss: 0.6937, Test Accuracy: 86.04\n",
      "✅ Best model saved!\n",
      "Epoch [25/100] Step [100/267], Loss: 0.0888, Accuracy: 99.50\n",
      "Epoch [25/100] Step [200/267], Loss: 0.0008, Accuracy: 99.31\n",
      "Epoch [25/100] Done, Loss: 0.0263, Accuracy: 99.32\n",
      "Test Loss: 0.6233, Test Accuracy: 86.50\n",
      "✅ Best model saved!\n",
      "Epoch [26/100] Step [100/267], Loss: 0.0049, Accuracy: 98.56\n",
      "Epoch [26/100] Step [200/267], Loss: 0.0519, Accuracy: 98.59\n",
      "Epoch [26/100] Done, Loss: 0.0483, Accuracy: 98.43\n",
      "Test Loss: 0.5734, Test Accuracy: 84.16\n",
      "✅ Best model saved!\n",
      "Epoch [27/100] Step [100/267], Loss: 0.0089, Accuracy: 99.06\n",
      "Epoch [27/100] Step [200/267], Loss: 0.0007, Accuracy: 99.09\n",
      "Epoch [27/100] Done, Loss: 0.0269, Accuracy: 99.11\n",
      "Test Loss: 0.5356, Test Accuracy: 89.41\n",
      "✅ Best model saved!\n",
      "Epoch [28/100] Step [100/267], Loss: 0.0410, Accuracy: 99.69\n",
      "Epoch [28/100] Step [200/267], Loss: 0.0002, Accuracy: 99.69\n",
      "Epoch [28/100] Done, Loss: 0.0114, Accuracy: 99.72\n",
      "Test Loss: 0.5545, Test Accuracy: 87.25\n",
      "✅ Best model saved!\n",
      "Epoch [29/100] Step [100/267], Loss: 0.0051, Accuracy: 99.88\n",
      "Epoch [29/100] Step [200/267], Loss: 0.0005, Accuracy: 99.88\n",
      "Epoch [29/100] Done, Loss: 0.0071, Accuracy: 99.84\n",
      "Test Loss: 0.5988, Test Accuracy: 88.38\n",
      "✅ Best model saved!\n",
      "Epoch [30/100] Step [100/267], Loss: 0.0002, Accuracy: 99.56\n",
      "Epoch [30/100] Step [200/267], Loss: 0.0043, Accuracy: 99.09\n",
      "Epoch [30/100] Done, Loss: 0.0294, Accuracy: 99.06\n",
      "Test Loss: 0.5841, Test Accuracy: 86.88\n",
      "✅ Best model saved!\n",
      "Epoch [31/100] Step [100/267], Loss: 0.0430, Accuracy: 98.75\n",
      "Epoch [31/100] Step [200/267], Loss: 0.0106, Accuracy: 98.94\n",
      "Epoch [31/100] Done, Loss: 0.0296, Accuracy: 99.13\n",
      "Test Loss: 0.5142, Test Accuracy: 88.00\n",
      "✅ Best model saved!\n",
      "Epoch [32/100] Step [100/267], Loss: 0.0400, Accuracy: 99.50\n",
      "Epoch [32/100] Step [200/267], Loss: 0.3105, Accuracy: 99.28\n",
      "Epoch [32/100] Done, Loss: 0.0168, Accuracy: 99.41\n",
      "Test Loss: 0.5200, Test Accuracy: 88.10\n",
      "✅ Best model saved!\n",
      "Epoch [33/100] Step [100/267], Loss: 0.0009, Accuracy: 99.62\n",
      "Epoch [33/100] Step [200/267], Loss: 0.0002, Accuracy: 99.66\n",
      "Epoch [33/100] Done, Loss: 0.0199, Accuracy: 99.46\n",
      "Test Loss: 0.5477, Test Accuracy: 88.19\n",
      "✅ Best model saved!\n",
      "Epoch [34/100] Step [100/267], Loss: 0.0074, Accuracy: 99.25\n",
      "Epoch [34/100] Step [200/267], Loss: 0.0027, Accuracy: 99.41\n",
      "Epoch [34/100] Done, Loss: 0.0225, Accuracy: 99.25\n",
      "Test Loss: 0.7024, Test Accuracy: 88.10\n",
      "✅ Best model saved!\n",
      "Epoch [35/100] Step [100/267], Loss: 0.0005, Accuracy: 98.56\n",
      "Epoch [35/100] Step [200/267], Loss: 0.0002, Accuracy: 99.09\n",
      "Epoch [35/100] Done, Loss: 0.0217, Accuracy: 99.23\n",
      "Test Loss: 0.5160, Test Accuracy: 87.91\n",
      "✅ Best model saved!\n",
      "Epoch [36/100] Step [100/267], Loss: 0.0804, Accuracy: 99.44\n",
      "Epoch [36/100] Step [200/267], Loss: 0.0007, Accuracy: 99.66\n",
      "Epoch [36/100] Done, Loss: 0.0121, Accuracy: 99.62\n",
      "Test Loss: 0.5266, Test Accuracy: 88.00\n",
      "✅ Best model saved!\n",
      "Epoch [37/100] Step [100/267], Loss: 0.0095, Accuracy: 99.75\n",
      "Epoch [37/100] Step [200/267], Loss: 0.0007, Accuracy: 99.62\n",
      "Epoch [37/100] Done, Loss: 0.0129, Accuracy: 99.51\n",
      "Test Loss: 0.5654, Test Accuracy: 87.91\n",
      "✅ Best model saved!\n",
      "Epoch [38/100] Step [100/267], Loss: 0.0032, Accuracy: 99.62\n",
      "Epoch [38/100] Step [200/267], Loss: 0.0540, Accuracy: 99.69\n",
      "Epoch [38/100] Done, Loss: 0.0131, Accuracy: 99.58\n",
      "Test Loss: 0.5808, Test Accuracy: 86.41\n",
      "✅ Best model saved!\n",
      "Epoch [39/100] Step [100/267], Loss: 0.0020, Accuracy: 99.75\n",
      "Epoch [39/100] Step [200/267], Loss: 0.3191, Accuracy: 99.53\n",
      "Epoch [39/100] Done, Loss: 0.0216, Accuracy: 99.39\n",
      "Test Loss: 0.4753, Test Accuracy: 85.47\n",
      "✅ Best model saved!\n",
      "Epoch [40/100] Step [100/267], Loss: 0.0008, Accuracy: 98.94\n",
      "Epoch [40/100] Step [200/267], Loss: 0.0022, Accuracy: 98.88\n",
      "Epoch [40/100] Done, Loss: 0.0350, Accuracy: 98.73\n",
      "Test Loss: 0.5777, Test Accuracy: 86.97\n",
      "✅ Best model saved!\n",
      "Epoch [41/100] Step [100/267], Loss: 0.0024, Accuracy: 99.81\n",
      "Epoch [41/100] Step [200/267], Loss: 0.0081, Accuracy: 99.69\n",
      "Epoch [41/100] Done, Loss: 0.0118, Accuracy: 99.65\n",
      "Test Loss: 0.5243, Test Accuracy: 87.35\n",
      "✅ Best model saved!\n",
      "Epoch [42/100] Step [100/267], Loss: 0.0000, Accuracy: 99.75\n",
      "Epoch [42/100] Step [200/267], Loss: 0.0001, Accuracy: 99.75\n",
      "Epoch [42/100] Done, Loss: 0.0067, Accuracy: 99.72\n",
      "Test Loss: 0.6452, Test Accuracy: 88.10\n",
      "✅ Best model saved!\n",
      "Epoch [43/100] Step [100/267], Loss: 0.0001, Accuracy: 99.69\n",
      "Epoch [43/100] Step [200/267], Loss: 0.0006, Accuracy: 99.56\n",
      "Epoch [43/100] Done, Loss: 0.0141, Accuracy: 99.46\n",
      "Test Loss: 0.7309, Test Accuracy: 85.94\n",
      "✅ Best model saved!\n",
      "Epoch [44/100] Step [100/267], Loss: 0.0574, Accuracy: 98.12\n",
      "Epoch [44/100] Step [200/267], Loss: 0.0005, Accuracy: 98.91\n",
      "Epoch [44/100] Done, Loss: 0.0282, Accuracy: 99.02\n",
      "Test Loss: 0.6028, Test Accuracy: 87.54\n",
      "✅ Best model saved!\n",
      "Epoch [45/100] Step [100/267], Loss: 0.0005, Accuracy: 99.81\n",
      "Epoch [45/100] Step [200/267], Loss: 0.0945, Accuracy: 99.75\n",
      "Epoch [45/100] Done, Loss: 0.0124, Accuracy: 99.72\n",
      "Test Loss: 0.6797, Test Accuracy: 86.41\n",
      "✅ Best model saved!\n",
      "Epoch [46/100] Step [100/267], Loss: 0.0002, Accuracy: 99.69\n",
      "Epoch [46/100] Step [200/267], Loss: 0.0004, Accuracy: 99.75\n",
      "Epoch [46/100] Done, Loss: 0.0061, Accuracy: 99.74\n",
      "Test Loss: 0.5574, Test Accuracy: 88.38\n",
      "✅ Best model saved!\n",
      "Epoch [47/100] Step [100/267], Loss: 0.0000, Accuracy: 99.81\n",
      "Epoch [47/100] Step [200/267], Loss: 0.0001, Accuracy: 99.81\n",
      "Epoch [47/100] Done, Loss: 0.0029, Accuracy: 99.84\n",
      "Test Loss: 0.5640, Test Accuracy: 88.28\n",
      "✅ Best model saved!\n",
      "Epoch [48/100] Step [100/267], Loss: 0.0001, Accuracy: 99.88\n",
      "Epoch [48/100] Step [200/267], Loss: 0.0001, Accuracy: 99.88\n",
      "Epoch [48/100] Done, Loss: 0.0023, Accuracy: 99.88\n",
      "Test Loss: 0.6420, Test Accuracy: 88.38\n",
      "✅ Best model saved!\n",
      "Epoch [49/100] Step [100/267], Loss: 0.0000, Accuracy: 99.88\n",
      "Epoch [49/100] Step [200/267], Loss: 0.0000, Accuracy: 99.84\n",
      "Epoch [49/100] Done, Loss: 0.0023, Accuracy: 99.79\n",
      "Test Loss: 0.5901, Test Accuracy: 88.28\n",
      "✅ Best model saved!\n",
      "Epoch [50/100] Step [100/267], Loss: 0.0000, Accuracy: 99.81\n",
      "Epoch [50/100] Step [200/267], Loss: 0.0000, Accuracy: 99.88\n",
      "Epoch [50/100] Done, Loss: 0.0021, Accuracy: 99.86\n",
      "Test Loss: 0.6456, Test Accuracy: 88.57\n",
      "✅ Best model saved!\n",
      "Epoch [51/100] Step [100/267], Loss: 0.0006, Accuracy: 99.94\n",
      "Epoch [51/100] Step [200/267], Loss: 0.0001, Accuracy: 99.84\n",
      "Epoch [51/100] Done, Loss: 0.0027, Accuracy: 99.84\n",
      "Test Loss: 0.5989, Test Accuracy: 88.19\n",
      "✅ Best model saved!\n",
      "Epoch [52/100] Step [100/267], Loss: 0.0121, Accuracy: 97.19\n",
      "Epoch [52/100] Step [200/267], Loss: 0.0685, Accuracy: 97.03\n",
      "Epoch [52/100] Done, Loss: 0.0706, Accuracy: 97.49\n",
      "Test Loss: 0.5752, Test Accuracy: 86.32\n",
      "✅ Best model saved!\n",
      "Epoch [53/100] Step [100/267], Loss: 0.0037, Accuracy: 99.06\n",
      "Epoch [53/100] Step [200/267], Loss: 0.0020, Accuracy: 99.41\n",
      "Epoch [53/100] Done, Loss: 0.0186, Accuracy: 99.27\n",
      "Test Loss: 0.5512, Test Accuracy: 84.72\n",
      "✅ Best model saved!\n",
      "Epoch [54/100] Step [100/267], Loss: 0.0011, Accuracy: 99.56\n",
      "Epoch [54/100] Step [200/267], Loss: 0.0016, Accuracy: 99.44\n",
      "Epoch [54/100] Done, Loss: 0.0199, Accuracy: 99.51\n",
      "Test Loss: 0.5545, Test Accuracy: 89.13\n",
      "✅ Best model saved!\n",
      "Epoch [55/100] Step [100/267], Loss: 0.0029, Accuracy: 99.88\n",
      "Epoch [55/100] Step [200/267], Loss: 0.0002, Accuracy: 99.78\n",
      "Epoch [55/100] Done, Loss: 0.0076, Accuracy: 99.81\n",
      "Test Loss: 0.5092, Test Accuracy: 88.85\n",
      "✅ Best model saved!\n",
      "Epoch [56/100] Step [100/267], Loss: 0.0007, Accuracy: 99.75\n",
      "Epoch [56/100] Step [200/267], Loss: 0.0002, Accuracy: 99.75\n",
      "Epoch [56/100] Done, Loss: 0.0036, Accuracy: 99.77\n",
      "Test Loss: 0.6571, Test Accuracy: 88.19\n",
      "✅ Best model saved!\n",
      "Epoch [57/100] Step [100/267], Loss: 0.0025, Accuracy: 99.75\n",
      "Epoch [57/100] Step [200/267], Loss: 0.0001, Accuracy: 99.75\n",
      "Epoch [57/100] Done, Loss: 0.0037, Accuracy: 99.77\n",
      "Test Loss: 0.6783, Test Accuracy: 86.97\n",
      "✅ Best model saved!\n",
      "Epoch [58/100] Step [100/267], Loss: 0.0002, Accuracy: 99.75\n",
      "Epoch [58/100] Step [200/267], Loss: 0.0422, Accuracy: 99.69\n",
      "Epoch [58/100] Done, Loss: 0.0101, Accuracy: 99.72\n",
      "Test Loss: 0.6019, Test Accuracy: 89.50\n",
      "✅ Best model saved!\n",
      "Epoch [59/100] Step [100/267], Loss: 0.0003, Accuracy: 99.75\n",
      "Epoch [59/100] Step [200/267], Loss: 0.0017, Accuracy: 99.53\n",
      "Epoch [59/100] Done, Loss: 0.0255, Accuracy: 99.27\n",
      "Test Loss: 0.6389, Test Accuracy: 86.04\n",
      "✅ Best model saved!\n",
      "Epoch [60/100] Step [100/267], Loss: 0.2956, Accuracy: 98.44\n",
      "Epoch [60/100] Step [200/267], Loss: 0.0040, Accuracy: 98.72\n",
      "Epoch [60/100] Done, Loss: 0.0370, Accuracy: 98.80\n",
      "Test Loss: 0.7547, Test Accuracy: 86.32\n",
      "✅ Best model saved!\n",
      "Epoch [61/100] Step [100/267], Loss: 0.0009, Accuracy: 99.56\n",
      "Epoch [61/100] Step [200/267], Loss: 0.0012, Accuracy: 99.56\n",
      "Epoch [61/100] Done, Loss: 0.0162, Accuracy: 99.55\n",
      "Test Loss: 0.6315, Test Accuracy: 88.85\n",
      "✅ Best model saved!\n",
      "Epoch [62/100] Step [100/267], Loss: 0.0004, Accuracy: 99.62\n",
      "Epoch [62/100] Step [200/267], Loss: 0.0004, Accuracy: 99.69\n",
      "Epoch [62/100] Done, Loss: 0.0049, Accuracy: 99.74\n",
      "Test Loss: 0.5350, Test Accuracy: 89.22\n",
      "✅ Best model saved!\n",
      "Epoch [63/100] Step [100/267], Loss: 0.0002, Accuracy: 99.88\n",
      "Epoch [63/100] Step [200/267], Loss: 0.0833, Accuracy: 99.62\n",
      "Epoch [63/100] Done, Loss: 0.0111, Accuracy: 99.65\n",
      "Test Loss: 0.5531, Test Accuracy: 87.63\n",
      "✅ Best model saved!\n",
      "Epoch [64/100] Step [100/267], Loss: 0.0003, Accuracy: 99.62\n",
      "Epoch [64/100] Step [200/267], Loss: 0.0002, Accuracy: 99.66\n",
      "Epoch [64/100] Done, Loss: 0.0094, Accuracy: 99.72\n",
      "Test Loss: 0.5462, Test Accuracy: 89.03\n",
      "✅ Best model saved!\n",
      "Epoch [65/100] Step [100/267], Loss: 0.0000, Accuracy: 99.81\n",
      "Epoch [65/100] Step [200/267], Loss: 0.0000, Accuracy: 99.75\n",
      "Epoch [65/100] Done, Loss: 0.0056, Accuracy: 99.77\n",
      "Test Loss: 0.5341, Test Accuracy: 89.22\n",
      "✅ Best model saved!\n",
      "Epoch [66/100] Step [100/267], Loss: 0.0001, Accuracy: 99.81\n",
      "Epoch [66/100] Step [200/267], Loss: 0.0011, Accuracy: 99.78\n",
      "Epoch [66/100] Done, Loss: 0.0058, Accuracy: 99.81\n",
      "Test Loss: 0.5596, Test Accuracy: 89.41\n",
      "✅ Best model saved!\n",
      "Epoch [67/100] Step [100/267], Loss: 0.0002, Accuracy: 99.88\n",
      "Epoch [67/100] Step [200/267], Loss: 0.0001, Accuracy: 99.78\n",
      "Epoch [67/100] Done, Loss: 0.0025, Accuracy: 99.81\n",
      "Test Loss: 0.6082, Test Accuracy: 90.35\n",
      "✅ Best model saved!\n",
      "Epoch [68/100] Step [100/267], Loss: 0.0521, Accuracy: 99.81\n",
      "Epoch [68/100] Step [200/267], Loss: 0.0006, Accuracy: 99.81\n",
      "Epoch [68/100] Done, Loss: 0.0026, Accuracy: 99.84\n",
      "Test Loss: 0.6302, Test Accuracy: 87.54\n",
      "✅ Best model saved!\n",
      "Epoch [69/100] Step [100/267], Loss: 0.0000, Accuracy: 99.88\n",
      "Epoch [69/100] Step [200/267], Loss: 0.0089, Accuracy: 99.41\n",
      "Epoch [69/100] Done, Loss: 0.0415, Accuracy: 98.31\n",
      "Test Loss: 0.5622, Test Accuracy: 84.82\n",
      "✅ Best model saved!\n",
      "Epoch [70/100] Step [100/267], Loss: 0.0498, Accuracy: 98.50\n",
      "Epoch [70/100] Step [200/267], Loss: 0.0020, Accuracy: 98.88\n",
      "Epoch [70/100] Done, Loss: 0.0282, Accuracy: 98.92\n",
      "Test Loss: 0.5706, Test Accuracy: 87.72\n",
      "✅ Best model saved!\n",
      "Epoch [71/100] Step [100/267], Loss: 0.0475, Accuracy: 99.50\n",
      "Epoch [71/100] Step [200/267], Loss: 0.0023, Accuracy: 99.56\n",
      "Epoch [71/100] Done, Loss: 0.0138, Accuracy: 99.58\n",
      "Test Loss: 0.5141, Test Accuracy: 86.97\n",
      "✅ Best model saved!\n",
      "Epoch [72/100] Step [100/267], Loss: 0.0003, Accuracy: 99.75\n",
      "Epoch [72/100] Step [200/267], Loss: 0.0002, Accuracy: 99.81\n",
      "Epoch [72/100] Done, Loss: 0.0050, Accuracy: 99.81\n",
      "Test Loss: 0.5381, Test Accuracy: 89.32\n",
      "✅ Best model saved!\n",
      "Epoch [73/100] Step [100/267], Loss: 0.0006, Accuracy: 99.88\n",
      "Epoch [73/100] Step [200/267], Loss: 0.0001, Accuracy: 99.84\n",
      "Epoch [73/100] Done, Loss: 0.0026, Accuracy: 99.86\n",
      "Test Loss: 0.5868, Test Accuracy: 89.50\n",
      "✅ Best model saved!\n",
      "Epoch [74/100] Step [100/267], Loss: 0.0813, Accuracy: 99.75\n",
      "Epoch [74/100] Step [200/267], Loss: 0.0001, Accuracy: 99.72\n",
      "Epoch [74/100] Done, Loss: 0.0026, Accuracy: 99.79\n",
      "Test Loss: 0.5724, Test Accuracy: 89.22\n",
      "✅ Best model saved!\n",
      "Epoch [75/100] Step [100/267], Loss: 0.0001, Accuracy: 99.88\n",
      "Epoch [75/100] Step [200/267], Loss: 0.0000, Accuracy: 99.84\n",
      "Epoch [75/100] Done, Loss: 0.0020, Accuracy: 99.84\n",
      "Test Loss: 0.5885, Test Accuracy: 89.78\n",
      "✅ Best model saved!\n",
      "Epoch [76/100] Step [100/267], Loss: 0.0000, Accuracy: 99.94\n",
      "Epoch [76/100] Step [200/267], Loss: 0.0001, Accuracy: 99.81\n",
      "Epoch [76/100] Done, Loss: 0.0021, Accuracy: 99.84\n",
      "Test Loss: 0.5744, Test Accuracy: 89.78\n",
      "✅ Best model saved!\n",
      "Epoch [77/100] Step [100/267], Loss: 0.0000, Accuracy: 99.94\n",
      "Epoch [77/100] Step [200/267], Loss: 0.0000, Accuracy: 99.88\n",
      "Epoch [77/100] Done, Loss: 0.0023, Accuracy: 99.86\n",
      "Test Loss: 0.5844, Test Accuracy: 89.60\n",
      "✅ Best model saved!\n",
      "Epoch [78/100] Step [100/267], Loss: 0.0001, Accuracy: 99.75\n",
      "Epoch [78/100] Step [200/267], Loss: 0.0000, Accuracy: 99.78\n",
      "Epoch [78/100] Done, Loss: 0.0023, Accuracy: 99.81\n",
      "Test Loss: 0.5850, Test Accuracy: 88.85\n",
      "✅ Best model saved!\n",
      "Epoch [79/100] Step [100/267], Loss: 0.0006, Accuracy: 99.81\n",
      "Epoch [79/100] Step [200/267], Loss: 0.1114, Accuracy: 99.84\n",
      "Epoch [79/100] Done, Loss: 0.0158, Accuracy: 99.34\n",
      "Test Loss: 0.8930, Test Accuracy: 85.29\n",
      "✅ Best model saved!\n",
      "Epoch [80/100] Step [100/267], Loss: 0.0103, Accuracy: 96.94\n",
      "Epoch [80/100] Step [200/267], Loss: 0.0059, Accuracy: 97.75\n",
      "Epoch [80/100] Done, Loss: 0.0518, Accuracy: 98.10\n",
      "Test Loss: 0.4997, Test Accuracy: 87.72\n",
      "✅ Best model saved!\n",
      "Epoch [81/100] Step [100/267], Loss: 0.0001, Accuracy: 99.69\n",
      "Epoch [81/100] Step [200/267], Loss: 0.0022, Accuracy: 99.75\n",
      "Epoch [81/100] Done, Loss: 0.0101, Accuracy: 99.67\n",
      "Test Loss: 0.5559, Test Accuracy: 88.66\n",
      "✅ Best model saved!\n",
      "Epoch [82/100] Step [100/267], Loss: 0.0020, Accuracy: 99.50\n",
      "Epoch [82/100] Step [200/267], Loss: 0.0732, Accuracy: 99.62\n",
      "Epoch [82/100] Done, Loss: 0.0142, Accuracy: 99.60\n",
      "Test Loss: 0.4889, Test Accuracy: 88.85\n",
      "✅ Best model saved!\n",
      "Epoch [83/100] Step [100/267], Loss: 0.0138, Accuracy: 99.88\n",
      "Epoch [83/100] Step [200/267], Loss: 0.0073, Accuracy: 99.84\n",
      "Epoch [83/100] Done, Loss: 0.0037, Accuracy: 99.81\n",
      "Test Loss: 0.4846, Test Accuracy: 89.03\n",
      "✅ Best model saved!\n",
      "Epoch [84/100] Step [100/267], Loss: 0.0000, Accuracy: 99.88\n",
      "Epoch [84/100] Step [200/267], Loss: 0.0001, Accuracy: 99.88\n",
      "Epoch [84/100] Done, Loss: 0.0025, Accuracy: 99.88\n",
      "Test Loss: 0.5212, Test Accuracy: 89.22\n",
      "✅ Best model saved!\n",
      "Epoch [85/100] Step [100/267], Loss: 0.0334, Accuracy: 99.88\n",
      "Epoch [85/100] Step [200/267], Loss: 0.0001, Accuracy: 99.84\n",
      "Epoch [85/100] Done, Loss: 0.0055, Accuracy: 99.84\n",
      "Test Loss: 0.5378, Test Accuracy: 88.75\n",
      "✅ Best model saved!\n",
      "Epoch [86/100] Step [100/267], Loss: 0.0014, Accuracy: 99.88\n",
      "Epoch [86/100] Step [200/267], Loss: 0.0000, Accuracy: 99.84\n",
      "Epoch [86/100] Done, Loss: 0.0020, Accuracy: 99.86\n",
      "Test Loss: 0.5319, Test Accuracy: 88.57\n",
      "✅ Best model saved!\n",
      "Epoch [87/100] Step [100/267], Loss: 0.0001, Accuracy: 99.88\n",
      "Epoch [87/100] Step [200/267], Loss: 0.0001, Accuracy: 99.91\n",
      "Epoch [87/100] Done, Loss: 0.0020, Accuracy: 99.86\n",
      "Test Loss: 0.5535, Test Accuracy: 88.94\n",
      "✅ Best model saved!\n",
      "Epoch [88/100] Step [100/267], Loss: 0.0002, Accuracy: 99.81\n",
      "Epoch [88/100] Step [200/267], Loss: 0.0000, Accuracy: 99.88\n",
      "Epoch [88/100] Done, Loss: 0.0025, Accuracy: 99.84\n",
      "Test Loss: 0.6183, Test Accuracy: 89.32\n",
      "✅ Best model saved!\n",
      "Epoch [89/100] Step [100/267], Loss: 0.0000, Accuracy: 99.75\n",
      "Epoch [89/100] Step [200/267], Loss: 0.0006, Accuracy: 99.78\n",
      "Epoch [89/100] Done, Loss: 0.0023, Accuracy: 99.84\n",
      "Test Loss: 0.5812, Test Accuracy: 89.22\n",
      "✅ Best model saved!\n",
      "Epoch [90/100] Step [100/267], Loss: 0.0000, Accuracy: 99.94\n",
      "Epoch [90/100] Step [200/267], Loss: 0.0001, Accuracy: 99.91\n",
      "Epoch [90/100] Done, Loss: 0.0020, Accuracy: 99.91\n",
      "Test Loss: 0.5659, Test Accuracy: 89.32\n",
      "✅ Best model saved!\n",
      "Epoch [91/100] Step [100/267], Loss: 0.0979, Accuracy: 99.75\n",
      "Epoch [91/100] Step [200/267], Loss: 0.0002, Accuracy: 99.78\n",
      "Epoch [91/100] Done, Loss: 0.0022, Accuracy: 99.81\n",
      "Test Loss: 0.5708, Test Accuracy: 89.22\n",
      "✅ Best model saved!\n",
      "Epoch [92/100] Step [100/267], Loss: 0.0000, Accuracy: 99.81\n",
      "Epoch [92/100] Step [200/267], Loss: 0.0000, Accuracy: 99.84\n",
      "Epoch [92/100] Done, Loss: 0.0023, Accuracy: 99.81\n",
      "Test Loss: 0.5862, Test Accuracy: 89.41\n",
      "✅ Best model saved!\n",
      "Epoch [93/100] Step [100/267], Loss: 0.0000, Accuracy: 99.75\n",
      "Epoch [93/100] Step [200/267], Loss: 0.0000, Accuracy: 99.81\n",
      "Epoch [93/100] Done, Loss: 0.0023, Accuracy: 99.81\n",
      "Test Loss: 0.5789, Test Accuracy: 89.50\n",
      "✅ Best model saved!\n",
      "Epoch [94/100] Step [100/267], Loss: 0.0001, Accuracy: 99.81\n",
      "Epoch [94/100] Step [200/267], Loss: 0.0001, Accuracy: 99.84\n",
      "Epoch [94/100] Done, Loss: 0.0022, Accuracy: 99.81\n",
      "Test Loss: 0.5838, Test Accuracy: 89.03\n",
      "✅ Best model saved!\n",
      "Epoch [95/100] Step [100/267], Loss: 0.0001, Accuracy: 99.75\n",
      "Epoch [95/100] Step [200/267], Loss: 0.0000, Accuracy: 99.81\n",
      "Epoch [95/100] Done, Loss: 0.0021, Accuracy: 99.84\n",
      "Test Loss: 0.6094, Test Accuracy: 89.13\n",
      "✅ Best model saved!\n",
      "Epoch [96/100] Step [100/267], Loss: 0.0001, Accuracy: 99.62\n",
      "Epoch [96/100] Step [200/267], Loss: 0.0000, Accuracy: 99.78\n",
      "Epoch [96/100] Done, Loss: 0.0441, Accuracy: 98.66\n",
      "Test Loss: 0.7902, Test Accuracy: 80.51\n",
      "✅ Best model saved!\n",
      "Epoch [97/100] Step [100/267], Loss: 0.0037, Accuracy: 97.88\n",
      "Epoch [97/100] Step [200/267], Loss: 0.0333, Accuracy: 98.31\n",
      "Epoch [97/100] Done, Loss: 0.0478, Accuracy: 98.31\n",
      "Test Loss: 0.5070, Test Accuracy: 85.66\n",
      "✅ Best model saved!\n",
      "Epoch [98/100] Step [100/267], Loss: 0.2980, Accuracy: 99.56\n",
      "Epoch [98/100] Step [200/267], Loss: 0.0023, Accuracy: 99.59\n",
      "Epoch [98/100] Done, Loss: 0.0131, Accuracy: 99.62\n",
      "Test Loss: 0.5994, Test Accuracy: 87.54\n",
      "✅ Best model saved!\n",
      "Epoch [99/100] Step [100/267], Loss: 0.0004, Accuracy: 99.75\n",
      "Epoch [99/100] Step [200/267], Loss: 0.0003, Accuracy: 99.75\n",
      "Epoch [99/100] Done, Loss: 0.0097, Accuracy: 99.58\n",
      "Test Loss: 0.5973, Test Accuracy: 87.25\n",
      "✅ Best model saved!\n",
      "Epoch [100/100] Step [100/267], Loss: 0.0020, Accuracy: 99.38\n",
      "Epoch [100/100] Step [200/267], Loss: 0.0150, Accuracy: 99.44\n",
      "Epoch [100/100] Done, Loss: 0.0217, Accuracy: 99.41\n",
      "Test Loss: 0.5568, Test Accuracy: 88.28\n",
      "✅ Best model saved!\n",
      "\n",
      "📊 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9068    0.7188    0.8019       352\n",
      "           1     0.8744    0.9636    0.9168       715\n",
      "\n",
      "    accuracy                         0.8828      1067\n",
      "   macro avg     0.8906    0.8412    0.8594      1067\n",
      "weighted avg     0.8851    0.8828    0.8789      1067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 환경 설정\n",
    "SLICE_ROOT = \"/data1/lidc-idri/slices\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 100\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "# 레이블 추출\n",
    "def extract_label_from_filename(filename):\n",
    "    try:\n",
    "        score = int(filename.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        if score == 3: return None\n",
    "        return 1 if score >= 4 else 0\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# 파일 리스트 정리\n",
    "all_files = glob(os.path.join(SLICE_ROOT, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "files, labels = zip(*file_label_pairs)\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(files, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 데이터셋 클래스\n",
    "class CTBinaryClassificationDataset(Dataset):\n",
    "    def __init__(self, file_list, label_list):\n",
    "        self.files = file_list\n",
    "        self.labels = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = np.load(self.files[idx])\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.0\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = np.expand_dims(img, axis=0).astype(np.float32)\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(img), torch.tensor(label).long()\n",
    "\n",
    "# CBAM 모듈\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.shared_mlp = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.shared_mlp(self.avg_pool(x))\n",
    "        max_out = self.shared_mlp(self.max_pool(x))\n",
    "        return self.sigmoid(avg_out + max_out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x_cat = torch.cat([avg_out, max_out], dim=1)\n",
    "        return self.sigmoid(self.conv(x_cat))\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ca(x) * x\n",
    "        x = self.sa(x) * x\n",
    "        return x\n",
    "\n",
    "# BasicBlock with CBAM\n",
    "class BasicBlockWithCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.cbam = CBAM(planes)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.cbam(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet18 with CBAM\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(64, 2)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "        layers = [BasicBlockWithCBAM(self.in_planes, planes, stride, downsample)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockWithCBAM(self.in_planes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# 학습 루프\n",
    "train_dataset = CTBinaryClassificationDataset(train_files, train_labels)\n",
    "test_dataset = CTBinaryClassificationDataset(test_files, test_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 모델 설정\n",
    "model = ResNet18_CBAM(num_classes=2).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 반복문\n",
    "train_loss_list = []    # train loss를 저장할 list\n",
    "test_loss_list = []     # test loss를 저장할 list\n",
    "\n",
    "train_acc_list = []     # train 정확도 저장할 list\n",
    "test_acc_list = []      # test 정확도 저장할 list\n",
    "\n",
    "total_step = len(train_loader)  # batch_size = 16, train total 샘플 수\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] Step [{i+1}/{total_step}], Loss: {loss.item():.4f}, Accuracy: {(correct/total)*100:.2f}')\n",
    "\n",
    "    train_loss = epoch_loss / total_step\n",
    "    train_acc = (correct / total) * 100\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] Done, Loss: {epoch_loss/total_step:.4f}, Accuracy: {(correct/total)*100:.2f}')\n",
    "\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0  # ✅ 새로 초기화해야 함\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item() * images.size(0)  # ✨ 배치 전체의 loss 합산\n",
    "            total += labels.size(0)\n",
    "\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        test_loss_avg = test_loss / total  # ✨ 전체 sample 수로 나눔\n",
    "        test_acc = correct / total * 100\n",
    "\n",
    "        print(f'Test Loss: {test_loss_avg:.4f}, Test Accuracy: {test_acc:.2f}')\n",
    "\n",
    "        test_loss_list.append(test_loss_avg)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "    save_dir = os.path.join(os.path.dirname(os.getcwd()), \"pth\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        save_path = os.path.join(save_dir, \"best_model_resnet18_CBAM.pth\")\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"✅ Best model saved!\")\n",
    "\n",
    "# --- 리포트 출력 ---\n",
    "print(\"\\n📊 Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
