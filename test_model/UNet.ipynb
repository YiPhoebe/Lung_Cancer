{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ PID: 4098834\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"í˜„ì¬ PID: {os.getpid()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   4%|â–         | 63/1570 [00:07<02:57,  8.48it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 172\u001b[39m\n\u001b[32m    169\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ“ˆ Mean IoU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.mean(ious)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 134\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m imgs, masks \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m    133\u001b[39m     imgs, masks = imgs.to(device), masks.to(device)\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m     loss = criterion(outputs, masks)\n\u001b[32m    136\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/lungcancer/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/lungcancer/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mUNet.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     d1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdown1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m     d2 = \u001b[38;5;28mself\u001b[39m.down2(F.max_pool2d(d1, \u001b[32m2\u001b[39m))\n\u001b[32m     64\u001b[39m     d3 = \u001b[38;5;28mself\u001b[39m.down3(F.max_pool2d(d2, \u001b[32m2\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/lungcancer/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/lungcancer/lib/python3.12/site-packages/torch/nn/modules/module.py:1756\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m-> \u001b[39m\u001b[32m1756\u001b[39m     forward_call = (\u001b[38;5;28mself\u001b[39m._slow_forward \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_tracing_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.forward)\n\u001b[32m   1757\u001b[39m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m             \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m             \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mí˜„ì¬ ì…€ ë˜ëŠ” ì´ì „ ì…€ì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë™ì•ˆ Kernelì´ ì¶©ëŒí–ˆìŠµë‹ˆë‹¤. \n",
      "\u001b[1;31mì…€ì˜ ì½”ë“œë¥¼ ê²€í† í•˜ì—¬ ê°€ëŠ¥í•œ ì˜¤ë¥˜ ì›ì¸ì„ ì‹ë³„í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì„ ë³´ë ¤ë©´ <a href='https://aka.ms/vscodeJupyterKernelCrash'>ì—¬ê¸°</a>ë¥¼ í´ë¦­í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì€ Jupyter <a href='command:jupyter.viewOutput'>ë¡œê·¸</a>ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
     ]
    }
   ],
   "source": [
    "# âœ… ê²½ëŸ‰ UNet + MGA ë²„ì „ (ë³‘ë³€ ë§ˆìŠ¤í¬ í¬í•¨)\n",
    "import os, numpy as np, torch, gc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import re\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "batch_size = 4\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# ì±„ë„ ìˆ˜ ì¤„ì¸ UNet\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super().__init__()\n",
    "        filters = [32, 64, 128, 256, 512]\n",
    "\n",
    "        self.down1 = DoubleConv(in_channels, filters[0])\n",
    "        self.down2 = DoubleConv(filters[0], filters[1])\n",
    "        self.down3 = DoubleConv(filters[1], filters[2])\n",
    "        self.down4 = DoubleConv(filters[2], filters[3])\n",
    "        self.bottom = DoubleConv(filters[3], filters[4])\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(filters[4], filters[3], 2, stride=2)\n",
    "        self.conv4 = DoubleConv(filters[4], filters[3])\n",
    "        self.up3 = nn.ConvTranspose2d(filters[3], filters[2], 2, stride=2)\n",
    "        self.conv3 = DoubleConv(filters[3], filters[2])\n",
    "        self.up2 = nn.ConvTranspose2d(filters[2], filters[1], 2, stride=2)\n",
    "        self.conv2 = DoubleConv(filters[2], filters[1])\n",
    "        self.up1 = nn.ConvTranspose2d(filters[1], filters[0], 2, stride=2)\n",
    "        self.conv1 = DoubleConv(filters[1], filters[0])\n",
    "\n",
    "        self.final = nn.Conv2d(filters[0], out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(F.max_pool2d(d1, 2))\n",
    "        d3 = self.down3(F.max_pool2d(d2, 2))\n",
    "        d4 = self.down4(F.max_pool2d(d3, 2))\n",
    "        b = self.bottom(F.max_pool2d(d4, 2))\n",
    "\n",
    "        u4 = self.conv4(torch.cat([self.up4(b), d4], 1))\n",
    "        u3 = self.conv3(torch.cat([self.up3(u4), d3], 1))\n",
    "        u2 = self.conv2(torch.cat([self.up2(u3), d2], 1))\n",
    "        u1 = self.conv1(torch.cat([self.up1(u2), d1], 1))\n",
    "\n",
    "        return torch.sigmoid(self.final(u1))\n",
    "\n",
    "# ë§ˆìŠ¤í¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "def load_bbox_csv(path):\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(path)\n",
    "    bbox_dict = {}\n",
    "    for _, row in df.iterrows():\n",
    "        pid = row['pid']\n",
    "        slice_num = int(re.findall(r'\\d+', str(row['slice']))[0])\n",
    "        fname = f\"{pid}_slice{slice_num:03d}.npy\"\n",
    "        bbox = eval(row['bb'])\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)\n",
    "    return bbox_dict\n",
    "\n",
    "# Dataset\n",
    "class CTMaskDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_dict, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_dict = mask_dict\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        img = np.load(path)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.\n",
    "        img = cv2.resize(img, (224, 224)).astype(np.float32)\n",
    "\n",
    "        fname = os.path.basename(path)\n",
    "        mask = np.zeros((224, 224), dtype=np.float32)\n",
    "        if fname in self.mask_dict:\n",
    "            for x1, y1, x2, y2 in self.mask_dict[fname]:\n",
    "                mask[y1:y2, x1:x2] = 1.0\n",
    "\n",
    "        img, mask = torch.tensor(img).unsqueeze(0), torch.tensor(mask).unsqueeze(0)\n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self): return len(self.image_paths)\n",
    "\n",
    "# í•™ìŠµ ë£¨í”„\n",
    "def train():\n",
    "    image_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "    train_imgs, val_imgs = train_test_split(image_files, test_size=0.2, random_state=42)\n",
    "\n",
    "    mask_dict = load_bbox_csv(bbox_csv_path)\n",
    "    train_set = CTMaskDataset(train_imgs, mask_dict)\n",
    "    val_set = CTMaskDataset(val_imgs, mask_dict)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "\n",
    "    model = UNet().to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        loss_total = 0\n",
    "        for imgs, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_total += loss.item()\n",
    "\n",
    "        avg_train_loss = loss_total / len(train_loader)\n",
    "        print(f\"\\nğŸ“š Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}\")\n",
    "\n",
    "        # -------------------- Validation --------------------\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        total_pixels = 0\n",
    "        correct_pixels = 0\n",
    "        ious = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in tqdm(val_loader, desc=\"Validation\"):\n",
    "                imgs, masks = imgs.to(device), masks.to(device)\n",
    "                outputs = model(imgs)\n",
    "                preds = (outputs > 0.5).float()\n",
    "\n",
    "                # IoU ê³„ì‚°\n",
    "                intersection = (preds * masks).sum(dim=(1,2,3))\n",
    "                union = (preds + masks).clamp(0,1).sum(dim=(1,2,3)) - intersection\n",
    "                iou = (intersection / (union + 1e-6)).mean().item()\n",
    "                ious.append(iou)\n",
    "\n",
    "                loss = criterion(outputs, masks)\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                correct_pixels += (preds == masks).sum().item()\n",
    "                total_pixels += torch.numel(masks)\n",
    "\n",
    "        val_loss = total_loss / len(val_loader)\n",
    "        val_acc = correct_pixels / total_pixels\n",
    "\n",
    "        print(f\"ğŸ“Š Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
    "        print(f\"ğŸ“ˆ Mean IoU: {np.mean(ious):.4f}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
