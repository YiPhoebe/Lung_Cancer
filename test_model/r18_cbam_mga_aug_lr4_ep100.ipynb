{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 PID: 3616504\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"현재 PID: {os.getpid()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: 100%|██████████| 234/234 [00:09<00:00, 25.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 58.3869, Loss: 0.6954\n",
      "[Epoch 1] lambda_mga: 0.1000\n",
      "Val Acc: 0.3912\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|██████████| 234/234 [00:09<00:00, 25.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 62.0311, Loss: 0.6558\n",
      "[Epoch 2] lambda_mga: 0.1040\n",
      "Val Acc: 0.5650\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|██████████| 234/234 [00:09<00:00, 24.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 64.2283, Loss: 0.6419\n",
      "[Epoch 3] lambda_mga: 0.1080\n",
      "Val Acc: 0.6525\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: 100%|██████████| 234/234 [00:09<00:00, 25.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 67.9528, Loss: 0.6124\n",
      "[Epoch 4] lambda_mga: 0.1120\n",
      "Val Acc: 0.7013\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: 100%|██████████| 234/234 [00:09<00:00, 25.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 68.8639, Loss: 0.5925\n",
      "[Epoch 5] lambda_mga: 0.1160\n",
      "Val Acc: 0.6388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6]: 100%|██████████| 234/234 [00:09<00:00, 25.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 71.6238, Loss: 0.5737\n",
      "[Epoch 6] lambda_mga: 0.1200\n",
      "Val Acc: 0.6388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7]: 100%|██████████| 234/234 [00:07<00:00, 30.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 73.5798, Loss: 0.5419\n",
      "[Epoch 7] lambda_mga: 0.1240\n",
      "Val Acc: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8]: 100%|██████████| 234/234 [00:06<00:00, 33.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 76.1790, Loss: 0.5144\n",
      "[Epoch 8] lambda_mga: 0.1280\n",
      "Val Acc: 0.7412\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9]: 100%|██████████| 234/234 [00:07<00:00, 30.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 76.9293, Loss: 0.4961\n",
      "[Epoch 9] lambda_mga: 0.1320\n",
      "Val Acc: 0.7550\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10]: 100%|██████████| 234/234 [00:09<00:00, 25.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 77.8135, Loss: 0.4746\n",
      "[Epoch 10] lambda_mga: 0.1360\n",
      "Val Acc: 0.7175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 11]: 100%|██████████| 234/234 [00:09<00:00, 24.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 79.2069, Loss: 0.4550\n",
      "[Epoch 11] lambda_mga: 0.1400\n",
      "Val Acc: 0.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 12]: 100%|██████████| 234/234 [00:09<00:00, 24.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 81.8060, Loss: 0.4130\n",
      "[Epoch 12] lambda_mga: 0.1440\n",
      "Val Acc: 0.7638\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 13]: 100%|██████████| 234/234 [00:09<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 82.6902, Loss: 0.3959\n",
      "[Epoch 13] lambda_mga: 0.1480\n",
      "Val Acc: 0.8013\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 14]: 100%|██████████| 234/234 [00:09<00:00, 24.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 83.2529, Loss: 0.3808\n",
      "[Epoch 14] lambda_mga: 0.1520\n",
      "Val Acc: 0.8137\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 15]: 100%|██████████| 234/234 [00:09<00:00, 25.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 84.9678, Loss: 0.3510\n",
      "[Epoch 15] lambda_mga: 0.1560\n",
      "Val Acc: 0.7950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 16]: 100%|██████████| 234/234 [00:09<00:00, 25.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 85.5305, Loss: 0.3357\n",
      "[Epoch 16] lambda_mga: 0.1600\n",
      "Val Acc: 0.8013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17]: 100%|██████████| 234/234 [00:09<00:00, 25.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 86.6292, Loss: 0.3142\n",
      "[Epoch 17] lambda_mga: 0.1640\n",
      "Val Acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 18]: 100%|██████████| 234/234 [00:09<00:00, 25.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 87.4598, Loss: 0.2962\n",
      "[Epoch 18] lambda_mga: 0.1680\n",
      "Val Acc: 0.8063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 19]: 100%|██████████| 234/234 [00:09<00:00, 25.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 88.7192, Loss: 0.2792\n",
      "[Epoch 19] lambda_mga: 0.1720\n",
      "Val Acc: 0.8263\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 20]: 100%|██████████| 234/234 [00:09<00:00, 24.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 88.6656, Loss: 0.2749\n",
      "[Epoch 20] lambda_mga: 0.1760\n",
      "Val Acc: 0.8425\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 21]: 100%|██████████| 234/234 [00:09<00:00, 24.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 89.7910, Loss: 0.2509\n",
      "[Epoch 21] lambda_mga: 0.1800\n",
      "Val Acc: 0.8337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 22]: 100%|██████████| 234/234 [00:09<00:00, 24.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 90.3805, Loss: 0.2461\n",
      "[Epoch 22] lambda_mga: 0.1840\n",
      "Val Acc: 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 23]: 100%|██████████| 234/234 [00:09<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.1308, Loss: 0.2302\n",
      "[Epoch 23] lambda_mga: 0.1880\n",
      "Val Acc: 0.7937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 24]: 100%|██████████| 234/234 [00:07<00:00, 29.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 90.8896, Loss: 0.2315\n",
      "[Epoch 24] lambda_mga: 0.1920\n",
      "Val Acc: 0.7825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 25]: 100%|██████████| 234/234 [00:06<00:00, 33.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 90.4341, Loss: 0.2386\n",
      "[Epoch 25] lambda_mga: 0.1960\n",
      "Val Acc: 0.8475\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 26]: 100%|██████████| 234/234 [00:07<00:00, 32.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.8542, Loss: 0.2229\n",
      "[Epoch 26] lambda_mga: 0.2000\n",
      "Val Acc: 0.8512\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 27]: 100%|██████████| 234/234 [00:09<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.2208, Loss: 0.1916\n",
      "[Epoch 27] lambda_mga: 0.2040\n",
      "Val Acc: 0.8625\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 28]: 100%|██████████| 234/234 [00:09<00:00, 25.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.4169, Loss: 0.1876\n",
      "[Epoch 28] lambda_mga: 0.2080\n",
      "Val Acc: 0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 29]: 100%|██████████| 234/234 [00:09<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.4705, Loss: 0.1978\n",
      "[Epoch 29] lambda_mga: 0.2120\n",
      "Val Acc: 0.8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 30]: 100%|██████████| 234/234 [00:09<00:00, 24.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.3012, Loss: 0.1728\n",
      "[Epoch 30] lambda_mga: 0.2160\n",
      "Val Acc: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 31]: 100%|██████████| 234/234 [00:09<00:00, 24.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.0600, Loss: 0.1844\n",
      "[Epoch 31] lambda_mga: 0.2200\n",
      "Val Acc: 0.8562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 32]: 100%|██████████| 234/234 [00:09<00:00, 24.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.2294, Loss: 0.2010\n",
      "[Epoch 32] lambda_mga: 0.2240\n",
      "Val Acc: 0.8812\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 33]: 100%|██████████| 234/234 [00:09<00:00, 24.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.2122, Loss: 0.1662\n",
      "[Epoch 33] lambda_mga: 0.2280\n",
      "Val Acc: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 34]: 100%|██████████| 234/234 [00:09<00:00, 25.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.9443, Loss: 0.1744\n",
      "[Epoch 34] lambda_mga: 0.2320\n",
      "Val Acc: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 35]: 100%|██████████| 234/234 [00:09<00:00, 25.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.2390, Loss: 0.1551\n",
      "[Epoch 35] lambda_mga: 0.2360\n",
      "Val Acc: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 36]: 100%|██████████| 234/234 [00:09<00:00, 25.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.9089, Loss: 0.1387\n",
      "[Epoch 36] lambda_mga: 0.2400\n",
      "Val Acc: 0.8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 37]: 100%|██████████| 234/234 [00:09<00:00, 25.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.7835, Loss: 0.1558\n",
      "[Epoch 37] lambda_mga: 0.2440\n",
      "Val Acc: 0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 38]: 100%|██████████| 234/234 [00:09<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.2840, Loss: 0.1351\n",
      "[Epoch 38] lambda_mga: 0.2480\n",
      "Val Acc: 0.8662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 39]: 100%|██████████| 234/234 [00:09<00:00, 25.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.5606, Loss: 0.1511\n",
      "[Epoch 39] lambda_mga: 0.2520\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 40]: 100%|██████████| 234/234 [00:09<00:00, 25.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.6677, Loss: 0.1453\n",
      "[Epoch 40] lambda_mga: 0.2560\n",
      "Val Acc: 0.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 41]: 100%|██████████| 234/234 [00:07<00:00, 32.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.5606, Loss: 0.1404\n",
      "[Epoch 41] lambda_mga: 0.2600\n",
      "Val Acc: 0.8850\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 42]: 100%|██████████| 234/234 [00:07<00:00, 32.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.2036, Loss: 0.1339\n",
      "[Epoch 42] lambda_mga: 0.2640\n",
      "Val Acc: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 43]: 100%|██████████| 234/234 [00:07<00:00, 30.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.6592, Loss: 0.1209\n",
      "[Epoch 43] lambda_mga: 0.2680\n",
      "Val Acc: 0.8662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 44]: 100%|██████████| 234/234 [00:09<00:00, 24.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.0429, Loss: 0.1256\n",
      "[Epoch 44] lambda_mga: 0.2720\n",
      "Val Acc: 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 45]: 100%|██████████| 234/234 [00:09<00:00, 24.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.1233, Loss: 0.1314\n",
      "[Epoch 45] lambda_mga: 0.2760\n",
      "Val Acc: 0.8875\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 46]: 100%|██████████| 234/234 [00:09<00:00, 25.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.8285, Loss: 0.1388\n",
      "[Epoch 46] lambda_mga: 0.2800\n",
      "Val Acc: 0.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 47]: 100%|██████████| 234/234 [00:09<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.1501, Loss: 0.1280\n",
      "[Epoch 47] lambda_mga: 0.2840\n",
      "Val Acc: 0.8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 48]: 100%|██████████| 234/234 [00:09<00:00, 25.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.6592, Loss: 0.1318\n",
      "[Epoch 48] lambda_mga: 0.2880\n",
      "Val Acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 49]: 100%|██████████| 234/234 [00:09<00:00, 24.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.1683, Loss: 0.1125\n",
      "[Epoch 49] lambda_mga: 0.2920\n",
      "Val Acc: 0.8925\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 50]: 100%|██████████| 234/234 [00:09<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3023, Loss: 0.1049\n",
      "[Epoch 50] lambda_mga: 0.2960\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 51]: 100%|██████████| 234/234 [00:09<00:00, 25.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.2572, Loss: 0.1252\n",
      "[Epoch 51] lambda_mga: 0.3000\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 52]: 100%|██████████| 234/234 [00:09<00:00, 25.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3826, Loss: 0.0981\n",
      "[Epoch 52] lambda_mga: 0.3040\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 53]: 100%|██████████| 234/234 [00:09<00:00, 25.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.1415, Loss: 0.1122\n",
      "[Epoch 53] lambda_mga: 0.3080\n",
      "Val Acc: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 54]: 100%|██████████| 234/234 [00:09<00:00, 24.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3023, Loss: 0.1055\n",
      "[Epoch 54] lambda_mga: 0.3120\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 55]: 100%|██████████| 234/234 [00:09<00:00, 25.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.4094, Loss: 0.0986\n",
      "[Epoch 55] lambda_mga: 0.3160\n",
      "Val Acc: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 56]: 100%|██████████| 234/234 [00:09<00:00, 24.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3023, Loss: 0.1061\n",
      "[Epoch 56] lambda_mga: 0.3200\n",
      "Val Acc: 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 57]: 100%|██████████| 234/234 [00:09<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.8467, Loss: 0.1076\n",
      "[Epoch 57] lambda_mga: 0.3240\n",
      "Val Acc: 0.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 58]: 100%|██████████| 234/234 [00:06<00:00, 34.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7310, Loss: 0.0977\n",
      "[Epoch 58] lambda_mga: 0.3280\n",
      "Val Acc: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 59]: 100%|██████████| 234/234 [00:07<00:00, 32.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3558, Loss: 0.1008\n",
      "[Epoch 59] lambda_mga: 0.3320\n",
      "Val Acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 60]: 100%|██████████| 234/234 [00:08<00:00, 28.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0879, Loss: 0.1061\n",
      "[Epoch 60] lambda_mga: 0.3360\n",
      "Val Acc: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 61]: 100%|██████████| 234/234 [00:09<00:00, 25.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9721, Loss: 0.0914\n",
      "[Epoch 61] lambda_mga: 0.3400\n",
      "Val Acc: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 62]: 100%|██████████| 234/234 [00:09<00:00, 25.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.4898, Loss: 0.0919\n",
      "[Epoch 62] lambda_mga: 0.3440\n",
      "Val Acc: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 63]: 100%|██████████| 234/234 [00:09<00:00, 24.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.4094, Loss: 0.0960\n",
      "[Epoch 63] lambda_mga: 0.3480\n",
      "Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 64]: 100%|██████████| 234/234 [00:09<00:00, 24.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7310, Loss: 0.0928\n",
      "[Epoch 64] lambda_mga: 0.3520\n",
      "Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 65]: 100%|██████████| 234/234 [00:09<00:00, 25.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.0793, Loss: 0.0876\n",
      "[Epoch 65] lambda_mga: 0.3560\n",
      "Val Acc: 0.8975\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 66]: 100%|██████████| 234/234 [00:09<00:00, 24.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.0793, Loss: 0.0854\n",
      "[Epoch 66] lambda_mga: 0.3600\n",
      "Val Acc: 0.9000\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 67]: 100%|██████████| 234/234 [00:09<00:00, 25.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9453, Loss: 0.0819\n",
      "[Epoch 67] lambda_mga: 0.3640\n",
      "Val Acc: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 68]: 100%|██████████| 234/234 [00:09<00:00, 25.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9185, Loss: 0.0871\n",
      "[Epoch 68] lambda_mga: 0.3680\n",
      "Val Acc: 0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 69]: 100%|██████████| 234/234 [00:09<00:00, 24.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.2401, Loss: 0.0830\n",
      "[Epoch 69] lambda_mga: 0.3720\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 70]: 100%|██████████| 234/234 [00:09<00:00, 25.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4812, Loss: 0.0733\n",
      "[Epoch 70] lambda_mga: 0.3760\n",
      "Val Acc: 0.9038\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 71]: 100%|██████████| 234/234 [00:09<00:00, 25.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7310, Loss: 0.0990\n",
      "[Epoch 71] lambda_mga: 0.3800\n",
      "Val Acc: 0.8413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 72]: 100%|██████████| 234/234 [00:09<00:00, 25.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.2401, Loss: 0.0802\n",
      "[Epoch 72] lambda_mga: 0.3840\n",
      "Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 73]: 100%|██████████| 234/234 [00:09<00:00, 24.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3558, Loss: 0.0955\n",
      "[Epoch 73] lambda_mga: 0.3880\n",
      "Val Acc: 0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 74]: 100%|██████████| 234/234 [00:09<00:00, 25.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9453, Loss: 0.0863\n",
      "[Epoch 74] lambda_mga: 0.3920\n",
      "Val Acc: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 75]: 100%|██████████| 234/234 [00:07<00:00, 33.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.0793, Loss: 0.0848\n",
      "[Epoch 75] lambda_mga: 0.3960\n",
      "Val Acc: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 76]: 100%|██████████| 234/234 [00:08<00:00, 28.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.1061, Loss: 0.0825\n",
      "[Epoch 76] lambda_mga: 0.4000\n",
      "Val Acc: 0.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 77]: 100%|██████████| 234/234 [00:08<00:00, 28.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.1865, Loss: 0.0789\n",
      "[Epoch 77] lambda_mga: 0.4040\n",
      "Val Acc: 0.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 78]: 100%|██████████| 234/234 [00:09<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6956, Loss: 0.0684\n",
      "[Epoch 78] lambda_mga: 0.4080\n",
      "Val Acc: 0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 79]: 100%|██████████| 234/234 [00:09<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5080, Loss: 0.0737\n",
      "[Epoch 79] lambda_mga: 0.4120\n",
      "Val Acc: 0.8962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 80]: 100%|██████████| 234/234 [00:09<00:00, 25.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6956, Loss: 0.0720\n",
      "[Epoch 80] lambda_mga: 0.4160\n",
      "Val Acc: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 81]: 100%|██████████| 234/234 [00:09<00:00, 25.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.8382, Loss: 0.0838\n",
      "[Epoch 81] lambda_mga: 0.4200\n",
      "Val Acc: 0.9050\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 82]: 100%|██████████| 234/234 [00:09<00:00, 24.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8296, Loss: 0.0653\n",
      "[Epoch 82] lambda_mga: 0.4240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 83]: 100%|██████████| 234/234 [00:09<00:00, 25.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7224, Loss: 0.0638\n",
      "[Epoch 83] lambda_mga: 0.4280\n",
      "Val Acc: 0.8962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 84]: 100%|██████████| 234/234 [00:08<00:00, 26.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5616, Loss: 0.0735\n",
      "[Epoch 84] lambda_mga: 0.4320\n",
      "Val Acc: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 85]: 100%|██████████| 234/234 [00:09<00:00, 25.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.0793, Loss: 0.0823\n",
      "[Epoch 85] lambda_mga: 0.4360\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 86]: 100%|██████████| 234/234 [00:09<00:00, 25.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6688, Loss: 0.0709\n",
      "[Epoch 86] lambda_mga: 0.4400\n",
      "Val Acc: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 87]: 100%|██████████| 234/234 [00:09<00:00, 25.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7846, Loss: 0.0810\n",
      "[Epoch 87] lambda_mga: 0.4440\n",
      "Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 88]: 100%|██████████| 234/234 [00:09<00:00, 24.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8028, Loss: 0.0622\n",
      "[Epoch 88] lambda_mga: 0.4480\n",
      "Val Acc: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 89]: 100%|██████████| 234/234 [00:09<00:00, 25.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8028, Loss: 0.0669\n",
      "[Epoch 89] lambda_mga: 0.4520\n",
      "Val Acc: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 90]: 100%|██████████| 234/234 [00:09<00:00, 25.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.2047, Loss: 0.0563\n",
      "[Epoch 90] lambda_mga: 0.4560\n",
      "Val Acc: 0.8950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 91]: 100%|██████████| 234/234 [00:09<00:00, 25.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5616, Loss: 0.0697\n",
      "[Epoch 91] lambda_mga: 0.4600\n",
      "Val Acc: 0.8988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 92]: 100%|██████████| 234/234 [00:07<00:00, 30.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8028, Loss: 0.0669\n",
      "[Epoch 92] lambda_mga: 0.4640\n",
      "Val Acc: 0.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 93]: 100%|██████████| 234/234 [00:06<00:00, 33.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6152, Loss: 0.0678\n",
      "[Epoch 93] lambda_mga: 0.4680\n",
      "Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 94]: 100%|██████████| 234/234 [00:07<00:00, 31.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8296, Loss: 0.0658\n",
      "[Epoch 94] lambda_mga: 0.4720\n",
      "Val Acc: 0.8975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 95]: 100%|██████████| 234/234 [00:09<00:00, 25.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5080, Loss: 0.0647\n",
      "[Epoch 95] lambda_mga: 0.4760\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 96]: 100%|██████████| 234/234 [00:09<00:00, 24.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8564, Loss: 0.0664\n",
      "[Epoch 96] lambda_mga: 0.4800\n",
      "Val Acc: 0.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 97]: 100%|██████████| 234/234 [00:09<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7492, Loss: 0.0584\n",
      "[Epoch 97] lambda_mga: 0.4840\n",
      "Val Acc: 0.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 98]: 100%|██████████| 234/234 [00:09<00:00, 25.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.9100, Loss: 0.0617\n",
      "[Epoch 98] lambda_mga: 0.4880\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 99]: 100%|██████████| 234/234 [00:09<00:00, 25.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7760, Loss: 0.0656\n",
      "[Epoch 99] lambda_mga: 0.4920\n",
      "Val Acc: 0.8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 100]: 100%|██████████| 234/234 [00:09<00:00, 25.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5884, Loss: 0.0733\n",
      "[Epoch 100] lambda_mga: 0.4960\n",
      "Val Acc: 0.8912\n",
      "\n",
      "📊 Test Evaluation:\n",
      "✅ Test Accuracy         : 89.38%\n",
      "🎯 AUC                   : 0.9391\n",
      "📌 Precision             : 0.9104\n",
      "📌 Recall (Sensitivity)  : 0.9295\n",
      "📌 Specificity           : 0.8255\n",
      "📌 F1 Score              : 0.9199\n",
      "📌 Balanced Accuracy     : 0.8775\n",
      "📌 MCC                   : 0.7626\n",
      "\n",
      "📌 Confusion Matrix:\n",
      "[[227  48]\n",
      " [ 37 488]]\n",
      "\n",
      "📁 테스트 지표 저장 완료: logs/final_test_metrics.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# 베스트 모델 시드 고정\n",
    "\n",
    "# 전체코드: ResNet18 + CBAM + MGA Loss + Lambda Scheduling (CE Weight ver)\n",
    "\n",
    "import os, re, numpy as np, torch, gc\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "# -------------------- 디바이스 설정 --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- 하이퍼파라미터 설정 --------------------\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "seed_list = [42, 123, 2025, 777, 999]\n",
    "all_metrics = []\n",
    "\n",
    "# lambda MGA 스케줄 설정\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "total_epochs = num_epochs\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # numpy or tensor 이미지를 PIL 이미지 객체로 변환\n",
    "    transforms.Resize((224, 224)),  # 이미지를 224x224로 resize\n",
    "    transforms.RandomHorizontalFlip(),  # 이미지를 50% 확률로 좌우 반전\n",
    "    transforms.RandomRotation(10),  # 이미지를 -10도 ~ +10도 사이로 랜덤 회전, 촬영 자세나 기울어짐에 대한 회전 강건성확보\n",
    "    transforms.ToTensor(),  # PIL이미지 -> PyTorch Tensor로 변환, (H, W, C) -> (C, H, W), 값도 0255 -> 01 사이즈로 스케일 조정\n",
    "    transforms.Normalize([0.5], [0.5]), # 평균 0.5, 표준편차 0.5로 정규화 -> 결과적으로 01 -> 11로 바뀜\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
    "])  # 전체 이미지의 일부분 지우고 0으로 채움 (검은 사각형 생김)\n",
    "    # p=0.5 : 50% 확률로 이 증강 적용\n",
    "    # scale : 전체 이미지 대비 삭제 영역의 크기 비율\n",
    "    # ratio : 지우는 사각형의 가로:세로 비율 범위\n",
    "    # value=0 : 지운 곳을 검은색(0)으로 덮음\n",
    "    # 폐 CT에서 병변이 항상 일정한 위치에 나오지 않으니까 모델이 특정 위치에 과적합되는걸 방지함 (overfitting 예방)\n",
    "\n",
    "# 검증/테스트는 모델이 학습하지 않은 깨긋한 상태의 이미지로 정확도를 확인하기 위해서 검증용은 깔끔하게\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # PIL 이미지 객체로 변환\n",
    "    transforms.Resize((224, 224)),  # 사이즈 맞추기\n",
    "    transforms.ToTensor(),  # PIL 이미지 -> PyTorch Tensor로 변환\n",
    "    transforms.Normalize([0.5], [0.5])  # 정규화\n",
    "])\n",
    "\n",
    "# 시드 고정\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)                         # 파이썬 random\n",
    "    np.random.seed(seed)                      # numpy\n",
    "    torch.manual_seed(seed)                   # torch CPU\n",
    "    torch.cuda.manual_seed(seed)              # torch GPU\n",
    "    torch.cuda.manual_seed_all(seed)          # multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # 연산 동일하게\n",
    "    torch.backends.cudnn.benchmark = False    # 연산 속도 최적화 OFF (같은 연산 보장)\n",
    "\n",
    "# -------------------- Bounding Box를 Binary Mask로 --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    # bbox_list : 한 이미지에 들어있는 bounding box 리스트\n",
    "    # image_size : 출력할 마스크 크기. 보통 이미지와 동일한 (height, width) -> 디폴트는 224x224\n",
    "    # bbox들을 binary mask로 바꿔주는 함수\n",
    "    masks = []  # 여러 개의 bbox가 들어오니까, 각각의 마스크를 하나씩 리스트에 쌓기 위한 빈 리스트\n",
    "    for bbox in bbox_list:  # bbox_list를 하나씩 돌면서 처리 -> [x_min, y_min, x_max, y_max]네 좌표로 구성된 하나의 사각형 영역 \n",
    "        mask = np.zeros(image_size, dtype=np.float32)   # 224x224짜리 0으로 꽉 찬 2D 배열을 하나 생성\n",
    "        # 배경이 흰 종이를 만드는 느낌으로 만들고, 사각 영역만 1로 덧칠할거임\n",
    "        x_min, y_min, x_max, y_max = bbox   # 각 bbox의 네 좌표값을 각각 변수로 언팩. -> 마스크의 해당 영역에 사각형을 칠하기 위해서\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0    # y_min, y_max, x_min, x_max까지의 범위에 1.0을 채워 넣음\n",
    "        # -> 마스크에서 bbox에 해당하는 사각형 영역만 1(foreground)로 표시됨. 나머진 여전히 0(background)\n",
    "        masks.append(mask)  # 지금 만든 마스크(2D 배열)를 리스트에 추가 -> [mask1, mask2, ...]이렇게 쌓임\n",
    "\n",
    "    masks = np.stack(masks) # 리스트를 하나의 3D 배열로 합침 -> shape : [N, H, W] -> N은 bbox 개수\n",
    "    masks = np.expand_dims(masks, axis=1)   # 텐서 shape을 [N, 1, H, W]로 바꿈\n",
    "    # PyTorch 모델에서 기대하는 (batch x channel x height x width) 포맷 맞추기\n",
    "\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "    # numpy 배열을 PyTorch 텐서로 변환해서 리턴\n",
    "\n",
    "    # 한 bbox → 하나의 마스크 → 여러 개면 쌓아서 batch 형태로\n",
    "# -------------------- Bounding Box CSV 로드 --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    # csv_path : bounding box 정보가 들어있는 CSV 파일 경로\n",
    "    # 반환값 : {filename:[bbox1, bbox2, ...]} 형태의 딕셔너리\n",
    "    df = pd.read_csv(csv_path)  # CSV파일을 pandas DataFrame으로 읽어옴\n",
    "    bbox_dict = {}\n",
    "    # key : 슬라이스 파일 이름 (ex. \"LIDC-IDRI-1012_slice0004.npy\")\n",
    "    # value : 해당 슬라이스에 존재하는 bbox들의 리스트\n",
    "    for _, row in df.iterrows():    # DataFrame의 모든 행(row)를 하나씩 순회\n",
    "        # row는 한 줄(=한 bbox)의 정보를 담고 있음\n",
    "\n",
    "        pid = row['pid']    # 환자 ID (예: \"LIDC-IDRI-1012\") -> 이미지 이름 구성 요소\n",
    "        slice_str = row['slice']    # 슬라이스 정보가 들어있는 문자열 (예: \"slice_0039\")\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])  # re.findall()로 문자열에서 숫자만 뽑아냄\n",
    "        # \"slice_0039\" -> ['0039'] -> [0] -> 39 (슬라이스 번호를 정수로 추출함)\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"   # 파일명 구성 (예: \"LIDC-IDRI-1012_slice0039.npy\")\n",
    "        # {:04d}는 4자리 정수로 만들고 빈자리는 0으로 채워줌 (39 -> 0039)\n",
    "        bbox = eval(row['bb'])  # row['bb']는 문자열 형태의 bbox (예: \"[20, 30, 80, 100]\")\n",
    "        # eval()을 써서 문자열을 리스트로 바꿔줌\n",
    "        # 주의 : 보안 상 위험할 수 있는 함수지만, 여긴 내부 데이터라 사용중\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)    # fname이라는 key가 딕셔너리에 없으면 []로 초기화하고,\n",
    "        # 거기에 bbox를 append -> 슬라이스 하나에 bbox 여러개 있어도 전부 리스트로 모아줌\n",
    "    return bbox_dict    # 최종적으로 {filename: [bbox1, bbox2, ...]} 형태의 딕셔너리 반환\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "# 실제로 csv_path에 있는 정보를 불러와서 bbox_dict에 저장함\n",
    "# 이걸 나주에 Dataset 클래스에서 fname 기준을 꺼내쓰게 됨\n",
    "\n",
    "# -------------------- 라벨 추출 --------------------\n",
    "def extract_label_from_filename(fname): # fname : 파일 이름 (예: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # 이 이름에서 malignancy score(악성도 점수)를 추출해서 라벨로 변환\n",
    "    try:    # 파일명이 이상하거나 에러나면 except로 빠져나가서 None 반환함 (안전장치)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # 파일명에서 _ 제외하고 나머지 것들 중에 마지막에꺼를 가져와서 .npy를 \"\" 이렇게 공백으로 처리함\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- 이게 malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # 라벨 결정 로직으로\n",
    "        # score == 3 -> 중립 -> None 반환 -> 학습에서 제외\n",
    "        # score >= 4 -> 암(양성) -> 1\n",
    "        # score <= 2 -> 정상(음성) -> 0\n",
    "        # int(score >= 4)는 파이썬에서 True -> 1\n",
    "        # False -> 0 이니깐 자동으로 라벨이 됨\n",
    "    except:\n",
    "        return None\n",
    "        # 혹시 split이나 replace, int 변환이 실패하면 그냥 None 반환하고 무시\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    # PyTorch의 Dataset 클래스를 상속해서 커ㅡ텀 데이터셋 정의\n",
    "    # 나중에 DataLoader랑 같이 쓰이기 때문에 __len__()이랑 __getitem__()을 꼭 넣어줘야함\n",
    "    def __init__(self, paths, labels, transform=None):  # 생성자 : 세개의 인자를 받음\n",
    "        # paths : 이미지 .npy 파일 경로 리스트\n",
    "        # labels : 각 이미지에 대한 라벨 리스트 (0, 1 or None)\n",
    "        # transform : 이미지 증강 설정 (train_transform, val_transform 등)\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # 받은 인자를 멤버 변수로 저장. 나중에 gettem()에서 접근함\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoader가 이걸 호출할 때 index에 해당하는 sample 하나를 반환\n",
    "        # 이미지, 라벨, 마스크( = MGA용 target) 3개를 리턴함\n",
    "        file_path = self.paths[idx] # 파일 경로 불러오기\n",
    "        label = self.labels[idx]    # 라벨 불러오기\n",
    "        fname = os.path.basename(file_path) # 전체 경로에서 파일 이름만 추출 -> 나중에 bbox_dict[fname] 찾을때 쓰임\n",
    "\n",
    "        img = np.load(file_path)    # .npy 파일에서 CT 슬라이스 불러오기 -> 흑백 CT 이미지, shape은 (H, W)\n",
    "        img = np.clip(img, -1000, 400)  # CT 이미지 HU 값이 너무 크거나 작으면 노이즈 -> -1000(공기) ~ 400(연조직)으로 클리핑해서 노이즈 제거\n",
    "        img = (img + 1000) / 1400.  # 정규화 : -1000 -> 0, 400 -> 1 사이 값으로 바꿔줌 -> 모델이 안정적으로 학습할 수 있도록 함\n",
    "        img = np.expand_dims(img, axis=-1)  # CT는 채널이 1개니깐 (H, W) -> (H, w, 1)로 바꿔줌\n",
    "        # 나중에 PyTorch에서 (C, H, W)로 바꾸기 위함\n",
    "\n",
    "        if self.transform:  # 데이터 증강(transform)이 있다면 적용\n",
    "            img = self.transform(img)   \n",
    "        else:   # 없으면 numpy -> tensor 변환하고 (H, W, C) -> (C, H, W)로 순서 바꿈\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "\n",
    "        if fname in bbox_dict:  # 이 이미지에 bbox가 존재하면 -> 마스크 생성\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(224, 224))\n",
    "            # image_size는 transform과 동일하게 224x224\n",
    "        else:   # bbox가 없다면 전부 0으로 채워진 마스크 생성 -> MGA Loss 계산 시 참고용으로 쓰일 수 있음\n",
    "            mask = torch.zeros((1, 224, 224), dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask.squeeze(0)\n",
    "        # 반환값 3개 :\n",
    "        # img : shape[1, 224, 224]\n",
    "        # label : int(0 or 1)\n",
    "        # mask : [224, 224] <- squeeze로 채널 1개 제거\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    # 전체 데이터셋 길이 반환 -> DataLoader가 아라야 배치 쪼갤 수 있음.\n",
    "\n",
    "# -------------------- CBAM 정의 (MGA 포함) --------------------\n",
    "# 2 Step : Channel Attention(어떤 채널에 집중할지) * Spatial Attention(어디에 집중할지) = 최종 Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # 입력 feature map의 채널별 중요도를 계산해서 강조함\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : 입력 채널 수\n",
    "        # ratio : 중간 채널 축소 비율. 기본 1/16으로 bottlenck 구성\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP 역할을 하는 1x1 conv 블록 -> 채널 압축 -> 비선형 -> 복원 (shared는 avg/max 둘다에서 같이 씀)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # 평균 풀링 / 최대 풀링으로 두가지 전역 정보를 추출\n",
    "        # 마지막 sigmoid는 attention weight로 스케일링\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max 풀링 경과를 각각 shape MLP에 통과시키고, 더한 후 sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> 채널마다 중요도 weight를 곱하게 됨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # 공간적으로 어디에 집중할지를 결정 -> 각 채널 내부에서 중요한 위치 찾기\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # 채널 차원은 평균, 최대 두 개만 써서 concat\n",
    "    # 그걸 1채널로 줄여주는 conv\n",
    "    # 커널 크기 k=7이면 넓은 영역까지 감지 가능\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # 입력 feature map에서 :\n",
    "    # 평균, 최대값을 각 spatial 위치별로 구함 -> [B, 1, H, W] 두 개\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> 위치별 중요도 map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttention을 내부에 선언\n",
    "    # MGA를 위해 마지막 attention map을 저장하는 변수 포함\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # 채널 중요도 -> 곱함\n",
    "    # 위치 중요도 -> 곱함\n",
    "    # 둘 다 반영된 최종 feature map 리턴\n",
    "\n",
    "# -------------------- ResNet18 + CBAM 모델 정의 --------------------\n",
    "# BasicBlockCBAM : ResNet의 기본 Residual Block 하나를 정의\n",
    "# → conv → BN → ReLU → conv → BN → (CBAM optional) → Add → ReLU\n",
    "\n",
    "# ResNet18_CBAM : ResNet18 구조로 전체 네트워크 쌓기\n",
    "# → conv1 → layer1~3 → layer4 → avgpool → fc\n",
    "\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        # 입력 채널: in_planes, 출력 채널: out_planes, 3x3 커널, padding=1로 크기 유지, stride로 크기 조절\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)   # 배치 정규화\n",
    "        self.relu = nn.ReLU()   # 비선형 활성화 함수\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        # 두번째 conv, 채널 수 유지, 크기 유지\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)   # 배치 정규화\n",
    "\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None  # CBAM 모듈 사용 여부\n",
    "        self.downsample = downsample    # residual 연결 시 차원 맞추는 conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # skip connection용 입력 저장\n",
    "\n",
    "        out = self.conv1(x) # 첫 번째 conv\n",
    "        out = self.bn1(out) # 정규화\n",
    "        out = self.relu(out)  # 활성화\n",
    "\n",
    "        out = self.conv2(out)   # 두 번째 conv\n",
    "        out = self.bn2(out) # 정규화\n",
    "\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)    # CBAM 적용\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)   # shortcut 경로 보정\n",
    "\n",
    "        out += residual # skip connection\n",
    "        out = self.relu(out)    # 출력에 ReLU 적용\n",
    "\n",
    "        return out  # 결과 반환\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64 # 조기 입력 채널 수 설정\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # 입력: [B, 1, 224, 224] -> 출력: [B, 64, 112, 112], 큰 커널로 넓은 영역 캡처 \n",
    "        self.bn1 = nn.BatchNorm2d(64)   # 정규화\n",
    "        self.relu = nn.ReLU()   # 활성화\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # 풀링: [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        self.layer1 = self._make_layer(64, blocks=2)  # [B, 64, 56, 56] 유지\n",
    "        self.layer2 = self._make_layer(128, blocks=2, stride=2)  # [B, 128, 28, 28] 다운샘플링\n",
    "        self.layer3 = self._make_layer(256, blocks=2, stride=2)  # [B, 256, 14, 14] 다운샘플링\n",
    "        self.layer4 = self._make_layer(512, blocks=2, stride=2, use_cbam=False)  # [B, 512, 7, 7], CBAM 미사용\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # [B, 512, 7, 7] -> [B, 512, 1, 1]\n",
    "        self.fc = nn.Linear(512, num_classes)  # [B, 512] -> [B, num_classes]\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        # Planes : 해당 레이어의 출력 채널 수\n",
    "        # # blocks : 블록 수\n",
    "        # stride=2인 경우 다운샘플링 (해상도 절반)\n",
    "\n",
    "        downsample = None   # 스킵 연결해서 입력/출력 크기가 다르면 맞춰야 함\n",
    "\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                # 1x1 conv로 채널 수   및 공간 크기 맞춤\n",
    "                nn.BatchNorm2d(planes))\n",
    "            \n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam=use_cbam)]\n",
    "        # 첫 블록은 다운샘플링 적용 가능성 있음\n",
    "        self.in_planes = planes # 이후 블록을 위한 입력 채널 업데이트\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "            # 나머지 블록은 stride=1로 동일한 해상도 유지\n",
    "\n",
    "        return nn.Sequential(*layers)   # 블록들을 Seguential로 묶어 반환\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # 입력: [B, 1, 224, 224] -> [B, 64, 112, 112]\n",
    "        x = self.bn1(x)    # 정규화\n",
    "        x = self.relu(x)   # ReLU 활성화\n",
    "        x = self.maxpool(x)  # [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        x = self.layer1(x)  # [B, 64, 56, 56]\n",
    "        x = self.layer2(x)  # [B, 128, 28, 28]\n",
    "        x = self.layer3(x)  # [B, 256, 14, 14]\n",
    "        x = self.layer4(x)  # [B, 512, 7, 7]\n",
    "\n",
    "        x = self.avgpool(x)  # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # [B, 512]\n",
    "        x = self.fc(x)  # [B, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------- 학습 루프 --------------------\n",
    "def run(seed=42):\n",
    "    seed_everything(seed)\n",
    "\n",
    "\n",
    "    # 모든 CT 슬라이스 파일 경로 불러오기 (LIDC-IDRI 환자 폴더 안의 .npy 파일들)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "\n",
    "    # 파일 경로와 해당 파일의 라벨을 튜플로 저장\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    # 라벨이 None이 아닌 데이터만 필터링 (중립 제외)\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "\n",
    "    # 파일, 라벨을 리스트로 분리\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    # 전체 데이터를 train(70%), val(15%), test(15%)로 분할\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(\n",
    "    files, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(\n",
    "    temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    # 데이터 불러오기\n",
    "    train_dataset = CTDataset(train_files, train_labels, transform=train_transform)\n",
    "    val_dataset = CTDataset(val_files, val_labels, transform=val_transform)\n",
    "    test_dataset = CTDataset(test_files, test_labels, transform=val_transform)\n",
    "\n",
    "    # 데이터 로더\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # 모델, 손실함수, 옵티마이저 정의\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.6653, 0.3347], device=device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_acc = 0.0  # 가장 높은 val accuracy를 저장\n",
    "    save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"r18_cbam_mga_aug_lr4_ep100_weight_seedfix.pth\")\n",
    "\n",
    "    # 학습 루프 시작\n",
    "    for epoch in range(num_epochs):\n",
    "        # MGA 스케쥴링: 초기 lambda -> 점점 증가시킴\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "\n",
    "        model.train()  # 학습 모드로 변경\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # 한 epoch 동안 모든 train 데이터를 학습\n",
    "        for images, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)  # forward pass\n",
    "            ce_loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "            # -------------------- MGA Loss 계산 위치 --------------------\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # attention map 꺼내오기\n",
    "\n",
    "            if attn_map is not None:\n",
    "                attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                attn_loss = F.mse_loss(attn_map, masks)  # mask와의 MSE loss\n",
    "                loss = ce_loss + lambda_mga * attn_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Acc: {(correct/total)*100:.4f}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] lambda_mga: {lambda_mga:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()  # 메모리 정리\n",
    "\n",
    "        # -------------------- 검증 --------------------\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iamegs, labels, masks in val_loader:\n",
    "                iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "                outputs = model(iamegs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"✅ Saved best model!\")\n",
    "\n",
    "    # -------------------- 테스트 --------------------\n",
    "    print(\"\\n📊 Test Evaluation:\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # numpy 배열로 변환\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    # 지표 계산\n",
    "    from sklearn.metrics import (\n",
    "        classification_report, roc_auc_score, confusion_matrix,\n",
    "        precision_score, recall_score, balanced_accuracy_score,\n",
    "        matthews_corrcoef, f1_score\n",
    "    )\n",
    "\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    # 📋 출력\n",
    "    print(f\"✅ Test Accuracy         : {acc*100:.2f}%\")\n",
    "    print(f\"🎯 AUC                   : {auc:.4f}\")\n",
    "    print(f\"📌 Precision             : {precision:.4f}\")\n",
    "    print(f\"📌 Recall (Sensitivity)  : {recall:.4f}\")\n",
    "    print(f\"📌 Specificity           : {specificity:.4f}\")\n",
    "    print(f\"📌 F1 Score              : {f1:.4f}\")\n",
    "    print(f\"📌 Balanced Accuracy     : {balanced_acc:.4f}\")\n",
    "    print(f\"📌 MCC                   : {mcc:.4f}\")\n",
    "    print(\"\\n📌 Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # 📁 CSV로 저장\n",
    "    test_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"phase\": \"test\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "\n",
    "    csv_path = \"logs/final_test_metrics.csv\"\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=test_metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(test_metrics)\n",
    "\n",
    "    print(f\"\\n📁 테스트 지표 저장 완료: {csv_path}\")\n",
    "\n",
    "# 진입점\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2569359/2177874015.py:60: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(p=0.4, max_holes=1, max_height=32, max_width=32),\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ResNet18_CBAM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 373\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# 실행\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 255\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    252\u001b[39m val_loader = DataLoader(CTDataset(val_files, val_labels, transform=val_transform), batch_size=batch_size)\n\u001b[32m    253\u001b[39m test_loader = DataLoader(test_dataset, batch_size=batch_size)\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m model = \u001b[43mResNet18_CBAM\u001b[49m().to(device)\n\u001b[32m    256\u001b[39m criterion = FocalLoss(weight=torch.tensor([\u001b[32m0.65\u001b[39m, \u001b[32m0.35\u001b[39m], device=device), gamma=\u001b[32m2.0\u001b[39m)\n\u001b[32m    257\u001b[39m optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
      "\u001b[31mNameError\u001b[39m: name 'ResNet18_CBAM' is not defined"
     ]
    }
   ],
   "source": [
    "# ✅ 전체코드: ResNet18 + CBAM + MGA + Lambda Scheduling + FocalLoss + TTA\n",
    "# ✅ 핵심: TTADataset 적용 + 다양한 TTA inference 지원\n",
    "\n",
    "import os, re, numpy as np, torch, gc, csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score, balanced_accuracy_score, matthews_corrcoef\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 경로 및 하이퍼파라미터\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "batch_size = 16\n",
    "num_epochs = 150\n",
    "learning_rate = 1e-4\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "\n",
    "# FocalLoss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = F.log_softmax(input, dim=1)\n",
    "        ce_loss = F.nll_loss(logp, target, weight=self.weight, reduction='none')\n",
    "        p = torch.exp(-ce_loss)\n",
    "        return ((1 - p) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "# Transform 설정\n",
    "def get_tta_transforms():\n",
    "    return [\n",
    "        A.Compose([A.Resize(224, 224), A.Normalize((0.5,), (0.5,)), ToTensorV2()]),\n",
    "        A.Compose([A.HorizontalFlip(p=1.0), A.Resize(224, 224), A.Normalize((0.5,), (0.5,)), ToTensorV2()]),\n",
    "        A.Compose([A.Rotate(limit=15, p=1.0), A.Resize(224, 224), A.Normalize((0.5,), (0.5,)), ToTensorV2()]),\n",
    "        A.Compose([A.RandomBrightnessContrast(p=1.0), A.Resize(224, 224), A.Normalize((0.5,), (0.5,)), ToTensorV2()])\n",
    "    ]\n",
    "\n",
    "tta_transforms = get_tta_transforms()\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.CoarseDropout(p=0.4, max_holes=1, max_height=32, max_width=32),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# 시드고정\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)                         # 파이썬 random\n",
    "    np.random.seed(seed)                      # numpy\n",
    "    torch.manual_seed(seed)                   # torch CPU\n",
    "    torch.cuda.manual_seed(seed)              # torch GPU\n",
    "    torch.cuda.manual_seed_all(seed)          # multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # 연산 동일하게\n",
    "    torch.backends.cudnn.benchmark = False    # 연산 속도 최적화 OFF (같은 연산 보장)\n",
    "\n",
    "# Bounding Box를 Binary Mask로\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    masks = []\n",
    "    for bbox in bbox_list:\n",
    "        mask = np.zeros(image_size, dtype=np.float32)\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0\n",
    "        masks.append(mask)\n",
    "    masks = np.stack(masks)\n",
    "    masks = np.expand_dims(masks, axis=1)\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "\n",
    "def load_bbox_dict(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    bbox_dict = {}\n",
    "    for _, row in df.iterrows():\n",
    "        pid = row['pid']\n",
    "        slice_str = row['slice']\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"\n",
    "        bbox = eval(row['bb'])\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)\n",
    "    return bbox_dict\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "\n",
    "def extract_label_from_filename(fname):\n",
    "    try:\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Dataset\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        fname = os.path.basename(f)\n",
    "\n",
    "        img = np.load(f)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.0\n",
    "        img = np.expand_dims(img.astype(np.float32), axis=-1)\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(h, w))[0].numpy()\n",
    "        else:\n",
    "            mask = np.zeros((h, w), dtype=np.float32)\n",
    "        mask = np.expand_dims(mask, axis=-1).astype(np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "        else:\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "            mask = torch.tensor(mask.squeeze(), dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "        \n",
    "\n",
    "# TTA용 Dataset\n",
    "class TTADataset(Dataset):\n",
    "    def __init__(self, paths, labels, tta_transforms):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.tta_transforms = tta_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = np.load(f)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.0\n",
    "        img = np.expand_dims(img.astype(np.float32), axis=-1)\n",
    "\n",
    "        images = [t(image=img)[\"image\"] for t in self.tta_transforms]\n",
    "        return torch.stack(images), torch.tensor(label).long()\n",
    "\n",
    "\n",
    "# CBAM + ResNet18 정의\n",
    "# -------------------- CBAM 정의 (MGA 포함) --------------------\n",
    "# 2 Step : Channel Attention(어떤 채널에 집중할지) * Spatial Attention(어디에 집중할지) = 최종 Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # 입력 feature map의 채널별 중요도를 계산해서 강조함\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : 입력 채널 수\n",
    "        # ratio : 중간 채널 축소 비율. 기본 1/16으로 bottlenck 구성\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP 역할을 하는 1x1 conv 블록 -> 채널 압축 -> 비선형 -> 복원 (shared는 avg/max 둘다에서 같이 씀)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # 평균 풀링 / 최대 풀링으로 두가지 전역 정보를 추출\n",
    "        # 마지막 sigmoid는 attention weight로 스케일링\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max 풀링 경과를 각각 shape MLP에 통과시키고, 더한 후 sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> 채널마다 중요도 weight를 곱하게 됨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # 공간적으로 어디에 집중할지를 결정 -> 각 채널 내부에서 중요한 위치 찾기\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # 채널 차원은 평균, 최대 두 개만 써서 concat\n",
    "    # 그걸 1채널로 줄여주는 conv\n",
    "    # 커널 크기 k=7이면 넓은 영역까지 감지 가능\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # 입력 feature map에서 :\n",
    "    # 평균, 최대값을 각 spatial 위치별로 구함 -> [B, 1, H, W] 두 개\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> 위치별 중요도 map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttention을 내부에 선언\n",
    "    # MGA를 위해 마지막 attention map을 저장하는 변수 포함\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # 채널 중요도 -> 곱함\n",
    "    # 위치 중요도 -> 곱함\n",
    "    # 둘 다 반영된 최종 feature map 리턴\n",
    "\n",
    "\n",
    "\n",
    "# 학습\n",
    "\n",
    "def run():\n",
    "    seed_everything(42)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "    \n",
    "    test_dataset = TTADataset(test_files, test_labels, tta_transforms)\n",
    "\n",
    "    train_loader = DataLoader(CTDataset(train_files, train_labels, transform=train_transform), batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(CTDataset(val_files, val_labels, transform=val_transform), batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = FocalLoss(weight=torch.tensor([0.65, 0.35], device=device), gamma=2.0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    save_path = os.path.join(\"pth\", \"r18_cbam_mga_aug_tta.pth\")\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "    \n",
    "\n",
    "    monitor_start = 80\n",
    "    monitor_window = 10\n",
    "    monitor_threshold = 0.90\n",
    "    recent_val_accs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for imgs, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            imgs, labels, masks = imgs.to(device), labels.to(device), masks.to(device)\n",
    "            outputs = model(imgs)\n",
    "            ce_loss = criterion(outputs, labels)\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # [B, 1, H, W]\n",
    "            attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)  # [B, 224, 224]\n",
    "            masks = masks.view(masks.size(0), 224, 224)  # 강제로 [B, 224, 224]로 reshape\n",
    "            mga_loss = F.mse_loss(attn_map, masks.float())\n",
    "            loss = ce_loss + lambda_mga * mga_loss\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        print(f\"Train Acc: {correct/total:.4f}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        model.eval(); val_correct, val_total = 0, 0\n",
    "        min_val_acc = 0.85  # 기본 기준선\n",
    "        patience = 10       # 기다릴 수 있는 횟수\n",
    "        epochs_no_improve = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels, _ in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        val_acc = val_correct / val_total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        recent_val_accs.append(val_acc)\n",
    "        if len(recent_val_accs) > monitor_window:\n",
    "            recent_val_accs.pop(0)\n",
    "\n",
    "        if epoch + 1 >= monitor_start:\n",
    "            if len(recent_val_accs) == monitor_window and all(acc < monitor_threshold for acc in recent_val_accs):\n",
    "                print(f\"🛑 Early stopping: Epoch {epoch+1} 기준 최근 {monitor_window}번 val_acc < {monitor_threshold}\")\n",
    "                break\n",
    "\n",
    "    # ---------------- 테스트 ----------------\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs_batch, labels in test_loader:  # imgs_batch: [B, T, C, H, W]\n",
    "            labels = labels.to(device)\n",
    "            B, T, C, H, W = imgs_batch.shape\n",
    "            imgs_batch = imgs_batch.to(device)  # (B, T, C, H, W)\n",
    "            imgs_batch = imgs_batch.view(-1, C, H, W)  # (B*T, C, H, W)\n",
    "\n",
    "            outputs = model(imgs_batch)  # (B*T, num_classes)\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "            outputs = outputs.view(B, T, -1).mean(dim=1)  # (B, num_classes)\n",
    "\n",
    "            probs = outputs[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true); y_pred = np.array(y_pred); y_probs = np.array(y_probs)\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n📊 Test Evaluation:\\n✅ Accuracy: {acc*100:.2f}% | AUC: {auc:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\", cm)\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    counter = Counter(labels)\n",
    "    print(f\"Class distribution: {counter}\")\n",
    "\n",
    "    metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "    with open(\"logs/final_test_metrics.csv\", 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=metrics.keys())\n",
    "        if not os.path.exists(\"logs/final_test_metrics.csv\"):\n",
    "            writer.writeheader()\n",
    "        writer.writerow(metrics)\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r18_cbam_mga_aug_focal150_2.pth\n",
    "# ✅ 전체코드: ResNet18 + CBAM + MGA + Lambda Scheduling\n",
    "# ✅ 추천 실험 조합 포함:\n",
    "# - Weighted FocalLoss (gamma=2.0)\n",
    "# - Data Aug: Resize + Flip + Rotate(15) + BrightnessContrast + Dropout\n",
    "# - Evaluation Metrics + CSV 저장 + tqdm\n",
    "\n",
    "import os, re, numpy as np, torch, gc, csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# 디바이스\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 경로 & 하이퍼파라미터\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "batch_size = 16\n",
    "num_epochs = 150\n",
    "learning_rate = 1e-4\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "\n",
    "# FocalLoss 구현\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = F.log_softmax(input, dim=1)\n",
    "        ce_loss = F.nll_loss(logp, target, weight=self.weight, reduction='none')\n",
    "        p = torch.exp(-ce_loss)\n",
    "        return ((1 - p) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "# Transform (Albumentations)\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.CoarseDropout(p=0.4, max_holes=1, max_height=32, max_width=32),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# BBox -> 마스크\n",
    "# -------------------- Bounding Box를 Binary Mask로 --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    # bbox_list : 한 이미지에 들어있는 bounding box 리스트\n",
    "    # image_size : 출력할 마스크 크기. 보통 이미지와 동일한 (height, width) -> 디폴트는 224x224\n",
    "    # bbox들을 binary mask로 바꿔주는 함수\n",
    "    masks = []  # 여러 개의 bbox가 들어오니까, 각각의 마스크를 하나씩 리스트에 쌓기 위한 빈 리스트\n",
    "    for bbox in bbox_list:  # bbox_list를 하나씩 돌면서 처리 -> [x_min, y_min, x_max, y_max]네 좌표로 구성된 하나의 사각형 영역 \n",
    "        mask = np.zeros(image_size, dtype=np.float32)   # 224x224짜리 0으로 꽉 찬 2D 배열을 하나 생성\n",
    "        # 배경이 흰 종이를 만드는 느낌으로 만들고, 사각 영역만 1로 덧칠할거임\n",
    "        x_min, y_min, x_max, y_max = bbox   # 각 bbox의 네 좌표값을 각각 변수로 언팩. -> 마스크의 해당 영역에 사각형을 칠하기 위해서\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0    # y_min, y_max, x_min, x_max까지의 범위에 1.0을 채워 넣음\n",
    "        # -> 마스크에서 bbox에 해당하는 사각형 영역만 1(foreground)로 표시됨. 나머진 여전히 0(background)\n",
    "        masks.append(mask)  # 지금 만든 마스크(2D 배열)를 리스트에 추가 -> [mask1, mask2, ...]이렇게 쌓임\n",
    "\n",
    "    masks = np.stack(masks) # 리스트를 하나의 3D 배열로 합침 -> shape : [N, H, W] -> N은 bbox 개수\n",
    "    masks = np.expand_dims(masks, axis=1)   # 텐서 shape을 [N, 1, H, W]로 바꿈\n",
    "    # PyTorch 모델에서 기대하는 (batch x channel x height x width) 포맷 맞추기\n",
    "\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "    # numpy 배열을 PyTorch 텐서로 변환해서 리턴\n",
    "\n",
    "    # 한 bbox → 하나의 마스크 → 여러 개면 쌓아서 batch 형태로\n",
    "# -------------------- Bounding Box CSV 로드 --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    # csv_path : bounding box 정보가 들어있는 CSV 파일 경로\n",
    "    # 반환값 : {filename:[bbox1, bbox2, ...]} 형태의 딕셔너리\n",
    "    df = pd.read_csv(csv_path)  # CSV파일을 pandas DataFrame으로 읽어옴\n",
    "    bbox_dict = {}\n",
    "    # key : 슬라이스 파일 이름 (ex. \"LIDC-IDRI-1012_slice0004.npy\")\n",
    "    # value : 해당 슬라이스에 존재하는 bbox들의 리스트\n",
    "    for _, row in df.iterrows():    # DataFrame의 모든 행(row)를 하나씩 순회\n",
    "        # row는 한 줄(=한 bbox)의 정보를 담고 있음\n",
    "\n",
    "        pid = row['pid']    # 환자 ID (예: \"LIDC-IDRI-1012\") -> 이미지 이름 구성 요소\n",
    "        slice_str = row['slice']    # 슬라이스 정보가 들어있는 문자열 (예: \"slice_0039\")\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])  # re.findall()로 문자열에서 숫자만 뽑아냄\n",
    "        # \"slice_0039\" -> ['0039'] -> [0] -> 39 (슬라이스 번호를 정수로 추출함)\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"   # 파일명 구성 (예: \"LIDC-IDRI-1012_slice0039.npy\")\n",
    "        # {:04d}는 4자리 정수로 만들고 빈자리는 0으로 채워줌 (39 -> 0039)\n",
    "        bbox = eval(row['bb'])  # row['bb']는 문자열 형태의 bbox (예: \"[20, 30, 80, 100]\")\n",
    "        # eval()을 써서 문자열을 리스트로 바꿔줌\n",
    "        # 주의 : 보안 상 위험할 수 있는 함수지만, 여긴 내부 데이터라 사용중\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)    # fname이라는 key가 딕셔너리에 없으면 []로 초기화하고,\n",
    "        # 거기에 bbox를 append -> 슬라이스 하나에 bbox 여러개 있어도 전부 리스트로 모아줌\n",
    "    return bbox_dict    # 최종적으로 {filename: [bbox1, bbox2, ...]} 형태의 딕셔너리 반환\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "# 실제로 csv_path에 있는 정보를 불러와서 bbox_dict에 저장함\n",
    "# 이걸 나주에 Dataset 클래스에서 fname 기준을 꺼내쓰게 됨\n",
    "\n",
    "# -------------------- 라벨 추출 --------------------\n",
    "def extract_label_from_filename(fname): # fname : 파일 이름 (예: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # 이 이름에서 malignancy score(악성도 점수)를 추출해서 라벨로 변환\n",
    "    try:    # 파일명이 이상하거나 에러나면 except로 빠져나가서 None 반환함 (안전장치)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # 파일명에서 _ 제외하고 나머지 것들 중에 마지막에꺼를 가져와서 .npy를 \"\" 이렇게 공백으로 처리함\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- 이게 malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # 라벨 결정 로직으로\n",
    "        # score == 3 -> 중립 -> None 반환 -> 학습에서 제외\n",
    "        # score >= 4 -> 암(양성) -> 1\n",
    "        # score <= 2 -> 정상(음성) -> 0\n",
    "        # int(score >= 4)는 파이썬에서 True -> 1\n",
    "        # False -> 0 이니깐 자동으로 라벨이 됨\n",
    "    except:\n",
    "        return None\n",
    "        # 혹시 split이나 replace, int 변환이 실패하면 그냥 None 반환하고 무시\n",
    "\n",
    "# 시드 고정\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)                         # 파이썬 random\n",
    "    np.random.seed(seed)                      # numpy\n",
    "    torch.manual_seed(seed)                   # torch CPU\n",
    "    torch.cuda.manual_seed(seed)              # torch GPU\n",
    "    torch.cuda.manual_seed_all(seed)          # multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # 연산 동일하게\n",
    "    torch.backends.cudnn.benchmark = False    # 연산 속도 최적화 OFF (같은 연산 보장)\n",
    "\n",
    "    \n",
    "# Dataset (Albumentations 적용)\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        fname = os.path.basename(f)\n",
    "\n",
    "        img = np.load(f)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.0\n",
    "        mask = np.zeros((224, 224), dtype=np.float32)\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(224, 224)).sum(0).squeeze().numpy()\n",
    "\n",
    "        augmented = self.transform(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "        return img.unsqueeze(0), torch.tensor(label).long(), mask\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "# CBAM + ResNet18 정의\n",
    "...\n",
    "\n",
    "# 학습\n",
    "\n",
    "def run():\n",
    "    seed_everything(42)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_loader = DataLoader(CTDataset(train_files, train_labels, transform=train_transform), batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(CTDataset(val_files, val_labels, transform=val_transform), batch_size=batch_size)\n",
    "    test_loader = DataLoader(CTDataset(test_files, test_labels, transform=val_transform), batch_size=batch_size)\n",
    "\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = FocalLoss(weight=torch.tensor([0.65, 0.35], device=device), gamma=2.0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    save_path = os.path.join(\"pth\", \"r18_cbam_mga_aug_focal150_2.pth\")\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for imgs, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            imgs, labels, masks = imgs.to(device), labels.to(device), masks.to(device)\n",
    "            outputs = model(imgs)\n",
    "            ce_loss = criterion(outputs, labels)\n",
    "            attn_map = model.layer3[1].cbam.last_attention\n",
    "            attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "            mga_loss = F.mse_loss(attn_map, masks)\n",
    "            loss = ce_loss + lambda_mga * mga_loss\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        print(f\"Train Acc: {correct/total:.4f}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        model.eval(); val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels, _ in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        val_acc = val_correct / val_total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"✅ Saved best model!\")\n",
    "\n",
    "    # ---------------- 테스트 ----------------\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, _ in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true); y_pred = np.array(y_pred); y_probs = np.array(y_probs)\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n📊 Test Evaluation:\\n✅ Accuracy: {acc*100:.2f}% | AUC: {auc:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\", cm)\n",
    "\n",
    "    metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "    with open(\"logs/final_test_metrics.csv\", 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=metrics.keys())\n",
    "        if not os.path.exists(\"logs/final_test_metrics.csv\"):\n",
    "            writer.writeheader()\n",
    "        writer.writerow(metrics)\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1974167/4093859747.py:52: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(p=0.4, max_holes=1, max_height=32, max_width=32),\n",
      "[Epoch 1]: 100%|██████████| 234/234 [00:13<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3540, Loss: 0.0447\n",
      "Val Acc: 0.3113\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|██████████| 234/234 [00:12<00:00, 18.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3631, Loss: 0.0262\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|██████████| 234/234 [00:08<00:00, 26.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3650, Loss: 0.0249\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: 100%|██████████| 234/234 [00:08<00:00, 28.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3652, Loss: 0.0246\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: 100%|██████████| 234/234 [00:13<00:00, 17.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3569, Loss: 0.0244\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6]: 100%|██████████| 234/234 [00:13<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3719, Loss: 0.0241\n",
      "Val Acc: 0.6550\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7]: 100%|██████████| 234/234 [00:13<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3633, Loss: 0.0242\n",
      "Val Acc: 0.6887\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8]: 100%|██████████| 234/234 [00:12<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3786, Loss: 0.0240\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9]: 100%|██████████| 234/234 [00:13<00:00, 17.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3909, Loss: 0.0238\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10]: 100%|██████████| 234/234 [00:13<00:00, 17.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3864, Loss: 0.0238\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 11]: 100%|██████████| 234/234 [00:10<00:00, 22.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3864, Loss: 0.0240\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 12]: 100%|██████████| 234/234 [00:08<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4148, Loss: 0.0237\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 13]: 100%|██████████| 234/234 [00:08<00:00, 26.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4223, Loss: 0.0234\n",
      "Val Acc: 0.4175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 14]: 100%|██████████| 234/234 [00:12<00:00, 18.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4432, Loss: 0.0233\n",
      "Val Acc: 0.3225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 15]: 100%|██████████| 234/234 [00:13<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4373, Loss: 0.0232\n",
      "Val Acc: 0.3325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 16]: 100%|██████████| 234/234 [00:12<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4735, Loss: 0.0228\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17]: 100%|██████████| 234/234 [00:13<00:00, 17.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4815, Loss: 0.0227\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 18]: 100%|██████████| 234/234 [00:13<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.5019, Loss: 0.0219\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 19]: 100%|██████████| 234/234 [00:13<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.5040, Loss: 0.0216\n",
      "Val Acc: 0.5088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 20]: 100%|██████████| 234/234 [00:09<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.5480, Loss: 0.0211\n",
      "Val Acc: 0.5150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 21]: 100%|██████████| 234/234 [00:08<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.5648, Loss: 0.0205\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 22]: 100%|██████████| 234/234 [00:11<00:00, 20.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.5793, Loss: 0.0204\n",
      "Val Acc: 0.4213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 23]: 100%|██████████| 234/234 [00:12<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6112, Loss: 0.0198\n",
      "Val Acc: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 24]: 100%|██████████| 234/234 [00:12<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6367, Loss: 0.0189\n",
      "Val Acc: 0.6987\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 25]: 100%|██████████| 234/234 [00:13<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6447, Loss: 0.0185\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 26]: 100%|██████████| 234/234 [00:12<00:00, 18.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6693, Loss: 0.0180\n",
      "Val Acc: 0.6388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 27]: 100%|██████████| 234/234 [00:12<00:00, 18.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6838, Loss: 0.0178\n",
      "Val Acc: 0.6725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 28]: 100%|██████████| 234/234 [00:12<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6943, Loss: 0.0173\n",
      "Val Acc: 0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 29]: 100%|██████████| 234/234 [00:07<00:00, 31.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7141, Loss: 0.0164\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 30]: 100%|██████████| 234/234 [00:08<00:00, 27.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7395, Loss: 0.0155\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 31]: 100%|██████████| 234/234 [00:12<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7406, Loss: 0.0154\n",
      "Val Acc: 0.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 32]: 100%|██████████| 234/234 [00:12<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7655, Loss: 0.0149\n",
      "Val Acc: 0.5025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 33]: 100%|██████████| 234/234 [00:13<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7779, Loss: 0.0140\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 34]: 100%|██████████| 234/234 [00:13<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7889, Loss: 0.0137\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 35]: 100%|██████████| 234/234 [00:12<00:00, 18.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7923, Loss: 0.0134\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 36]: 100%|██████████| 234/234 [00:12<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8025, Loss: 0.0127\n",
      "Val Acc: 0.4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 37]: 100%|██████████| 234/234 [00:13<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8065, Loss: 0.0127\n",
      "Val Acc: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 38]: 100%|██████████| 234/234 [00:07<00:00, 29.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8106, Loss: 0.0128\n",
      "Val Acc: 0.5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 39]: 100%|██████████| 234/234 [00:08<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8242, Loss: 0.0120\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 40]: 100%|██████████| 234/234 [00:10<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8315, Loss: 0.0119\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 41]: 100%|██████████| 234/234 [00:12<00:00, 18.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8309, Loss: 0.0116\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 42]: 100%|██████████| 234/234 [00:13<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8344, Loss: 0.0112\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 43]: 100%|██████████| 234/234 [00:13<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8518, Loss: 0.0110\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 44]: 100%|██████████| 234/234 [00:12<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8360, Loss: 0.0109\n",
      "Val Acc: 0.8087\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 45]: 100%|██████████| 234/234 [00:13<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8569, Loss: 0.0106\n",
      "Val Acc: 0.6338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 46]: 100%|██████████| 234/234 [00:13<00:00, 17.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8494, Loss: 0.0106\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 47]: 100%|██████████| 234/234 [00:08<00:00, 29.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8599, Loss: 0.0095\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 48]: 100%|██████████| 234/234 [00:08<00:00, 28.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8655, Loss: 0.0099\n",
      "Val Acc: 0.4437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 49]: 100%|██████████| 234/234 [00:12<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8762, Loss: 0.0093\n",
      "Val Acc: 0.4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 50]: 100%|██████████| 234/234 [00:13<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8708, Loss: 0.0098\n",
      "Val Acc: 0.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 51]: 100%|██████████| 234/234 [00:13<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8743, Loss: 0.0095\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 52]: 100%|██████████| 234/234 [00:12<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8880, Loss: 0.0089\n",
      "Val Acc: 0.6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 53]: 100%|██████████| 234/234 [00:13<00:00, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8842, Loss: 0.0086\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 54]: 100%|██████████| 234/234 [00:13<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8920, Loss: 0.0088\n",
      "Val Acc: 0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 55]: 100%|██████████| 234/234 [00:12<00:00, 19.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8867, Loss: 0.0089\n",
      "Val Acc: 0.3475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 56]: 100%|██████████| 234/234 [00:08<00:00, 29.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8958, Loss: 0.0079\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 57]: 100%|██████████| 234/234 [00:08<00:00, 27.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9009, Loss: 0.0078\n",
      "Val Acc: 0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 58]: 100%|██████████| 234/234 [00:12<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9027, Loss: 0.0081\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 59]: 100%|██████████| 234/234 [00:12<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9086, Loss: 0.0073\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 60]: 100%|██████████| 234/234 [00:13<00:00, 17.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9017, Loss: 0.0080\n",
      "Val Acc: 0.4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 61]: 100%|██████████| 234/234 [00:12<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8971, Loss: 0.0079\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 62]: 100%|██████████| 234/234 [00:13<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9110, Loss: 0.0073\n",
      "Val Acc: 0.3162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 63]: 100%|██████████| 234/234 [00:12<00:00, 18.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9159, Loss: 0.0069\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 64]: 100%|██████████| 234/234 [00:11<00:00, 20.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9073, Loss: 0.0072\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 65]: 100%|██████████| 234/234 [00:08<00:00, 28.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9159, Loss: 0.0067\n",
      "Val Acc: 0.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 66]: 100%|██████████| 234/234 [00:09<00:00, 24.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9196, Loss: 0.0064\n",
      "Val Acc: 0.5675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 67]: 100%|██████████| 234/234 [00:13<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9159, Loss: 0.0064\n",
      "Val Acc: 0.5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 68]: 100%|██████████| 234/234 [00:12<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9086, Loss: 0.0076\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 69]: 100%|██████████| 234/234 [00:12<00:00, 18.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9175, Loss: 0.0067\n",
      "Val Acc: 0.8425\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 70]: 100%|██████████| 234/234 [00:13<00:00, 17.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9223, Loss: 0.0066\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 71]: 100%|██████████| 234/234 [00:12<00:00, 18.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9156, Loss: 0.0067\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 72]: 100%|██████████| 234/234 [00:12<00:00, 18.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9223, Loss: 0.0064\n",
      "Val Acc: 0.3175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 73]: 100%|██████████| 234/234 [00:09<00:00, 24.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9260, Loss: 0.0059\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 74]: 100%|██████████| 234/234 [00:07<00:00, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9226, Loss: 0.0063\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 75]: 100%|██████████| 234/234 [00:09<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9094, Loss: 0.0073\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 76]: 100%|██████████| 234/234 [00:14<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9306, Loss: 0.0055\n",
      "Val Acc: 0.4188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 77]: 100%|██████████| 234/234 [00:15<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9287, Loss: 0.0054\n",
      "Val Acc: 0.6925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 78]: 100%|██████████| 234/234 [00:13<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9293, Loss: 0.0057\n",
      "Val Acc: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 79]: 100%|██████████| 234/234 [00:12<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9255, Loss: 0.0055\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 80]: 100%|██████████| 234/234 [00:13<00:00, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9258, Loss: 0.0060\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 81]: 100%|██████████| 234/234 [00:12<00:00, 18.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9311, Loss: 0.0056\n",
      "Val Acc: 0.5763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 82]: 100%|██████████| 234/234 [00:10<00:00, 23.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9370, Loss: 0.0054\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 83]: 100%|██████████| 234/234 [00:11<00:00, 20.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9357, Loss: 0.0060\n",
      "Val Acc: 0.3650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 84]: 100%|██████████| 234/234 [00:12<00:00, 18.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9381, Loss: 0.0052\n",
      "Val Acc: 0.3337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 85]: 100%|██████████| 234/234 [00:13<00:00, 17.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9362, Loss: 0.0056\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 86]: 100%|██████████| 234/234 [00:12<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9389, Loss: 0.0053\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 87]: 100%|██████████| 234/234 [00:12<00:00, 18.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9362, Loss: 0.0057\n",
      "Val Acc: 0.4825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 88]: 100%|██████████| 234/234 [00:13<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9322, Loss: 0.0055\n",
      "Val Acc: 0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 89]: 100%|██████████| 234/234 [00:13<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9429, Loss: 0.0051\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 90]: 100%|██████████| 234/234 [00:13<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9440, Loss: 0.0050\n",
      "Val Acc: 0.8588\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 91]: 100%|██████████| 234/234 [00:08<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9483, Loss: 0.0047\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 92]: 100%|██████████| 234/234 [00:10<00:00, 21.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9515, Loss: 0.0044\n",
      "Val Acc: 0.4525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 93]: 100%|██████████| 234/234 [00:13<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9510, Loss: 0.0043\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 94]: 100%|██████████| 234/234 [00:12<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9408, Loss: 0.0050\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 95]: 100%|██████████| 234/234 [00:12<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9499, Loss: 0.0044\n",
      "Val Acc: 0.6488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 96]: 100%|██████████| 234/234 [00:12<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9486, Loss: 0.0044\n",
      "Val Acc: 0.4037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 97]: 100%|██████████| 234/234 [00:12<00:00, 18.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9285, Loss: 0.0058\n",
      "Val Acc: 0.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 98]: 100%|██████████| 234/234 [00:12<00:00, 18.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9456, Loss: 0.0050\n",
      "Val Acc: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 99]: 100%|██████████| 234/234 [00:13<00:00, 17.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9553, Loss: 0.0036\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 100]: 100%|██████████| 234/234 [00:08<00:00, 28.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9502, Loss: 0.0043\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 101]: 100%|██████████| 234/234 [00:08<00:00, 28.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9459, Loss: 0.0047\n",
      "Val Acc: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 102]: 100%|██████████| 234/234 [00:12<00:00, 19.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9330, Loss: 0.0055\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 103]: 100%|██████████| 234/234 [00:12<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9365, Loss: 0.0052\n",
      "Val Acc: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 104]: 100%|██████████| 234/234 [00:13<00:00, 17.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9526, Loss: 0.0038\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 105]: 100%|██████████| 234/234 [00:16<00:00, 14.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9408, Loss: 0.0050\n",
      "Val Acc: 0.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 106]: 100%|██████████| 234/234 [00:13<00:00, 16.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9400, Loss: 0.0049\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 107]: 100%|██████████| 234/234 [00:12<00:00, 18.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9515, Loss: 0.0040\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 108]: 100%|██████████| 234/234 [00:12<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9579, Loss: 0.0035\n",
      "Val Acc: 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 109]: 100%|██████████| 234/234 [00:07<00:00, 31.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9515, Loss: 0.0044\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 110]: 100%|██████████| 234/234 [00:07<00:00, 29.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9593, Loss: 0.0039\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 111]: 100%|██████████| 234/234 [00:11<00:00, 21.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9448, Loss: 0.0046\n",
      "Val Acc: 0.7113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 112]: 100%|██████████| 234/234 [00:12<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9547, Loss: 0.0040\n",
      "Val Acc: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 113]: 100%|██████████| 234/234 [00:13<00:00, 17.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9561, Loss: 0.0039\n",
      "Val Acc: 0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 114]: 100%|██████████| 234/234 [00:13<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9277, Loss: 0.0056\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 115]: 100%|██████████| 234/234 [00:13<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9558, Loss: 0.0040\n",
      "Val Acc: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 116]: 100%|██████████| 234/234 [00:13<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9469, Loss: 0.0045\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 117]: 100%|██████████| 234/234 [00:12<00:00, 18.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9518, Loss: 0.0044\n",
      "Val Acc: 0.6787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 118]: 100%|██████████| 234/234 [00:07<00:00, 29.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9477, Loss: 0.0042\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 119]: 100%|██████████| 234/234 [00:07<00:00, 29.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9531, Loss: 0.0042\n",
      "Val Acc: 0.5413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 120]: 100%|██████████| 234/234 [00:12<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9609, Loss: 0.0033\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 121]: 100%|██████████| 234/234 [00:13<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9582, Loss: 0.0037\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 122]: 100%|██████████| 234/234 [00:13<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9652, Loss: 0.0035\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 123]: 100%|██████████| 234/234 [00:13<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9483, Loss: 0.0044\n",
      "Val Acc: 0.7900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 124]: 100%|██████████| 234/234 [00:13<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9628, Loss: 0.0035\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 125]: 100%|██████████| 234/234 [00:12<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9622, Loss: 0.0034\n",
      "Val Acc: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 126]: 100%|██████████| 234/234 [00:13<00:00, 17.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9553, Loss: 0.0036\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 127]: 100%|██████████| 234/234 [00:08<00:00, 29.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9633, Loss: 0.0034\n",
      "Val Acc: 0.6525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 128]: 100%|██████████| 234/234 [00:07<00:00, 31.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9665, Loss: 0.0034\n",
      "Val Acc: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 129]: 100%|██████████| 234/234 [00:11<00:00, 20.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9609, Loss: 0.0033\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 130]: 100%|██████████| 234/234 [00:13<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9569, Loss: 0.0037\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 131]: 100%|██████████| 234/234 [00:13<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9601, Loss: 0.0035\n",
      "Val Acc: 0.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 132]: 100%|██████████| 234/234 [00:13<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9689, Loss: 0.0027\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 133]: 100%|██████████| 234/234 [00:12<00:00, 18.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9689, Loss: 0.0031\n",
      "Val Acc: 0.8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 134]: 100%|██████████| 234/234 [00:13<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9614, Loss: 0.0035\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 135]: 100%|██████████| 234/234 [00:13<00:00, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9654, Loss: 0.0031\n",
      "Val Acc: 0.4238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 136]: 100%|██████████| 234/234 [00:07<00:00, 29.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9464, Loss: 0.0048\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 137]: 100%|██████████| 234/234 [00:07<00:00, 29.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9595, Loss: 0.0037\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 138]: 100%|██████████| 234/234 [00:13<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9579, Loss: 0.0037\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 139]: 100%|██████████| 234/234 [00:13<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9574, Loss: 0.0036\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 140]: 100%|██████████| 234/234 [00:13<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9601, Loss: 0.0033\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 141]: 100%|██████████| 234/234 [00:13<00:00, 17.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9652, Loss: 0.0031\n",
      "Val Acc: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 142]: 100%|██████████| 234/234 [00:13<00:00, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9628, Loss: 0.0035\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 143]: 100%|██████████| 234/234 [00:13<00:00, 17.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9686, Loss: 0.0027\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 144]: 100%|██████████| 234/234 [00:12<00:00, 18.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9638, Loss: 0.0034\n",
      "Val Acc: 0.3812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 145]: 100%|██████████| 234/234 [00:08<00:00, 27.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9646, Loss: 0.0031\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 146]: 100%|██████████| 234/234 [00:07<00:00, 30.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9625, Loss: 0.0034\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 147]: 100%|██████████| 234/234 [00:13<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9641, Loss: 0.0035\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 148]: 100%|██████████| 234/234 [00:13<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9705, Loss: 0.0029\n",
      "Val Acc: 0.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 149]: 100%|██████████| 234/234 [00:13<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9703, Loss: 0.0027\n",
      "Val Acc: 0.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 150]: 100%|██████████| 234/234 [00:13<00:00, 17.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9665, Loss: 0.0035\n",
      "Val Acc: 0.6362\n",
      "\n",
      "📊 Test Evaluation:\n",
      "✅ Accuracy: 88.50% | AUC: 0.9253 | F1: 0.9148\n",
      "Confusion Matrix: [[214  61]\n",
      " [ 31 494]]\n"
     ]
    }
   ],
   "source": [
    "# ✅ Test Accuracy: 88.50% | AUC: 0.9253 | F1: 0.9148\n",
    "# Confusion Matrix: [[214  61]\n",
    "#  [ 31 494]]\n",
    "#r18_cbam_mga_aug_focal150.pth\n",
    "\n",
    "# ✅ 전체코드: ResNet18 + CBAM + MGA + Lambda Scheduling\n",
    "\n",
    "# ✅ 추천 실험 조합 포함:\n",
    "# - Weighted FocalLoss (gamma=2.0)\n",
    "# - Data Aug: Resize + Flip + Rotate(15) + BrightnessContrast + Dropout\n",
    "# - Evaluation Metrics + CSV 저장 + tqdm\n",
    "\n",
    "import os, re, numpy as np, torch, gc, csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from datetime import datetime\n",
    "\n",
    "# 디바이스\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 경로 & 하이퍼파라미터\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "batch_size = 16\n",
    "num_epochs = 150\n",
    "learning_rate = 1e-4\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "\n",
    "# FocalLoss 구현\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = F.log_softmax(input, dim=1)\n",
    "        ce_loss = F.nll_loss(logp, target, weight=self.weight, reduction='none')\n",
    "        p = torch.exp(-ce_loss)\n",
    "        return ((1 - p) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "# Transform (Albumentations)\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.CoarseDropout(p=0.4, max_holes=1, max_height=32, max_width=32),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# -------------------- Bounding Box를 Binary Mask로 --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    # bbox_list : 한 이미지에 들어있는 bounding box 리스트\n",
    "    # image_size : 출력할 마스크 크기. 보통 이미지와 동일한 (height, width) -> 디폴트는 224x224\n",
    "    # bbox들을 binary mask로 바꿔주는 함수\n",
    "    masks = []  # 여러 개의 bbox가 들어오니까, 각각의 마스크를 하나씩 리스트에 쌓기 위한 빈 리스트\n",
    "    for bbox in bbox_list:  # bbox_list를 하나씩 돌면서 처리 -> [x_min, y_min, x_max, y_max]네 좌표로 구성된 하나의 사각형 영역 \n",
    "        mask = np.zeros(image_size, dtype=np.float32)   # 224x224짜리 0으로 꽉 찬 2D 배열을 하나 생성\n",
    "        # 배경이 흰 종이를 만드는 느낌으로 만들고, 사각 영역만 1로 덧칠할거임\n",
    "        x_min, y_min, x_max, y_max = bbox   # 각 bbox의 네 좌표값을 각각 변수로 언팩. -> 마스크의 해당 영역에 사각형을 칠하기 위해서\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0    # y_min, y_max, x_min, x_max까지의 범위에 1.0을 채워 넣음\n",
    "        # -> 마스크에서 bbox에 해당하는 사각형 영역만 1(foreground)로 표시됨. 나머진 여전히 0(background)\n",
    "        masks.append(mask)  # 지금 만든 마스크(2D 배열)를 리스트에 추가 -> [mask1, mask2, ...]이렇게 쌓임\n",
    "\n",
    "    masks = np.stack(masks) # 리스트를 하나의 3D 배열로 합침 -> shape : [N, H, W] -> N은 bbox 개수\n",
    "    masks = np.expand_dims(masks, axis=1)   # 텐서 shape을 [N, 1, H, W]로 바꿈\n",
    "    # PyTorch 모델에서 기대하는 (batch x channel x height x width) 포맷 맞추기\n",
    "\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "    # numpy 배열을 PyTorch 텐서로 변환해서 리턴\n",
    "\n",
    "    # 한 bbox → 하나의 마스크 → 여러 개면 쌓아서 batch 형태로\n",
    "# -------------------- Bounding Box CSV 로드 --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    # csv_path : bounding box 정보가 들어있는 CSV 파일 경로\n",
    "    # 반환값 : {filename:[bbox1, bbox2, ...]} 형태의 딕셔너리\n",
    "    df = pd.read_csv(csv_path)  # CSV파일을 pandas DataFrame으로 읽어옴\n",
    "    bbox_dict = {}\n",
    "    # key : 슬라이스 파일 이름 (ex. \"LIDC-IDRI-1012_slice0004.npy\")\n",
    "    # value : 해당 슬라이스에 존재하는 bbox들의 리스트\n",
    "    for _, row in df.iterrows():    # DataFrame의 모든 행(row)를 하나씩 순회\n",
    "        # row는 한 줄(=한 bbox)의 정보를 담고 있음\n",
    "\n",
    "        pid = row['pid']    # 환자 ID (예: \"LIDC-IDRI-1012\") -> 이미지 이름 구성 요소\n",
    "        slice_str = row['slice']    # 슬라이스 정보가 들어있는 문자열 (예: \"slice_0039\")\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])  # re.findall()로 문자열에서 숫자만 뽑아냄\n",
    "        # \"slice_0039\" -> ['0039'] -> [0] -> 39 (슬라이스 번호를 정수로 추출함)\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"   # 파일명 구성 (예: \"LIDC-IDRI-1012_slice0039.npy\")\n",
    "        # {:04d}는 4자리 정수로 만들고 빈자리는 0으로 채워줌 (39 -> 0039)\n",
    "        bbox = eval(row['bb'])  # row['bb']는 문자열 형태의 bbox (예: \"[20, 30, 80, 100]\")\n",
    "        # eval()을 써서 문자열을 리스트로 바꿔줌\n",
    "        # 주의 : 보안 상 위험할 수 있는 함수지만, 여긴 내부 데이터라 사용중\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)    # fname이라는 key가 딕셔너리에 없으면 []로 초기화하고,\n",
    "        # 거기에 bbox를 append -> 슬라이스 하나에 bbox 여러개 있어도 전부 리스트로 모아줌\n",
    "    return bbox_dict    # 최종적으로 {filename: [bbox1, bbox2, ...]} 형태의 딕셔너리 반환\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "# 실제로 csv_path에 있는 정보를 불러와서 bbox_dict에 저장함\n",
    "# 이걸 나주에 Dataset 클래스에서 fname 기준을 꺼내쓰게 됨\n",
    "\n",
    "# -------------------- 라벨 추출 --------------------\n",
    "def extract_label_from_filename(fname): # fname : 파일 이름 (예: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # 이 이름에서 malignancy score(악성도 점수)를 추출해서 라벨로 변환\n",
    "    try:    # 파일명이 이상하거나 에러나면 except로 빠져나가서 None 반환함 (안전장치)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # 파일명에서 _ 제외하고 나머지 것들 중에 마지막에꺼를 가져와서 .npy를 \"\" 이렇게 공백으로 처리함\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- 이게 malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # 라벨 결정 로직으로\n",
    "        # score == 3 -> 중립 -> None 반환 -> 학습에서 제외\n",
    "        # score >= 4 -> 암(양성) -> 1\n",
    "        # score <= 2 -> 정상(음성) -> 0\n",
    "        # int(score >= 4)는 파이썬에서 True -> 1\n",
    "        # False -> 0 이니깐 자동으로 라벨이 됨\n",
    "    except:\n",
    "        return None\n",
    "        # 혹시 split이나 replace, int 변환이 실패하면 그냥 None 반환하고 무시\n",
    "\n",
    "# Dataset (Albumentations 적용)\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        fname = os.path.basename(f)\n",
    "\n",
    "        img = np.load(f)  # 원래 이미지\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.0\n",
    "        img = img.astype(np.float32)\n",
    "        img = np.expand_dims(img, axis=-1)  # (H, W, 1)\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # === (1) 원본 이미지와 같은 크기로 마스크 생성 ===\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(h, w))[0].numpy()\n",
    "        else:\n",
    "            mask = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "        mask = np.expand_dims(mask, axis=-1).astype(np.float32)  # (H, W, 1)\n",
    "\n",
    "        # === (2) Albumentations transform: 같이 resize 시킴 ===\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "        else:\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "            mask = torch.tensor(mask.squeeze(), dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "# CBAM + ResNet18 정의\n",
    "# -------------------- CBAM 정의 (MGA 포함) --------------------\n",
    "# 2 Step : Channel Attention(어떤 채널에 집중할지) * Spatial Attention(어디에 집중할지) = 최종 Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # 입력 feature map의 채널별 중요도를 계산해서 강조함\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : 입력 채널 수\n",
    "        # ratio : 중간 채널 축소 비율. 기본 1/16으로 bottlenck 구성\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP 역할을 하는 1x1 conv 블록 -> 채널 압축 -> 비선형 -> 복원 (shared는 avg/max 둘다에서 같이 씀)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # 평균 풀링 / 최대 풀링으로 두가지 전역 정보를 추출\n",
    "        # 마지막 sigmoid는 attention weight로 스케일링\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max 풀링 경과를 각각 shape MLP에 통과시키고, 더한 후 sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> 채널마다 중요도 weight를 곱하게 됨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # 공간적으로 어디에 집중할지를 결정 -> 각 채널 내부에서 중요한 위치 찾기\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # 채널 차원은 평균, 최대 두 개만 써서 concat\n",
    "    # 그걸 1채널로 줄여주는 conv\n",
    "    # 커널 크기 k=7이면 넓은 영역까지 감지 가능\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # 입력 feature map에서 :\n",
    "    # 평균, 최대값을 각 spatial 위치별로 구함 -> [B, 1, H, W] 두 개\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> 위치별 중요도 map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttention을 내부에 선언\n",
    "    # MGA를 위해 마지막 attention map을 저장하는 변수 포함\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # 채널 중요도 -> 곱함\n",
    "    # 위치 중요도 -> 곱함\n",
    "    # 둘 다 반영된 최종 feature map 리턴\n",
    "\n",
    "\n",
    "\n",
    "# 학습\n",
    "\n",
    "def run():\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_loader = DataLoader(CTDataset(train_files, train_labels, transform=train_transform), batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(CTDataset(val_files, val_labels, transform=val_transform), batch_size=batch_size)\n",
    "    test_loader = DataLoader(CTDataset(test_files, test_labels, transform=val_transform), batch_size=batch_size)\n",
    "\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = FocalLoss(weight=torch.tensor([0.65, 0.35], device=device), gamma=2.0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    save_path = os.path.join(\"pth\", \"r18_cbam_mga_aug_focal150.pth\")\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for imgs, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            imgs, labels, masks = imgs.to(device), labels.to(device), masks.to(device)\n",
    "            outputs = model(imgs)\n",
    "            ce_loss = criterion(outputs, labels)\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # [B, 1, H, W]\n",
    "            attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)  # [B, 224, 224]\n",
    "            masks = masks.view(masks.size(0), 224, 224)  # 강제로 [B, 224, 224]로 reshape\n",
    "            mga_loss = F.mse_loss(attn_map, masks.float())\n",
    "            loss = ce_loss + lambda_mga * mga_loss\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        print(f\"Train Acc: {correct/total:.4f}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        model.eval(); val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels, _ in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        val_acc = val_correct / val_total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"✅ Saved best model!\")\n",
    "\n",
    "    # ---------------- 테스트 ----------------\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, _ in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true); y_pred = np.array(y_pred); y_probs = np.array(y_probs)\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\n📊 Test Evaluation:\\n✅ Accuracy: {acc*100:.2f}% | AUC: {auc:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\", cm)\n",
    "\n",
    "    metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "    with open(\"logs/final_test_metrics.csv\", 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=metrics.keys())\n",
    "        if not os.path.exists(\"logs/final_test_metrics.csv\"):\n",
    "            writer.writeheader()\n",
    "        writer.writerow(metrics)\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1974167/24495587.py:42: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(\n",
      "[Epoch 1]: 100%|██████████| 467/467 [00:15<00:00, 29.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 65.2465, Loss: 0.6626\n",
      "[Epoch 1] lambda_mga: 0.1000\n",
      "Val Acc: 0.6675\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|██████████| 467/467 [00:15<00:00, 29.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 65.1661, Loss: 0.6476\n",
      "[Epoch 2] lambda_mga: 0.1040\n",
      "Val Acc: 0.6887\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|██████████| 467/467 [00:15<00:00, 30.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 65.8628, Loss: 0.6447\n",
      "[Epoch 3] lambda_mga: 0.1080\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: 100%|██████████| 467/467 [00:14<00:00, 31.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 66.6399, Loss: 0.6412\n",
      "[Epoch 4] lambda_mga: 0.1120\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: 100%|██████████| 467/467 [00:15<00:00, 29.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 66.2379, Loss: 0.6384\n",
      "[Epoch 5] lambda_mga: 0.1160\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6]: 100%|██████████| 467/467 [00:15<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 66.2915, Loss: 0.6366\n",
      "[Epoch 6] lambda_mga: 0.1200\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7]: 100%|██████████| 467/467 [00:15<00:00, 30.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 67.6045, Loss: 0.6311\n",
      "[Epoch 7] lambda_mga: 0.1240\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8]: 100%|██████████| 467/467 [00:15<00:00, 30.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 67.4705, Loss: 0.6256\n",
      "[Epoch 8] lambda_mga: 0.1280\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9]: 100%|██████████| 467/467 [00:10<00:00, 46.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 67.8457, Loss: 0.6211\n",
      "[Epoch 9] lambda_mga: 0.1320\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10]: 100%|██████████| 467/467 [00:10<00:00, 46.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 68.2476, Loss: 0.6190\n",
      "[Epoch 10] lambda_mga: 0.1360\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 11]: 100%|██████████| 467/467 [00:15<00:00, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 69.6945, Loss: 0.6101\n",
      "[Epoch 11] lambda_mga: 0.1400\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 12]: 100%|██████████| 467/467 [00:15<00:00, 29.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 70.4984, Loss: 0.6013\n",
      "[Epoch 12] lambda_mga: 0.1440\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 13]: 100%|██████████| 467/467 [00:15<00:00, 30.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 70.9271, Loss: 0.5925\n",
      "[Epoch 13] lambda_mga: 0.1480\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 14]: 100%|██████████| 467/467 [00:15<00:00, 30.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 71.3023, Loss: 0.5832\n",
      "[Epoch 14] lambda_mga: 0.1520\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 15]: 100%|██████████| 467/467 [00:15<00:00, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 73.7406, Loss: 0.5655\n",
      "[Epoch 15] lambda_mga: 0.1560\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 16]: 100%|██████████| 467/467 [00:15<00:00, 31.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 74.6249, Loss: 0.5557\n",
      "[Epoch 16] lambda_mga: 0.1600\n",
      "Val Acc: 0.3175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17]: 100%|██████████| 467/467 [00:15<00:00, 30.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 76.6077, Loss: 0.5363\n",
      "[Epoch 17] lambda_mga: 0.1640\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 18]: 100%|██████████| 467/467 [00:15<00:00, 30.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 78.5102, Loss: 0.5172\n",
      "[Epoch 18] lambda_mga: 0.1680\n",
      "Val Acc: 0.6412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 19]: 100%|██████████| 467/467 [00:13<00:00, 34.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 79.4748, Loss: 0.4997\n",
      "[Epoch 19] lambda_mga: 0.1720\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 20]: 100%|██████████| 467/467 [00:10<00:00, 45.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 81.3773, Loss: 0.4790\n",
      "[Epoch 20] lambda_mga: 0.1760\n",
      "Val Acc: 0.3362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 21]: 100%|██████████| 467/467 [00:10<00:00, 43.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 82.1543, Loss: 0.4692\n",
      "[Epoch 21] lambda_mga: 0.1800\n",
      "Val Acc: 0.6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 22]: 100%|██████████| 467/467 [00:15<00:00, 31.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 83.6817, Loss: 0.4481\n",
      "[Epoch 22] lambda_mga: 0.1840\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 23]: 100%|██████████| 467/467 [00:15<00:00, 30.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 84.4855, Loss: 0.4397\n",
      "[Epoch 23] lambda_mga: 0.1880\n",
      "Val Acc: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 24]: 100%|██████████| 467/467 [00:15<00:00, 30.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 85.9593, Loss: 0.4178\n",
      "[Epoch 24] lambda_mga: 0.1920\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 25]: 100%|██████████| 467/467 [00:15<00:00, 30.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 86.5756, Loss: 0.4155\n",
      "[Epoch 25] lambda_mga: 0.1960\n",
      "Val Acc: 0.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 26]: 100%|██████████| 467/467 [00:15<00:00, 31.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 86.2272, Loss: 0.4088\n",
      "[Epoch 26] lambda_mga: 0.2000\n",
      "Val Acc: 0.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 27]: 100%|██████████| 467/467 [00:15<00:00, 30.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 88.1565, Loss: 0.3864\n",
      "[Epoch 27] lambda_mga: 0.2040\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 28]: 100%|██████████| 467/467 [00:14<00:00, 31.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 88.5048, Loss: 0.3826\n",
      "[Epoch 28] lambda_mga: 0.2080\n",
      "Val Acc: 0.7050\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 29]: 100%|██████████| 467/467 [00:15<00:00, 30.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 90.0054, Loss: 0.3671\n",
      "[Epoch 29] lambda_mga: 0.2120\n",
      "Val Acc: 0.7362\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 30]: 100%|██████████| 467/467 [00:11<00:00, 39.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.6131, Loss: 0.3476\n",
      "[Epoch 30] lambda_mga: 0.2160\n",
      "Val Acc: 0.6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 31]: 100%|██████████| 467/467 [00:10<00:00, 42.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.8006, Loss: 0.3463\n",
      "[Epoch 31] lambda_mga: 0.2200\n",
      "Val Acc: 0.3488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 32]: 100%|██████████| 467/467 [00:12<00:00, 37.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.9882, Loss: 0.3368\n",
      "[Epoch 32] lambda_mga: 0.2240\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 33]: 100%|██████████| 467/467 [00:15<00:00, 31.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.0954, Loss: 0.3332\n",
      "[Epoch 33] lambda_mga: 0.2280\n",
      "Val Acc: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 34]: 100%|██████████| 467/467 [00:15<00:00, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.7653, Loss: 0.3254\n",
      "[Epoch 34] lambda_mga: 0.2320\n",
      "Val Acc: 0.4163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 35]: 100%|██████████| 467/467 [00:15<00:00, 30.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.3012, Loss: 0.3175\n",
      "[Epoch 35] lambda_mga: 0.2360\n",
      "Val Acc: 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 36]: 100%|██████████| 467/467 [00:15<00:00, 30.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.5959, Loss: 0.3152\n",
      "[Epoch 36] lambda_mga: 0.2400\n",
      "Val Acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 37]: 100%|██████████| 467/467 [00:15<00:00, 30.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.3730, Loss: 0.3054\n",
      "[Epoch 37] lambda_mga: 0.2440\n",
      "Val Acc: 0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 38]: 100%|██████████| 467/467 [00:15<00:00, 30.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.5691, Loss: 0.3117\n",
      "[Epoch 38] lambda_mga: 0.2480\n",
      "Val Acc: 0.7400\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 39]: 100%|██████████| 467/467 [00:15<00:00, 31.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.9175, Loss: 0.3085\n",
      "[Epoch 39] lambda_mga: 0.2520\n",
      "Val Acc: 0.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 40]: 100%|██████████| 467/467 [00:14<00:00, 31.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.5606, Loss: 0.3028\n",
      "[Epoch 40] lambda_mga: 0.2560\n",
      "Val Acc: 0.6850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 41]: 100%|██████████| 467/467 [00:10<00:00, 46.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.0429, Loss: 0.2940\n",
      "[Epoch 41] lambda_mga: 0.2600\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 42]: 100%|██████████| 467/467 [00:09<00:00, 47.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.0965, Loss: 0.2864\n",
      "[Epoch 42] lambda_mga: 0.2640\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 43]: 100%|██████████| 467/467 [00:14<00:00, 31.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.3912, Loss: 0.2815\n",
      "[Epoch 43] lambda_mga: 0.2680\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 44]: 100%|██████████| 467/467 [00:15<00:00, 29.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.9357, Loss: 0.2897\n",
      "[Epoch 44] lambda_mga: 0.2720\n",
      "Val Acc: 0.6737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 45]: 100%|██████████| 467/467 [00:15<00:00, 30.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.0429, Loss: 0.2890\n",
      "[Epoch 45] lambda_mga: 0.2760\n",
      "Val Acc: 0.8662\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 46]: 100%|██████████| 467/467 [00:15<00:00, 30.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.1768, Loss: 0.2852\n",
      "[Epoch 46] lambda_mga: 0.2800\n",
      "Val Acc: 0.6787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 47]: 100%|██████████| 467/467 [00:15<00:00, 30.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0611, Loss: 0.2754\n",
      "[Epoch 47] lambda_mga: 0.2840\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 48]: 100%|██████████| 467/467 [00:15<00:00, 30.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.5788, Loss: 0.2792\n",
      "[Epoch 48] lambda_mga: 0.2880\n",
      "Val Acc: 0.5950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 49]: 100%|██████████| 467/467 [00:14<00:00, 31.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0611, Loss: 0.2754\n",
      "[Epoch 49] lambda_mga: 0.2920\n",
      "Val Acc: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 50]: 100%|██████████| 467/467 [00:15<00:00, 30.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0879, Loss: 0.2748\n",
      "[Epoch 50] lambda_mga: 0.2960\n",
      "Val Acc: 0.6987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 51]: 100%|██████████| 467/467 [00:12<00:00, 36.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7846, Loss: 0.2645\n",
      "[Epoch 51] lambda_mga: 0.3000\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 52]: 100%|██████████| 467/467 [00:10<00:00, 43.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.2755, Loss: 0.2662\n",
      "[Epoch 52] lambda_mga: 0.3040\n",
      "Val Acc: 0.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 53]: 100%|██████████| 467/467 [00:11<00:00, 39.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3826, Loss: 0.2669\n",
      "[Epoch 53] lambda_mga: 0.3080\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 54]: 100%|██████████| 467/467 [00:16<00:00, 28.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.4094, Loss: 0.2689\n",
      "[Epoch 54] lambda_mga: 0.3120\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 55]: 100%|██████████| 467/467 [00:15<00:00, 30.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7578, Loss: 0.2607\n",
      "[Epoch 55] lambda_mga: 0.3160\n",
      "Val Acc: 0.3425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 56]: 100%|██████████| 467/467 [00:15<00:00, 30.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.4898, Loss: 0.2636\n",
      "[Epoch 56] lambda_mga: 0.3200\n",
      "Val Acc: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 57]: 100%|██████████| 467/467 [00:15<00:00, 30.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.5166, Loss: 0.2648\n",
      "[Epoch 57] lambda_mga: 0.3240\n",
      "Val Acc: 0.7087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 58]: 100%|██████████| 467/467 [00:15<00:00, 30.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9721, Loss: 0.2568\n",
      "[Epoch 58] lambda_mga: 0.3280\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 59]: 100%|██████████| 467/467 [00:15<00:00, 30.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9721, Loss: 0.2548\n",
      "[Epoch 59] lambda_mga: 0.3320\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 60]: 100%|██████████| 467/467 [00:15<00:00, 30.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9721, Loss: 0.2571\n",
      "[Epoch 60] lambda_mga: 0.3360\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 61]: 100%|██████████| 467/467 [00:13<00:00, 34.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.5434, Loss: 0.2634\n",
      "[Epoch 61] lambda_mga: 0.3400\n",
      "Val Acc: 0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 62]: 100%|██████████| 467/467 [00:11<00:00, 41.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7846, Loss: 0.2562\n",
      "[Epoch 62] lambda_mga: 0.3440\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 63]: 100%|██████████| 467/467 [00:10<00:00, 42.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7578, Loss: 0.2571\n",
      "[Epoch 63] lambda_mga: 0.3480\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 64]: 100%|██████████| 467/467 [00:16<00:00, 29.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.0525, Loss: 0.2522\n",
      "[Epoch 64] lambda_mga: 0.3520\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 65]: 100%|██████████| 467/467 [00:16<00:00, 28.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.3473, Loss: 0.2473\n",
      "[Epoch 65] lambda_mga: 0.3560\n",
      "Val Acc: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 66]: 100%|██████████| 467/467 [00:15<00:00, 29.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6420, Loss: 0.2523\n",
      "[Epoch 66] lambda_mga: 0.3600\n",
      "Val Acc: 0.8425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 67]: 100%|██████████| 467/467 [00:15<00:00, 29.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.1597, Loss: 0.2574\n",
      "[Epoch 67] lambda_mga: 0.3640\n",
      "Val Acc: 0.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 68]: 100%|██████████| 467/467 [00:15<00:00, 30.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.2937, Loss: 0.2475\n",
      "[Epoch 68] lambda_mga: 0.3680\n",
      "Val Acc: 0.4138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 69]: 100%|██████████| 467/467 [00:15<00:00, 29.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5884, Loss: 0.2453\n",
      "[Epoch 69] lambda_mga: 0.3720\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 70]: 100%|██████████| 467/467 [00:15<00:00, 30.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6420, Loss: 0.2440\n",
      "[Epoch 70] lambda_mga: 0.3760\n",
      "Val Acc: 0.6787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 71]: 100%|██████████| 467/467 [00:14<00:00, 32.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4544, Loss: 0.2468\n",
      "[Epoch 71] lambda_mga: 0.3800\n",
      "Val Acc: 0.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 72]: 100%|██████████| 467/467 [00:11<00:00, 42.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8564, Loss: 0.2409\n",
      "[Epoch 72] lambda_mga: 0.3840\n",
      "Val Acc: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 73]: 100%|██████████| 467/467 [00:10<00:00, 43.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6152, Loss: 0.2444\n",
      "[Epoch 73] lambda_mga: 0.3880\n",
      "Val Acc: 0.3987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 74]: 100%|██████████| 467/467 [00:16<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7760, Loss: 0.2419\n",
      "[Epoch 74] lambda_mga: 0.3920\n",
      "Val Acc: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 75]: 100%|██████████| 467/467 [00:16<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7492, Loss: 0.2451\n",
      "[Epoch 75] lambda_mga: 0.3960\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 76]: 100%|██████████| 467/467 [00:15<00:00, 30.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7224, Loss: 0.2405\n",
      "[Epoch 76] lambda_mga: 0.4000\n",
      "Val Acc: 0.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 77]: 100%|██████████| 467/467 [00:15<00:00, 29.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.3387, Loss: 0.2357\n",
      "[Epoch 77] lambda_mga: 0.4040\n",
      "Val Acc: 0.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 78]: 100%|██████████| 467/467 [00:15<00:00, 29.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.1597, Loss: 0.2482\n",
      "[Epoch 78] lambda_mga: 0.4080\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 79]: 100%|██████████| 467/467 [00:15<00:00, 30.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8564, Loss: 0.2392\n",
      "[Epoch 79] lambda_mga: 0.4120\n",
      "Val Acc: 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 80]: 100%|██████████| 467/467 [00:15<00:00, 29.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8028, Loss: 0.2394\n",
      "[Epoch 80] lambda_mga: 0.4160\n",
      "Val Acc: 0.6625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 81]: 100%|██████████| 467/467 [00:13<00:00, 33.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5080, Loss: 0.2417\n",
      "[Epoch 81] lambda_mga: 0.4200\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 82]: 100%|██████████| 467/467 [00:11<00:00, 41.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8296, Loss: 0.2372\n",
      "[Epoch 82] lambda_mga: 0.4240\n",
      "Val Acc: 0.3362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 83]: 100%|██████████| 467/467 [00:11<00:00, 41.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8296, Loss: 0.2380\n",
      "[Epoch 83] lambda_mga: 0.4280\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 84]: 100%|██████████| 467/467 [00:15<00:00, 29.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4812, Loss: 0.2453\n",
      "[Epoch 84] lambda_mga: 0.4320\n",
      "Val Acc: 0.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 85]: 100%|██████████| 467/467 [00:16<00:00, 28.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.2047, Loss: 0.2331\n",
      "[Epoch 85] lambda_mga: 0.4360\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 86]: 100%|██████████| 467/467 [00:15<00:00, 29.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.9904, Loss: 0.2363\n",
      "[Epoch 86] lambda_mga: 0.4400\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 87]: 100%|██████████| 467/467 [00:15<00:00, 30.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8564, Loss: 0.2376\n",
      "[Epoch 87] lambda_mga: 0.4440\n",
      "Val Acc: 0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 88]: 100%|██████████| 467/467 [00:15<00:00, 29.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.6602, Loss: 0.2283\n",
      "[Epoch 88] lambda_mga: 0.4480\n",
      "Val Acc: 0.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 89]: 100%|██████████| 467/467 [00:15<00:00, 30.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.2047, Loss: 0.2329\n",
      "[Epoch 89] lambda_mga: 0.4520\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 90]: 100%|██████████| 467/467 [00:15<00:00, 29.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8296, Loss: 0.2409\n",
      "[Epoch 90] lambda_mga: 0.4560\n",
      "Val Acc: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 91]: 100%|██████████| 467/467 [00:13<00:00, 34.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.4727, Loss: 0.2324\n",
      "[Epoch 91] lambda_mga: 0.4600\n",
      "Val Acc: 0.5988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 92]: 100%|██████████| 467/467 [00:11<00:00, 41.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.9904, Loss: 0.2359\n",
      "[Epoch 92] lambda_mga: 0.4640\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 93]: 100%|██████████| 467/467 [00:11<00:00, 39.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.4727, Loss: 0.2285\n",
      "[Epoch 93] lambda_mga: 0.4680\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 94]: 100%|██████████| 467/467 [00:16<00:00, 27.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.6066, Loss: 0.2291\n",
      "[Epoch 94] lambda_mga: 0.4720\n",
      "Val Acc: 0.5275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 95]: 100%|██████████| 467/467 [00:16<00:00, 28.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.1511, Loss: 0.2345\n",
      "[Epoch 95] lambda_mga: 0.4760\n",
      "Val Acc: 0.6550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 96]: 100%|██████████| 467/467 [00:15<00:00, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.1779, Loss: 0.2344\n",
      "[Epoch 96] lambda_mga: 0.4800\n",
      "Val Acc: 0.4462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 97]: 100%|██████████| 467/467 [00:15<00:00, 29.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.9100, Loss: 0.2367\n",
      "[Epoch 97] lambda_mga: 0.4840\n",
      "Val Acc: 0.6025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 98]: 100%|██████████| 467/467 [00:14<00:00, 31.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.9904, Loss: 0.2361\n",
      "[Epoch 98] lambda_mga: 0.4880\n",
      "Val Acc: 0.8237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 99]: 100%|██████████| 467/467 [00:14<00:00, 32.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.6066, Loss: 0.2257\n",
      "[Epoch 99] lambda_mga: 0.4920\n",
      "Val Acc: 0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 100]: 100%|██████████| 467/467 [00:14<00:00, 32.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.1779, Loss: 0.2302\n",
      "[Epoch 100] lambda_mga: 0.4960\n",
      "Val Acc: 0.5413\n",
      "\n",
      "📊 Test Evaluation:\n",
      "✅ Test Accuracy         : 87.12%\n",
      "🎯 AUC                   : 0.9110\n",
      "📌 Precision             : 0.9011\n",
      "📌 Recall (Sensitivity)  : 0.9029\n",
      "📌 Specificity           : 0.8109\n",
      "📌 F1 Score              : 0.9020\n",
      "📌 Balanced Accuracy     : 0.8569\n",
      "📌 MCC                   : 0.7144\n",
      "\n",
      "📌 Confusion Matrix:\n",
      "[[223  52]\n",
      " [ 51 474]]\n",
      "\n",
      "📁 테스트 지표 저장 완료: logs/final_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# ✅ Test Accuracy         : 87.12%\n",
    "# 🎯 AUC                   : 0.9110\n",
    "# 📌 Precision             : 0.9011\n",
    "# 📌 Recall (Sensitivity)  : 0.9029\n",
    "# 📌 Specificity           : 0.8109\n",
    "# 📌 F1 Score              : 0.9020\n",
    "# 📌 Balanced Accuracy     : 0.8569\n",
    "# 📌 MCC                   : 0.7144\n",
    "\n",
    "# 📌 Confusion Matrix:\n",
    "# [[223  52]\n",
    "#  [ 51 474]]\n",
    "# r18_cbam_mga_aug_lr4_ep100_label1.pth\n",
    "# 전체코드: ResNet18 + CBAM + MGA Loss + Lambda Scheduling (Label Smoothing + )\n",
    "\n",
    "import os, re, numpy as np, torch, gc\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "\n",
    "# -------------------- 디바이스 설정 --------------------\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- 하이퍼파라미터 설정 --------------------\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# lambda MGA 스케줄 설정\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "total_epochs = num_epochs\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=10, p=0.5),\n",
    "    A.CoarseDropout(\n",
    "        max_holes=1, max_height=32, max_width=32, min_holes=1, \n",
    "        min_height=16, min_width=16, fill_value=0, p=0.5),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        fname = os.path.basename(file_path)\n",
    "\n",
    "        img = np.load(file_path)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(img.shape[0], img.shape[1])).sum(axis=0)\n",
    "        else:\n",
    "            mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img, mask=mask)\n",
    "            img = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "        else:\n",
    "            img = torch.tensor(img).unsqueeze(0)\n",
    "            mask = torch.tensor(mask)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "# -------------------- Bounding Box Mask --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    masks = []\n",
    "    for bbox in bbox_list:\n",
    "        mask = np.zeros(image_size, dtype=np.float32)\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0\n",
    "        masks.append(mask)\n",
    "    masks = np.stack(masks)\n",
    "    masks = np.expand_dims(masks, axis=1)\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)                         # 파이썬 random\n",
    "    np.random.seed(seed)                      # numpy\n",
    "    torch.manual_seed(seed)                   # torch CPU\n",
    "    torch.cuda.manual_seed(seed)              # torch GPU\n",
    "    torch.cuda.manual_seed_all(seed)          # multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # 연산 동일하게\n",
    "    torch.backends.cudnn.benchmark = False    # 연산 속도 최적화 OFF (같은 연산 보장)\n",
    "\n",
    "# -------------------- Bounding Box CSV --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    bbox_dict = {}\n",
    "    for _, row in df.iterrows():\n",
    "        pid = row['pid']\n",
    "        slice_idx = int(re.findall(r'\\d+', str(row['slice']))[0])\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"\n",
    "        bbox = eval(row['bb'])\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)\n",
    "    return bbox_dict\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "\n",
    "def extract_label_from_filename(fname):\n",
    "    try:\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# -------------------- 라벨 추출 --------------------\n",
    "def extract_label_from_filename(fname): # fname : 파일 이름 (예: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # 이 이름에서 malignancy score(악성도 점수)를 추출해서 라벨로 변환\n",
    "    try:    # 파일명이 이상하거나 에러나면 except로 빠져나가서 None 반환함 (안전장치)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # 파일명에서 _ 제외하고 나머지 것들 중에 마지막에꺼를 가져와서 .npy를 \"\" 이렇게 공백으로 처리함\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- 이게 malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # 라벨 결정 로직으로\n",
    "        # score == 3 -> 중립 -> None 반환 -> 학습에서 제외\n",
    "        # score >= 4 -> 암(양성) -> 1\n",
    "        # score <= 2 -> 정상(음성) -> 0\n",
    "        # int(score >= 4)는 파이썬에서 True -> 1\n",
    "        # False -> 0 이니깐 자동으로 라벨이 됨\n",
    "    except:\n",
    "        return None\n",
    "        # 혹시 split이나 replace, int 변환이 실패하면 그냥 None 반환하고 무시\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    # PyTorch의 Dataset 클래스를 상속해서 커ㅡ텀 데이터셋 정의\n",
    "    # 나중에 DataLoader랑 같이 쓰이기 때문에 __len__()이랑 __getitem__()을 꼭 넣어줘야함\n",
    "    def __init__(self, paths, labels, transform=None):  # 생성자 : 세개의 인자를 받음\n",
    "        # paths : 이미지 .npy 파일 경로 리스트\n",
    "        # labels : 각 이미지에 대한 라벨 리스트 (0, 1 or None)\n",
    "        # transform : 이미지 증강 설정 (train_transform, val_transform 등)\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # 받은 인자를 멤버 변수로 저장. 나중에 gettem()에서 접근함\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoader가 이걸 호출할 때 index에 해당하는 sample 하나를 반환\n",
    "        # 이미지, 라벨, 마스크( = MGA용 target) 3개를 리턴함\n",
    "        file_path = self.paths[idx] # 파일 경로 불러오기\n",
    "        label = self.labels[idx]    # 라벨 불러오기\n",
    "        fname = os.path.basename(file_path) # 전체 경로에서 파일 이름만 추출 -> 나중에 bbox_dict[fname] 찾을때 쓰임\n",
    "\n",
    "        img = np.load(file_path)    # .npy 파일에서 CT 슬라이스 불러오기 -> 흑백 CT 이미지, shape은 (H, W)\n",
    "        img = np.clip(img, -1000, 400)  # CT 이미지 HU 값이 너무 크거나 작으면 노이즈 -> -1000(공기) ~ 400(연조직)으로 클리핑해서 노이즈 제거\n",
    "        img = (img + 1000) / 1400.  # 정규화 : -1000 -> 0, 400 -> 1 사이 값으로 바꿔줌 -> 모델이 안정적으로 학습할 수 있도록 함\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        h, w = img.shape\n",
    "        img = np.expand_dims(img, axis=-1)  # (H, W, 1)\n",
    "\n",
    "        # 마스크 생성\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(h, w)).sum(dim=0).numpy()\n",
    "        else:\n",
    "            mask = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "        # transform 적용\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented['image']  # shape: [1, 224, 224]\n",
    "            mask = augmented['mask']  # shape: [224, 224]\n",
    "        else:\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "            mask = torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    # 전체 데이터셋 길이 반환 -> DataLoader가 아라야 배치 쪼갤 수 있음.\n",
    "\n",
    "# -------------------- CBAM 정의 (MGA 포함) --------------------\n",
    "# 2 Step : Channel Attention(어떤 채널에 집중할지) * Spatial Attention(어디에 집중할지) = 최종 Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # 입력 feature map의 채널별 중요도를 계산해서 강조함\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : 입력 채널 수\n",
    "        # ratio : 중간 채널 축소 비율. 기본 1/16으로 bottlenck 구성\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP 역할을 하는 1x1 conv 블록 -> 채널 압축 -> 비선형 -> 복원 (shared는 avg/max 둘다에서 같이 씀)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # 평균 풀링 / 최대 풀링으로 두가지 전역 정보를 추출\n",
    "        # 마지막 sigmoid는 attention weight로 스케일링\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max 풀링 경과를 각각 shape MLP에 통과시키고, 더한 후 sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> 채널마다 중요도 weight를 곱하게 됨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # 공간적으로 어디에 집중할지를 결정 -> 각 채널 내부에서 중요한 위치 찾기\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # 채널 차원은 평균, 최대 두 개만 써서 concat\n",
    "    # 그걸 1채널로 줄여주는 conv\n",
    "    # 커널 크기 k=7이면 넓은 영역까지 감지 가능\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # 입력 feature map에서 :\n",
    "    # 평균, 최대값을 각 spatial 위치별로 구함 -> [B, 1, H, W] 두 개\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> 위치별 중요도 map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttention을 내부에 선언\n",
    "    # MGA를 위해 마지막 attention map을 저장하는 변수 포함\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # 채널 중요도 -> 곱함\n",
    "    # 위치 중요도 -> 곱함\n",
    "    # 둘 다 반영된 최종 feature map 리턴\n",
    "\n",
    "# -------------------- ResNet18 + CBAM 모델 정의 --------------------\n",
    "# BasicBlockCBAM : ResNet의 기본 Residual Block 하나를 정의\n",
    "# → conv → BN → ReLU → conv → BN → (CBAM optional) → Add → ReLU\n",
    "\n",
    "# ResNet18_CBAM : ResNet18 구조로 전체 네트워크 쌓기\n",
    "# → conv1 → layer1~3 → layer4 → avgpool → fc\n",
    "\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        # 입력 채널: in_planes, 출력 채널: out_planes, 3x3 커널, padding=1로 크기 유지, stride로 크기 조절\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)   # 배치 정규화\n",
    "        self.relu = nn.ReLU()   # 비선형 활성화 함수\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        # 두번째 conv, 채널 수 유지, 크기 유지\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)   # 배치 정규화\n",
    "\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None  # CBAM 모듈 사용 여부\n",
    "        self.downsample = downsample    # residual 연결 시 차원 맞추는 conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # skip connection용 입력 저장\n",
    "\n",
    "        out = self.conv1(x) # 첫 번째 conv\n",
    "        out = self.bn1(out) # 정규화\n",
    "        out = self.relu(out)  # 활성화\n",
    "\n",
    "        out = self.conv2(out)   # 두 번째 conv\n",
    "        out = self.bn2(out) # 정규화\n",
    "\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)    # CBAM 적용\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)   # shortcut 경로 보정\n",
    "\n",
    "        out += residual # skip connection\n",
    "        out = self.relu(out)    # 출력에 ReLU 적용\n",
    "\n",
    "        return out  # 결과 반환\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2, use_cbam=True):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "        self.use_cbam = use_cbam\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, blocks=2, use_cbam=use_cbam)\n",
    "        self.layer2 = self._make_layer(128, blocks=2, stride=2, use_cbam=use_cbam)\n",
    "        self.layer3 = self._make_layer(256, blocks=2, stride=2, use_cbam=use_cbam)\n",
    "        self.layer4 = self._make_layer(512, blocks=2, stride=2, use_cbam=False)  # 마지막 블록은 CBAM 제거\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam=use_cbam)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# -------------------- 학습 루프 --------------------\n",
    "def run():\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_dataset = CTDataset(train_files, train_labels, transform=train_transform)\n",
    "    val_dataset = CTDataset(val_files, val_labels, transform=val_transform)\n",
    "    test_dataset = CTDataset(test_files, test_labels, transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # 모델, 손실함수, 옵티마이저 정의\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    best_acc = 0.0  # 가장 높은 val accuracy를 저장\n",
    "    save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"r18_cbam_mga_aug_lr4_ep100_label1.pth\")\n",
    "\n",
    "    # 학습 루프 시작\n",
    "    for epoch in range(num_epochs):\n",
    "        # MGA 스케쥴링: 초기 lambda -> 점점 증가시킴\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "\n",
    "        model.train()  # 학습 모드로 변경\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # 한 epoch 동안 모든 train 데이터를 학습\n",
    "        for images, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)  # forward pass\n",
    "            ce_loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "            # -------------------- MGA Loss 계산 위치 --------------------\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # attention map 꺼내오기\n",
    "\n",
    "            if attn_map is not None:\n",
    "                attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                attn_loss = F.mse_loss(attn_map, masks)  # mask와의 MSE loss\n",
    "                loss = ce_loss + lambda_mga * attn_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Acc: {(correct/total)*100:.4f}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] lambda_mga: {lambda_mga:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()  # 메모리 정리\n",
    "\n",
    "        # -------------------- 검증 --------------------\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iamegs, labels, masks in val_loader:\n",
    "                iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "                outputs = model(iamegs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"✅ Saved best model!\")\n",
    "\n",
    "    # -------------------- 테스트 --------------------\n",
    "    print(\"\\n📊 Test Evaluation:\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # numpy 배열로 변환\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    # 지표 계산\n",
    "    from sklearn.metrics import (\n",
    "        classification_report, roc_auc_score, confusion_matrix,\n",
    "        precision_score, recall_score, balanced_accuracy_score,\n",
    "        matthews_corrcoef, f1_score\n",
    "    )\n",
    "\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    # 📋 출력\n",
    "    print(f\"✅ Test Accuracy         : {acc*100:.2f}%\")\n",
    "    print(f\"🎯 AUC                   : {auc:.4f}\")\n",
    "    print(f\"📌 Precision             : {precision:.4f}\")\n",
    "    print(f\"📌 Recall (Sensitivity)  : {recall:.4f}\")\n",
    "    print(f\"📌 Specificity           : {specificity:.4f}\")\n",
    "    print(f\"📌 F1 Score              : {f1:.4f}\")\n",
    "    print(f\"📌 Balanced Accuracy     : {balanced_acc:.4f}\")\n",
    "    print(f\"📌 MCC                   : {mcc:.4f}\")\n",
    "    print(\"\\n📌 Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # 📁 CSV로 저장\n",
    "    test_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"phase\": \"test\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "\n",
    "    csv_path = \"logs/final_test_metrics.csv\"\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=test_metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(test_metrics)\n",
    "\n",
    "    print(f\"\\n📁 테스트 지표 저장 완료: {csv_path}\")\n",
    "\n",
    "# 진입점\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Test Accuracy         : 85.50%\n",
    "# 🎯 AUC                   : 0.9074\n",
    "# 📌 Precision             : 0.9034\n",
    "# 📌 Recall (Sensitivity)  : 0.8724\n",
    "# 📌 Specificity           : 0.8218\n",
    "# 📌 F1 Score              : 0.8876\n",
    "# 📌 Balanced Accuracy     : 0.8471\n",
    "# 📌 MCC                   : 0.6844\n",
    "\n",
    "# 📌 Confusion Matrix:\n",
    "# [[226  49]\n",
    "#  [ 67 458]]\n",
    "\n",
    "# r18_cbam_mga_aug_lr4_ep100_weight2.pth\n",
    "# 전체코드: ResNet18 + CBAM + MGA Loss + Lambda Scheduling (CE Weight + mask 회전)\n",
    "\n",
    "import os, re, numpy as np, torch, gc\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "\n",
    "# -------------------- 디바이스 설정 --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- 하이퍼파라미터 설정 --------------------\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# lambda MGA 스케줄 설정\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "total_epochs = num_epochs\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=10, p=0.5),\n",
    "    A.CoarseDropout(\n",
    "        max_holes=1, max_height=32, max_width=32, min_holes=1, \n",
    "        min_height=16, min_width=16, fill_value=0, p=0.5),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        fname = os.path.basename(file_path)\n",
    "\n",
    "        img = np.load(file_path)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(img.shape[0], img.shape[1])).sum(axis=0)\n",
    "        else:\n",
    "            mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img, mask=mask)\n",
    "            img = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "        else:\n",
    "            img = torch.tensor(img).unsqueeze(0)\n",
    "            mask = torch.tensor(mask)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "# 시드 고정\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)                         # 파이썬 random\n",
    "    np.random.seed(seed)                      # numpy\n",
    "    torch.manual_seed(seed)                   # torch CPU\n",
    "    torch.cuda.manual_seed(seed)              # torch GPU\n",
    "    torch.cuda.manual_seed_all(seed)          # multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # 연산 동일하게\n",
    "    torch.backends.cudnn.benchmark = False    # 연산 속도 최적화 OFF (같은 연산 보장)\n",
    "\n",
    "# -------------------- Bounding Box Mask --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    masks = []\n",
    "    for bbox in bbox_list:\n",
    "        mask = np.zeros(image_size, dtype=np.float32)\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0\n",
    "        masks.append(mask)\n",
    "    masks = np.stack(masks)\n",
    "    masks = np.expand_dims(masks, axis=1)\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "\n",
    "# -------------------- Bounding Box CSV --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    bbox_dict = {}\n",
    "    for _, row in df.iterrows():\n",
    "        pid = row['pid']\n",
    "        slice_idx = int(re.findall(r'\\d+', str(row['slice']))[0])\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"\n",
    "        bbox = eval(row['bb'])\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)\n",
    "    return bbox_dict\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "\n",
    "def extract_label_from_filename(fname):\n",
    "    try:\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# -------------------- 라벨 추출 --------------------\n",
    "def extract_label_from_filename(fname): # fname : 파일 이름 (예: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # 이 이름에서 malignancy score(악성도 점수)를 추출해서 라벨로 변환\n",
    "    try:    # 파일명이 이상하거나 에러나면 except로 빠져나가서 None 반환함 (안전장치)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # 파일명에서 _ 제외하고 나머지 것들 중에 마지막에꺼를 가져와서 .npy를 \"\" 이렇게 공백으로 처리함\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- 이게 malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # 라벨 결정 로직으로\n",
    "        # score == 3 -> 중립 -> None 반환 -> 학습에서 제외\n",
    "        # score >= 4 -> 암(양성) -> 1\n",
    "        # score <= 2 -> 정상(음성) -> 0\n",
    "        # int(score >= 4)는 파이썬에서 True -> 1\n",
    "        # False -> 0 이니깐 자동으로 라벨이 됨\n",
    "    except:\n",
    "        return None\n",
    "        # 혹시 split이나 replace, int 변환이 실패하면 그냥 None 반환하고 무시\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    # PyTorch의 Dataset 클래스를 상속해서 커ㅡ텀 데이터셋 정의\n",
    "    # 나중에 DataLoader랑 같이 쓰이기 때문에 __len__()이랑 __getitem__()을 꼭 넣어줘야함\n",
    "    def __init__(self, paths, labels, transform=None):  # 생성자 : 세개의 인자를 받음\n",
    "        # paths : 이미지 .npy 파일 경로 리스트\n",
    "        # labels : 각 이미지에 대한 라벨 리스트 (0, 1 or None)\n",
    "        # transform : 이미지 증강 설정 (train_transform, val_transform 등)\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # 받은 인자를 멤버 변수로 저장. 나중에 gettem()에서 접근함\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoader가 이걸 호출할 때 index에 해당하는 sample 하나를 반환\n",
    "        # 이미지, 라벨, 마스크( = MGA용 target) 3개를 리턴함\n",
    "        file_path = self.paths[idx] # 파일 경로 불러오기\n",
    "        label = self.labels[idx]    # 라벨 불러오기\n",
    "        fname = os.path.basename(file_path) # 전체 경로에서 파일 이름만 추출 -> 나중에 bbox_dict[fname] 찾을때 쓰임\n",
    "\n",
    "        img = np.load(file_path)    # .npy 파일에서 CT 슬라이스 불러오기 -> 흑백 CT 이미지, shape은 (H, W)\n",
    "        img = np.clip(img, -1000, 400)  # CT 이미지 HU 값이 너무 크거나 작으면 노이즈 -> -1000(공기) ~ 400(연조직)으로 클리핑해서 노이즈 제거\n",
    "        img = (img + 1000) / 1400.  # 정규화 : -1000 -> 0, 400 -> 1 사이 값으로 바꿔줌 -> 모델이 안정적으로 학습할 수 있도록 함\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        h, w = img.shape\n",
    "        img = np.expand_dims(img, axis=-1)  # (H, W, 1)\n",
    "\n",
    "        # 마스크 생성\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(h, w)).sum(dim=0).numpy()\n",
    "        else:\n",
    "            mask = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "        # transform 적용\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented['image']  # shape: [1, 224, 224]\n",
    "            mask = augmented['mask']  # shape: [224, 224]\n",
    "        else:\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "            mask = torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    # 전체 데이터셋 길이 반환 -> DataLoader가 아라야 배치 쪼갤 수 있음.\n",
    "\n",
    "# -------------------- CBAM 정의 (MGA 포함) --------------------\n",
    "# 2 Step : Channel Attention(어떤 채널에 집중할지) * Spatial Attention(어디에 집중할지) = 최종 Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # 입력 feature map의 채널별 중요도를 계산해서 강조함\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : 입력 채널 수\n",
    "        # ratio : 중간 채널 축소 비율. 기본 1/16으로 bottlenck 구성\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP 역할을 하는 1x1 conv 블록 -> 채널 압축 -> 비선형 -> 복원 (shared는 avg/max 둘다에서 같이 씀)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # 평균 풀링 / 최대 풀링으로 두가지 전역 정보를 추출\n",
    "        # 마지막 sigmoid는 attention weight로 스케일링\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max 풀링 경과를 각각 shape MLP에 통과시키고, 더한 후 sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> 채널마다 중요도 weight를 곱하게 됨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # 공간적으로 어디에 집중할지를 결정 -> 각 채널 내부에서 중요한 위치 찾기\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # 채널 차원은 평균, 최대 두 개만 써서 concat\n",
    "    # 그걸 1채널로 줄여주는 conv\n",
    "    # 커널 크기 k=7이면 넓은 영역까지 감지 가능\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # 입력 feature map에서 :\n",
    "    # 평균, 최대값을 각 spatial 위치별로 구함 -> [B, 1, H, W] 두 개\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> 위치별 중요도 map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttention을 내부에 선언\n",
    "    # MGA를 위해 마지막 attention map을 저장하는 변수 포함\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # 채널 중요도 -> 곱함\n",
    "    # 위치 중요도 -> 곱함\n",
    "    # 둘 다 반영된 최종 feature map 리턴\n",
    "\n",
    "# -------------------- ResNet18 + CBAM 모델 정의 --------------------\n",
    "# BasicBlockCBAM : ResNet의 기본 Residual Block 하나를 정의\n",
    "# → conv → BN → ReLU → conv → BN → (CBAM optional) → Add → ReLU\n",
    "\n",
    "# ResNet18_CBAM : ResNet18 구조로 전체 네트워크 쌓기\n",
    "# → conv1 → layer1~3 → layer4 → avgpool → fc\n",
    "\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        # 입력 채널: in_planes, 출력 채널: out_planes, 3x3 커널, padding=1로 크기 유지, stride로 크기 조절\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)   # 배치 정규화\n",
    "        self.relu = nn.ReLU()   # 비선형 활성화 함수\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        # 두번째 conv, 채널 수 유지, 크기 유지\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)   # 배치 정규화\n",
    "\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None  # CBAM 모듈 사용 여부\n",
    "        self.downsample = downsample    # residual 연결 시 차원 맞추는 conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # skip connection용 입력 저장\n",
    "\n",
    "        out = self.conv1(x) # 첫 번째 conv\n",
    "        out = self.bn1(out) # 정규화\n",
    "        out = self.relu(out)  # 활성화\n",
    "\n",
    "        out = self.conv2(out)   # 두 번째 conv\n",
    "        out = self.bn2(out) # 정규화\n",
    "\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)    # CBAM 적용\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)   # shortcut 경로 보정\n",
    "\n",
    "        out += residual # skip connection\n",
    "        out = self.relu(out)    # 출력에 ReLU 적용\n",
    "\n",
    "        return out  # 결과 반환\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64 # 조기 입력 채널 수 설정\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # 입력: [B, 1, 224, 224] -> 출력: [B, 64, 112, 112], 큰 커널로 넓은 영역 캡처 \n",
    "        self.bn1 = nn.BatchNorm2d(64)   # 정규화\n",
    "        self.relu = nn.ReLU()   # 활성화\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # 풀링: [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        self.layer1 = self._make_layer(64, blocks=2)  # [B, 64, 56, 56] 유지\n",
    "        self.layer2 = self._make_layer(128, blocks=2, stride=2)  # [B, 128, 28, 28] 다운샘플링\n",
    "        self.layer3 = self._make_layer(256, blocks=2, stride=2)  # [B, 256, 14, 14] 다운샘플링\n",
    "        self.layer4 = self._make_layer(512, blocks=2, stride=2, use_cbam=False)  # [B, 512, 7, 7], CBAM 미사용\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # [B, 512, 7, 7] -> [B, 512, 1, 1]\n",
    "        self.fc = nn.Linear(512, num_classes)  # [B, 512] -> [B, num_classes]\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        # Planes : 해당 레이어의 출력 채널 수\n",
    "        # # blocks : 블록 수\n",
    "        # stride=2인 경우 다운샘플링 (해상도 절반)\n",
    "\n",
    "        downsample = None   # 스킵 연결해서 입력/출력 크기가 다르면 맞춰야 함\n",
    "\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                # 1x1 conv로 채널 수   및 공간 크기 맞춤\n",
    "                nn.BatchNorm2d(planes))\n",
    "            \n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam=use_cbam)]\n",
    "        # 첫 블록은 다운샘플링 적용 가능성 있음\n",
    "        self.in_planes = planes # 이후 블록을 위한 입력 채널 업데이트\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "            # 나머지 블록은 stride=1로 동일한 해상도 유지\n",
    "\n",
    "        return nn.Sequential(*layers)   # 블록들을 Seguential로 묶어 반환\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # 입력: [B, 1, 224, 224] -> [B, 64, 112, 112]\n",
    "        x = self.bn1(x)    # 정규화\n",
    "        x = self.relu(x)   # ReLU 활성화\n",
    "        x = self.maxpool(x)  # [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        x = self.layer1(x)  # [B, 64, 56, 56]\n",
    "        x = self.layer2(x)  # [B, 128, 28, 28]\n",
    "        x = self.layer3(x)  # [B, 256, 14, 14]\n",
    "        x = self.layer4(x)  # [B, 512, 7, 7]\n",
    "\n",
    "        x = self.avgpool(x)  # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # [B, 512]\n",
    "        x = self.fc(x)  # [B, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------- 학습 루프 --------------------\n",
    "# -------------------- run 함수 --------------------\n",
    "def run():\n",
    "    seed_everything(42)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_dataset = CTDataset(train_files, train_labels, transform=train_transform)\n",
    "    val_dataset = CTDataset(val_files, val_labels, transform=val_transform)\n",
    "    test_dataset = CTDataset(test_files, test_labels, transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # 모델, 손실함수, 옵티마이저 정의\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.6653, 0.3347], device=device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    best_acc = 0.0  # 가장 높은 val accuracy를 저장\n",
    "    save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"r18_cbam_mga_aug_lr4_ep100_weight2.pth\")\n",
    "\n",
    "    # 학습 루프 시작\n",
    "    for epoch in range(num_epochs):\n",
    "        # MGA 스케쥴링: 초기 lambda -> 점점 증가시킴\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "\n",
    "        model.train()  # 학습 모드로 변경\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # 한 epoch 동안 모든 train 데이터를 학습\n",
    "        for images, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)  # forward pass\n",
    "            ce_loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "            # -------------------- MGA Loss 계산 위치 --------------------\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # attention map 꺼내오기\n",
    "\n",
    "            if attn_map is not None:\n",
    "                attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                attn_loss = F.mse_loss(attn_map, masks)  # mask와의 MSE loss\n",
    "                loss = ce_loss + lambda_mga * attn_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Acc: {(correct/total)*100:.4f}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] lambda_mga: {lambda_mga:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()  # 메모리 정리\n",
    "\n",
    "        # -------------------- 검증 --------------------\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iamegs, labels, masks in val_loader:\n",
    "                iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "                outputs = model(iamegs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"✅ Saved best model!\")\n",
    "\n",
    "    # -------------------- 테스트 --------------------\n",
    "    print(\"\\n📊 Test Evaluation:\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # numpy 배열로 변환\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    # 지표 계산\n",
    "    from sklearn.metrics import (\n",
    "        classification_report, roc_auc_score, confusion_matrix,\n",
    "        precision_score, recall_score, balanced_accuracy_score,\n",
    "        matthews_corrcoef, f1_score\n",
    "    )\n",
    "\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    # 📋 출력\n",
    "    print(f\"✅ Test Accuracy         : {acc*100:.2f}%\")\n",
    "    print(f\"🎯 AUC                   : {auc:.4f}\")\n",
    "    print(f\"📌 Precision             : {precision:.4f}\")\n",
    "    print(f\"📌 Recall (Sensitivity)  : {recall:.4f}\")\n",
    "    print(f\"📌 Specificity           : {specificity:.4f}\")\n",
    "    print(f\"📌 F1 Score              : {f1:.4f}\")\n",
    "    print(f\"📌 Balanced Accuracy     : {balanced_acc:.4f}\")\n",
    "    print(f\"📌 MCC                   : {mcc:.4f}\")\n",
    "    print(\"\\n📌 Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # 📁 CSV로 저장\n",
    "    test_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"phase\": \"test\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "\n",
    "    csv_path = \"logs/final_test_metrics.csv\"\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=test_metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(test_metrics)\n",
    "\n",
    "    print(f\"\\n📁 테스트 지표 저장 완료: {csv_path}\")\n",
    "\n",
    "# 진입점\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: 100%|██████████| 234/234 [00:09<00:00, 25.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 58.0386, Loss: 0.6966\n",
      "[Epoch 1] lambda_mga: 0.1000\n",
      "Val Acc: 0.4375\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|██████████| 234/234 [00:10<00:00, 23.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 61.7631, Loss: 0.6565\n",
      "[Epoch 2] lambda_mga: 0.1040\n",
      "Val Acc: 0.5600\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|██████████| 234/234 [00:11<00:00, 19.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 63.8800, Loss: 0.6432\n",
      "[Epoch 3] lambda_mga: 0.1080\n",
      "Val Acc: 0.6388\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: 100%|██████████| 234/234 [00:11<00:00, 19.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 68.5959, Loss: 0.6116\n",
      "[Epoch 4] lambda_mga: 0.1120\n",
      "Val Acc: 0.6913\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: 100%|██████████| 234/234 [00:12<00:00, 19.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 69.2926, Loss: 0.5956\n",
      "[Epoch 5] lambda_mga: 0.1160\n",
      "Val Acc: 0.6850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6]: 100%|██████████| 234/234 [00:12<00:00, 19.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 70.9807, Loss: 0.5735\n",
      "[Epoch 6] lambda_mga: 0.1200\n",
      "Val Acc: 0.6438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7]: 100%|██████████| 234/234 [00:08<00:00, 26.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 72.9368, Loss: 0.5483\n",
      "[Epoch 7] lambda_mga: 0.1240\n",
      "Val Acc: 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8]: 100%|██████████| 234/234 [00:08<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 75.0804, Loss: 0.5140\n",
      "[Epoch 8] lambda_mga: 0.1280\n",
      "Val Acc: 0.7512\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9]: 100%|██████████| 234/234 [00:11<00:00, 20.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 76.2862, Loss: 0.4979\n",
      "[Epoch 9] lambda_mga: 0.1320\n",
      "Val Acc: 0.7562\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10]: 100%|██████████| 234/234 [00:12<00:00, 19.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 78.2958, Loss: 0.4730\n",
      "[Epoch 10] lambda_mga: 0.1360\n",
      "Val Acc: 0.6587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 11]: 100%|██████████| 234/234 [00:11<00:00, 19.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 79.5820, Loss: 0.4584\n",
      "[Epoch 11] lambda_mga: 0.1400\n",
      "Val Acc: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 12]: 100%|██████████| 234/234 [00:12<00:00, 19.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 81.6720, Loss: 0.4181\n",
      "[Epoch 12] lambda_mga: 0.1440\n",
      "Val Acc: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 13]: 100%|██████████| 234/234 [00:12<00:00, 19.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 82.5295, Loss: 0.3966\n",
      "[Epoch 13] lambda_mga: 0.1480\n",
      "Val Acc: 0.7600\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 14]:  19%|█▉        | 44/234 [00:02<00:07, 25.48it/s]"
     ]
    }
   ],
   "source": [
    "# 베스트 모델 시드 고정\n",
    "\n",
    "# 전체코드: ResNet18 + CBAM + MGA Loss + Lambda Scheduling (CE Weight ver)\n",
    "\n",
    "import os, re, numpy as np, torch, gc\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "# -------------------- 디바이스 설정 --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- 하이퍼파라미터 설정 --------------------\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# lambda MGA 스케줄 설정\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "total_epochs = num_epochs\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # numpy or tensor 이미지를 PIL 이미지 객체로 변환\n",
    "    transforms.Resize((224, 224)),  # 이미지를 224x224로 resize\n",
    "    transforms.RandomHorizontalFlip(),  # 이미지를 50% 확률로 좌우 반전\n",
    "    transforms.RandomRotation(10),  # 이미지를 -10도 ~ +10도 사이로 랜덤 회전, 촬영 자세나 기울어짐에 대한 회전 강건성확보\n",
    "    transforms.ToTensor(),  # PIL이미지 -> PyTorch Tensor로 변환, (H, W, C) -> (C, H, W), 값도 0255 -> 01 사이즈로 스케일 조정\n",
    "    transforms.Normalize([0.5], [0.5]), # 평균 0.5, 표준편차 0.5로 정규화 -> 결과적으로 01 -> 11로 바뀜\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
    "])  # 전체 이미지의 일부분 지우고 0으로 채움 (검은 사각형 생김)\n",
    "    # p=0.5 : 50% 확률로 이 증강 적용\n",
    "    # scale : 전체 이미지 대비 삭제 영역의 크기 비율\n",
    "    # ratio : 지우는 사각형의 가로:세로 비율 범위\n",
    "    # value=0 : 지운 곳을 검은색(0)으로 덮음\n",
    "    # 폐 CT에서 병변이 항상 일정한 위치에 나오지 않으니까 모델이 특정 위치에 과적합되는걸 방지함 (overfitting 예방)\n",
    "\n",
    "# 검증/테스트는 모델이 학습하지 않은 깨긋한 상태의 이미지로 정확도를 확인하기 위해서 검증용은 깔끔하게\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # PIL 이미지 객체로 변환\n",
    "    transforms.Resize((224, 224)),  # 사이즈 맞추기\n",
    "    transforms.ToTensor(),  # PIL 이미지 -> PyTorch Tensor로 변환\n",
    "    transforms.Normalize([0.5], [0.5])  # 정규화\n",
    "])\n",
    "\n",
    "# 시드 고정\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)                         # 파이썬 random\n",
    "    np.random.seed(seed)                      # numpy\n",
    "    torch.manual_seed(seed)                   # torch CPU\n",
    "    torch.cuda.manual_seed(seed)              # torch GPU\n",
    "    torch.cuda.manual_seed_all(seed)          # multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # 연산 동일하게\n",
    "    torch.backends.cudnn.benchmark = False    # 연산 속도 최적화 OFF (같은 연산 보장)\n",
    "\n",
    "# -------------------- Bounding Box를 Binary Mask로 --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    # bbox_list : 한 이미지에 들어있는 bounding box 리스트\n",
    "    # image_size : 출력할 마스크 크기. 보통 이미지와 동일한 (height, width) -> 디폴트는 224x224\n",
    "    # bbox들을 binary mask로 바꿔주는 함수\n",
    "    masks = []  # 여러 개의 bbox가 들어오니까, 각각의 마스크를 하나씩 리스트에 쌓기 위한 빈 리스트\n",
    "    for bbox in bbox_list:  # bbox_list를 하나씩 돌면서 처리 -> [x_min, y_min, x_max, y_max]네 좌표로 구성된 하나의 사각형 영역 \n",
    "        mask = np.zeros(image_size, dtype=np.float32)   # 224x224짜리 0으로 꽉 찬 2D 배열을 하나 생성\n",
    "        # 배경이 흰 종이를 만드는 느낌으로 만들고, 사각 영역만 1로 덧칠할거임\n",
    "        x_min, y_min, x_max, y_max = bbox   # 각 bbox의 네 좌표값을 각각 변수로 언팩. -> 마스크의 해당 영역에 사각형을 칠하기 위해서\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0    # y_min, y_max, x_min, x_max까지의 범위에 1.0을 채워 넣음\n",
    "        # -> 마스크에서 bbox에 해당하는 사각형 영역만 1(foreground)로 표시됨. 나머진 여전히 0(background)\n",
    "        masks.append(mask)  # 지금 만든 마스크(2D 배열)를 리스트에 추가 -> [mask1, mask2, ...]이렇게 쌓임\n",
    "\n",
    "    masks = np.stack(masks) # 리스트를 하나의 3D 배열로 합침 -> shape : [N, H, W] -> N은 bbox 개수\n",
    "    masks = np.expand_dims(masks, axis=1)   # 텐서 shape을 [N, 1, H, W]로 바꿈\n",
    "    # PyTorch 모델에서 기대하는 (batch x channel x height x width) 포맷 맞추기\n",
    "\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "    # numpy 배열을 PyTorch 텐서로 변환해서 리턴\n",
    "\n",
    "    # 한 bbox → 하나의 마스크 → 여러 개면 쌓아서 batch 형태로\n",
    "# -------------------- Bounding Box CSV 로드 --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    # csv_path : bounding box 정보가 들어있는 CSV 파일 경로\n",
    "    # 반환값 : {filename:[bbox1, bbox2, ...]} 형태의 딕셔너리\n",
    "    df = pd.read_csv(csv_path)  # CSV파일을 pandas DataFrame으로 읽어옴\n",
    "    bbox_dict = {}\n",
    "    # key : 슬라이스 파일 이름 (ex. \"LIDC-IDRI-1012_slice0004.npy\")\n",
    "    # value : 해당 슬라이스에 존재하는 bbox들의 리스트\n",
    "    for _, row in df.iterrows():    # DataFrame의 모든 행(row)를 하나씩 순회\n",
    "        # row는 한 줄(=한 bbox)의 정보를 담고 있음\n",
    "\n",
    "        pid = row['pid']    # 환자 ID (예: \"LIDC-IDRI-1012\") -> 이미지 이름 구성 요소\n",
    "        slice_str = row['slice']    # 슬라이스 정보가 들어있는 문자열 (예: \"slice_0039\")\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])  # re.findall()로 문자열에서 숫자만 뽑아냄\n",
    "        # \"slice_0039\" -> ['0039'] -> [0] -> 39 (슬라이스 번호를 정수로 추출함)\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"   # 파일명 구성 (예: \"LIDC-IDRI-1012_slice0039.npy\")\n",
    "        # {:04d}는 4자리 정수로 만들고 빈자리는 0으로 채워줌 (39 -> 0039)\n",
    "        bbox = eval(row['bb'])  # row['bb']는 문자열 형태의 bbox (예: \"[20, 30, 80, 100]\")\n",
    "        # eval()을 써서 문자열을 리스트로 바꿔줌\n",
    "        # 주의 : 보안 상 위험할 수 있는 함수지만, 여긴 내부 데이터라 사용중\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)    # fname이라는 key가 딕셔너리에 없으면 []로 초기화하고,\n",
    "        # 거기에 bbox를 append -> 슬라이스 하나에 bbox 여러개 있어도 전부 리스트로 모아줌\n",
    "    return bbox_dict    # 최종적으로 {filename: [bbox1, bbox2, ...]} 형태의 딕셔너리 반환\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "# 실제로 csv_path에 있는 정보를 불러와서 bbox_dict에 저장함\n",
    "# 이걸 나주에 Dataset 클래스에서 fname 기준을 꺼내쓰게 됨\n",
    "\n",
    "# -------------------- 라벨 추출 --------------------\n",
    "def extract_label_from_filename(fname): # fname : 파일 이름 (예: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # 이 이름에서 malignancy score(악성도 점수)를 추출해서 라벨로 변환\n",
    "    try:    # 파일명이 이상하거나 에러나면 except로 빠져나가서 None 반환함 (안전장치)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # 파일명에서 _ 제외하고 나머지 것들 중에 마지막에꺼를 가져와서 .npy를 \"\" 이렇게 공백으로 처리함\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- 이게 malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # 라벨 결정 로직으로\n",
    "        # score == 3 -> 중립 -> None 반환 -> 학습에서 제외\n",
    "        # score >= 4 -> 암(양성) -> 1\n",
    "        # score <= 2 -> 정상(음성) -> 0\n",
    "        # int(score >= 4)는 파이썬에서 True -> 1\n",
    "        # False -> 0 이니깐 자동으로 라벨이 됨\n",
    "    except:\n",
    "        return None\n",
    "        # 혹시 split이나 replace, int 변환이 실패하면 그냥 None 반환하고 무시\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    # PyTorch의 Dataset 클래스를 상속해서 커ㅡ텀 데이터셋 정의\n",
    "    # 나중에 DataLoader랑 같이 쓰이기 때문에 __len__()이랑 __getitem__()을 꼭 넣어줘야함\n",
    "    def __init__(self, paths, labels, transform=None):  # 생성자 : 세개의 인자를 받음\n",
    "        # paths : 이미지 .npy 파일 경로 리스트\n",
    "        # labels : 각 이미지에 대한 라벨 리스트 (0, 1 or None)\n",
    "        # transform : 이미지 증강 설정 (train_transform, val_transform 등)\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # 받은 인자를 멤버 변수로 저장. 나중에 gettem()에서 접근함\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoader가 이걸 호출할 때 index에 해당하는 sample 하나를 반환\n",
    "        # 이미지, 라벨, 마스크( = MGA용 target) 3개를 리턴함\n",
    "        file_path = self.paths[idx] # 파일 경로 불러오기\n",
    "        label = self.labels[idx]    # 라벨 불러오기\n",
    "        fname = os.path.basename(file_path) # 전체 경로에서 파일 이름만 추출 -> 나중에 bbox_dict[fname] 찾을때 쓰임\n",
    "\n",
    "        img = np.load(file_path)    # .npy 파일에서 CT 슬라이스 불러오기 -> 흑백 CT 이미지, shape은 (H, W)\n",
    "        img = np.clip(img, -1000, 400)  # CT 이미지 HU 값이 너무 크거나 작으면 노이즈 -> -1000(공기) ~ 400(연조직)으로 클리핑해서 노이즈 제거\n",
    "        img = (img + 1000) / 1400.  # 정규화 : -1000 -> 0, 400 -> 1 사이 값으로 바꿔줌 -> 모델이 안정적으로 학습할 수 있도록 함\n",
    "        img = np.expand_dims(img, axis=-1)  # CT는 채널이 1개니깐 (H, W) -> (H, w, 1)로 바꿔줌\n",
    "        # 나중에 PyTorch에서 (C, H, W)로 바꾸기 위함\n",
    "\n",
    "        if self.transform:  # 데이터 증강(transform)이 있다면 적용\n",
    "            img = self.transform(img)   \n",
    "        else:   # 없으면 numpy -> tensor 변환하고 (H, W, C) -> (C, H, W)로 순서 바꿈\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "\n",
    "        if fname in bbox_dict:  # 이 이미지에 bbox가 존재하면 -> 마스크 생성\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(224, 224))\n",
    "            # image_size는 transform과 동일하게 224x224\n",
    "        else:   # bbox가 없다면 전부 0으로 채워진 마스크 생성 -> MGA Loss 계산 시 참고용으로 쓰일 수 있음\n",
    "            mask = torch.zeros((1, 224, 224), dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask.squeeze(0)\n",
    "        # 반환값 3개 :\n",
    "        # img : shape[1, 224, 224]\n",
    "        # label : int(0 or 1)\n",
    "        # mask : [224, 224] <- squeeze로 채널 1개 제거\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    # 전체 데이터셋 길이 반환 -> DataLoader가 아라야 배치 쪼갤 수 있음.\n",
    "\n",
    "# -------------------- CBAM 정의 (MGA 포함) --------------------\n",
    "# 2 Step : Channel Attention(어떤 채널에 집중할지) * Spatial Attention(어디에 집중할지) = 최종 Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # 입력 feature map의 채널별 중요도를 계산해서 강조함\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : 입력 채널 수\n",
    "        # ratio : 중간 채널 축소 비율. 기본 1/16으로 bottlenck 구성\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP 역할을 하는 1x1 conv 블록 -> 채널 압축 -> 비선형 -> 복원 (shared는 avg/max 둘다에서 같이 씀)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # 평균 풀링 / 최대 풀링으로 두가지 전역 정보를 추출\n",
    "        # 마지막 sigmoid는 attention weight로 스케일링\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max 풀링 경과를 각각 shape MLP에 통과시키고, 더한 후 sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> 채널마다 중요도 weight를 곱하게 됨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # 공간적으로 어디에 집중할지를 결정 -> 각 채널 내부에서 중요한 위치 찾기\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # 채널 차원은 평균, 최대 두 개만 써서 concat\n",
    "    # 그걸 1채널로 줄여주는 conv\n",
    "    # 커널 크기 k=7이면 넓은 영역까지 감지 가능\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # 입력 feature map에서 :\n",
    "    # 평균, 최대값을 각 spatial 위치별로 구함 -> [B, 1, H, W] 두 개\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> 위치별 중요도 map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttention을 내부에 선언\n",
    "    # MGA를 위해 마지막 attention map을 저장하는 변수 포함\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # 채널 중요도 -> 곱함\n",
    "    # 위치 중요도 -> 곱함\n",
    "    # 둘 다 반영된 최종 feature map 리턴\n",
    "\n",
    "# -------------------- ResNet18 + CBAM 모델 정의 --------------------\n",
    "# BasicBlockCBAM : ResNet의 기본 Residual Block 하나를 정의\n",
    "# → conv → BN → ReLU → conv → BN → (CBAM optional) → Add → ReLU\n",
    "\n",
    "# ResNet18_CBAM : ResNet18 구조로 전체 네트워크 쌓기\n",
    "# → conv1 → layer1~3 → layer4 → avgpool → fc\n",
    "\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        # 입력 채널: in_planes, 출력 채널: out_planes, 3x3 커널, padding=1로 크기 유지, stride로 크기 조절\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)   # 배치 정규화\n",
    "        self.relu = nn.ReLU()   # 비선형 활성화 함수\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        # 두번째 conv, 채널 수 유지, 크기 유지\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)   # 배치 정규화\n",
    "\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None  # CBAM 모듈 사용 여부\n",
    "        self.downsample = downsample    # residual 연결 시 차원 맞추는 conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # skip connection용 입력 저장\n",
    "\n",
    "        out = self.conv1(x) # 첫 번째 conv\n",
    "        out = self.bn1(out) # 정규화\n",
    "        out = self.relu(out)  # 활성화\n",
    "\n",
    "        out = self.conv2(out)   # 두 번째 conv\n",
    "        out = self.bn2(out) # 정규화\n",
    "\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)    # CBAM 적용\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)   # shortcut 경로 보정\n",
    "\n",
    "        out += residual # skip connection\n",
    "        out = self.relu(out)    # 출력에 ReLU 적용\n",
    "\n",
    "        return out  # 결과 반환\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64 # 조기 입력 채널 수 설정\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # 입력: [B, 1, 224, 224] -> 출력: [B, 64, 112, 112], 큰 커널로 넓은 영역 캡처 \n",
    "        self.bn1 = nn.BatchNorm2d(64)   # 정규화\n",
    "        self.relu = nn.ReLU()   # 활성화\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # 풀링: [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        self.layer1 = self._make_layer(64, blocks=2)  # [B, 64, 56, 56] 유지\n",
    "        self.layer2 = self._make_layer(128, blocks=2, stride=2)  # [B, 128, 28, 28] 다운샘플링\n",
    "        self.layer3 = self._make_layer(256, blocks=2, stride=2)  # [B, 256, 14, 14] 다운샘플링\n",
    "        self.layer4 = self._make_layer(512, blocks=2, stride=2, use_cbam=False)  # [B, 512, 7, 7], CBAM 미사용\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # [B, 512, 7, 7] -> [B, 512, 1, 1]\n",
    "        self.fc = nn.Linear(512, num_classes)  # [B, 512] -> [B, num_classes]\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        # Planes : 해당 레이어의 출력 채널 수\n",
    "        # # blocks : 블록 수\n",
    "        # stride=2인 경우 다운샘플링 (해상도 절반)\n",
    "\n",
    "        downsample = None   # 스킵 연결해서 입력/출력 크기가 다르면 맞춰야 함\n",
    "\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                # 1x1 conv로 채널 수   및 공간 크기 맞춤\n",
    "                nn.BatchNorm2d(planes))\n",
    "            \n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam=use_cbam)]\n",
    "        # 첫 블록은 다운샘플링 적용 가능성 있음\n",
    "        self.in_planes = planes # 이후 블록을 위한 입력 채널 업데이트\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "            # 나머지 블록은 stride=1로 동일한 해상도 유지\n",
    "\n",
    "        return nn.Sequential(*layers)   # 블록들을 Seguential로 묶어 반환\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # 입력: [B, 1, 224, 224] -> [B, 64, 112, 112]\n",
    "        x = self.bn1(x)    # 정규화\n",
    "        x = self.relu(x)   # ReLU 활성화\n",
    "        x = self.maxpool(x)  # [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        x = self.layer1(x)  # [B, 64, 56, 56]\n",
    "        x = self.layer2(x)  # [B, 128, 28, 28]\n",
    "        x = self.layer3(x)  # [B, 256, 14, 14]\n",
    "        x = self.layer4(x)  # [B, 512, 7, 7]\n",
    "\n",
    "        x = self.avgpool(x)  # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # [B, 512]\n",
    "        x = self.fc(x)  # [B, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------- 학습 루프 --------------------\n",
    "def run():\n",
    "    seed_everything(42)\n",
    "    # 모든 CT 슬라이스 파일 경로 불러오기 (LIDC-IDRI 환자 폴더 안의 .npy 파일들)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "\n",
    "    # 파일 경로와 해당 파일의 라벨을 튜플로 저장\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    # 라벨이 None이 아닌 데이터만 필터링 (중립 제외)\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "\n",
    "    # 파일, 라벨을 리스트로 분리\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    # 전체 데이터를 train(70%), val(15%), test(15%)로 분할\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(\n",
    "    files, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(\n",
    "    temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    # 데이터 불러오기\n",
    "    train_dataset = CTDataset(train_files, train_labels, transform=train_transform)\n",
    "    val_dataset = CTDataset(val_files, val_labels, transform=val_transform)\n",
    "    test_dataset = CTDataset(test_files, test_labels, transform=val_transform)\n",
    "\n",
    "    # 데이터 로더\n",
    "    train_loader = DataLoader(train_dataset,  batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # 모델, 손실함수, 옵티마이저 정의\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.6653, 0.3347], device=device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    best_acc = 0.0  # 가장 높은 val accuracy를 저장\n",
    "    save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"r18_cbam_mga_aug_lr4_ep100_weight_seedfix.pth\")\n",
    "\n",
    "    # 학습 루프 시작\n",
    "    for epoch in range(num_epochs):\n",
    "        # MGA 스케쥴링: 초기 lambda -> 점점 증가시킴\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "\n",
    "        model.train()  # 학습 모드로 변경\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # 한 epoch 동안 모든 train 데이터를 학습\n",
    "        for images, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)  # forward pass\n",
    "            ce_loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "            # -------------------- MGA Loss 계산 위치 --------------------\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # attention map 꺼내오기\n",
    "\n",
    "            if attn_map is not None:\n",
    "                attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                attn_loss = F.mse_loss(attn_map, masks)  # mask와의 MSE loss\n",
    "                loss = ce_loss + lambda_mga * attn_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Acc: {(correct/total)*100:.4f}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] lambda_mga: {lambda_mga:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()  # 메모리 정리\n",
    "\n",
    "        # -------------------- 검증 --------------------\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iamegs, labels, masks in val_loader:\n",
    "                iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "                outputs = model(iamegs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"✅ Saved best model!\")\n",
    "\n",
    "    # -------------------- 테스트 --------------------\n",
    "    print(\"\\n📊 Test Evaluation:\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # numpy 배열로 변환\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    # 지표 계산\n",
    "    from sklearn.metrics import (\n",
    "        classification_report, roc_auc_score, confusion_matrix,\n",
    "        precision_score, recall_score, balanced_accuracy_score,\n",
    "        matthews_corrcoef, f1_score\n",
    "    )\n",
    "\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    # 📋 출력\n",
    "    print(f\"✅ Test Accuracy         : {acc*100:.2f}%\")\n",
    "    print(f\"🎯 AUC                   : {auc:.4f}\")\n",
    "    print(f\"📌 Precision             : {precision:.4f}\")\n",
    "    print(f\"📌 Recall (Sensitivity)  : {recall:.4f}\")\n",
    "    print(f\"📌 Specificity           : {specificity:.4f}\")\n",
    "    print(f\"📌 F1 Score              : {f1:.4f}\")\n",
    "    print(f\"📌 Balanced Accuracy     : {balanced_acc:.4f}\")\n",
    "    print(f\"📌 MCC                   : {mcc:.4f}\")\n",
    "    print(\"\\n📌 Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # 📁 CSV로 저장\n",
    "    test_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"phase\": \"test\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "\n",
    "    csv_path = \"logs/final_test_metrics.csv\"\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=test_metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(test_metrics)\n",
    "\n",
    "    print(f\"\\n📁 테스트 지표 저장 완료: {csv_path}\")\n",
    "\n",
    "# 진입점\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: 100%|██████████| 467/467 [00:16<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 59.5391, Loss: 0.7025\n",
      "[Epoch 1] lambda_mga: 0.1000\n",
      "Val Acc: 0.6112\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|██████████| 467/467 [00:16<00:00, 28.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 61.5488, Loss: 0.6686\n",
      "[Epoch 2] lambda_mga: 0.1040\n",
      "Val Acc: 0.6850\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]:  21%|██        | 97/467 [00:03<00:12, 29.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|██████████| 467/467 [00:16<00:00, 28.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 64.6302, Loss: 0.6406\n",
      "[Epoch 3] lambda_mga: 0.1080\n",
      "Val Acc: 0.5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: 100%|██████████| 467/467 [00:16<00:00, 28.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 67.0954, Loss: 0.6272\n",
      "[Epoch 4] lambda_mga: 0.1120\n",
      "Val Acc: 0.7300\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: 100%|██████████| 467/467 [00:13<00:00, 35.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 66.9882, Loss: 0.6162\n",
      "[Epoch 5] lambda_mga: 0.1160\n",
      "Val Acc: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6]: 100%|██████████| 467/467 [00:13<00:00, 34.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 70.0965, Loss: 0.5933\n",
      "[Epoch 6] lambda_mga: 0.1200\n",
      "Val Acc: 0.7125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7]: 100%|██████████| 467/467 [00:16<00:00, 28.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 71.1415, Loss: 0.5739\n",
      "[Epoch 7] lambda_mga: 0.1240\n",
      "Val Acc: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8]: 100%|██████████| 467/467 [00:16<00:00, 28.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 73.1243, Loss: 0.5526\n",
      "[Epoch 8] lambda_mga: 0.1280\n",
      "Val Acc: 0.7288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9]: 100%|██████████| 467/467 [00:16<00:00, 28.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 75.5091, Loss: 0.5167\n",
      "[Epoch 9] lambda_mga: 0.1320\n",
      "Val Acc: 0.7063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10]: 100%|██████████| 467/467 [00:15<00:00, 29.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 75.1876, Loss: 0.5112\n",
      "[Epoch 10] lambda_mga: 0.1360\n",
      "Val Acc: 0.7388\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 11]: 100%|██████████| 467/467 [00:12<00:00, 37.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 77.8403, Loss: 0.4868\n",
      "[Epoch 11] lambda_mga: 0.1400\n",
      "Val Acc: 0.7450\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 12]: 100%|██████████| 467/467 [00:13<00:00, 34.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 80.1179, Loss: 0.4569\n",
      "[Epoch 12] lambda_mga: 0.1440\n",
      "Val Acc: 0.6675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 13]: 100%|██████████| 467/467 [00:16<00:00, 28.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 79.4212, Loss: 0.4462\n",
      "[Epoch 13] lambda_mga: 0.1480\n",
      "Val Acc: 0.7612\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 14]: 100%|██████████| 467/467 [00:16<00:00, 28.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 81.5380, Loss: 0.4130\n",
      "[Epoch 14] lambda_mga: 0.1520\n",
      "Val Acc: 0.7975\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 15]: 100%|██████████| 467/467 [00:16<00:00, 28.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 82.2079, Loss: 0.4060\n",
      "[Epoch 15] lambda_mga: 0.1560\n",
      "Val Acc: 0.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 16]: 100%|██████████| 467/467 [00:13<00:00, 34.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 84.4587, Loss: 0.3728\n",
      "[Epoch 16] lambda_mga: 0.1600\n",
      "Val Acc: 0.8000\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17]: 100%|██████████| 467/467 [00:11<00:00, 39.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 84.9678, Loss: 0.3623\n",
      "[Epoch 17] lambda_mga: 0.1640\n",
      "Val Acc: 0.8175\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 18]: 100%|██████████| 467/467 [00:10<00:00, 42.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 85.6913, Loss: 0.3337\n",
      "[Epoch 18] lambda_mga: 0.1680\n",
      "Val Acc: 0.8175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 19]: 100%|██████████| 467/467 [00:11<00:00, 41.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 86.7899, Loss: 0.3204\n",
      "[Epoch 19] lambda_mga: 0.1720\n",
      "Val Acc: 0.8187\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 20]: 100%|██████████| 467/467 [00:11<00:00, 42.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 87.4062, Loss: 0.3087\n",
      "[Epoch 20] lambda_mga: 0.1760\n",
      "Val Acc: 0.8150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 21]: 100%|██████████| 467/467 [00:11<00:00, 42.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 87.4598, Loss: 0.3059\n",
      "[Epoch 21] lambda_mga: 0.1800\n",
      "Val Acc: 0.8075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 22]: 100%|██████████| 467/467 [00:10<00:00, 42.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 88.8264, Loss: 0.2772\n",
      "[Epoch 22] lambda_mga: 0.1840\n",
      "Val Acc: 0.8438\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 23]: 100%|██████████| 467/467 [00:09<00:00, 48.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 88.9871, Loss: 0.2755\n",
      "[Epoch 23] lambda_mga: 0.1880\n",
      "Val Acc: 0.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 24]: 100%|██████████| 467/467 [00:10<00:00, 46.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 90.1661, Loss: 0.2538\n",
      "[Epoch 24] lambda_mga: 0.1920\n",
      "Val Acc: 0.8413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 25]: 100%|██████████| 467/467 [00:13<00:00, 33.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 90.1929, Loss: 0.2444\n",
      "[Epoch 25] lambda_mga: 0.1960\n",
      "Val Acc: 0.8600\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 26]: 100%|██████████| 467/467 [00:14<00:00, 32.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.3451, Loss: 0.2288\n",
      "[Epoch 26] lambda_mga: 0.2000\n",
      "Val Acc: 0.7887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 27]: 100%|██████████| 467/467 [00:14<00:00, 31.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.4523, Loss: 0.2264\n",
      "[Epoch 27] lambda_mga: 0.2040\n",
      "Val Acc: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 28]: 100%|██████████| 467/467 [00:14<00:00, 31.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.0150, Loss: 0.2190\n",
      "[Epoch 28] lambda_mga: 0.2080\n",
      "Val Acc: 0.8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 29]: 100%|██████████| 467/467 [00:12<00:00, 37.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.9346, Loss: 0.2188\n",
      "[Epoch 29] lambda_mga: 0.2120\n",
      "Val Acc: 0.8163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 30]: 100%|██████████| 467/467 [00:13<00:00, 34.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.6313, Loss: 0.2034\n",
      "[Epoch 30] lambda_mga: 0.2160\n",
      "Val Acc: 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 31]: 100%|██████████| 467/467 [00:15<00:00, 31.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.7117, Loss: 0.1908\n",
      "[Epoch 31] lambda_mga: 0.2200\n",
      "Val Acc: 0.8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 32]: 100%|██████████| 467/467 [00:14<00:00, 31.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.4169, Loss: 0.1969\n",
      "[Epoch 32] lambda_mga: 0.2240\n",
      "Val Acc: 0.8425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 33]: 100%|██████████| 467/467 [00:14<00:00, 31.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.3365, Loss: 0.1936\n",
      "[Epoch 33] lambda_mga: 0.2280\n",
      "Val Acc: 0.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 34]: 100%|██████████| 467/467 [00:12<00:00, 37.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.0514, Loss: 0.1696\n",
      "[Epoch 34] lambda_mga: 0.2320\n",
      "Val Acc: 0.8575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 35]: 100%|██████████| 467/467 [00:11<00:00, 39.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.8907, Loss: 0.1695\n",
      "[Epoch 35] lambda_mga: 0.2360\n",
      "Val Acc: 0.8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 36]: 100%|██████████| 467/467 [00:14<00:00, 31.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.3548, Loss: 0.1728\n",
      "[Epoch 36] lambda_mga: 0.2400\n",
      "Val Acc: 0.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 37]: 100%|██████████| 467/467 [00:14<00:00, 31.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.8103, Loss: 0.1754\n",
      "[Epoch 37] lambda_mga: 0.2440\n",
      "Val Acc: 0.8650\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 38]: 100%|██████████| 467/467 [00:14<00:00, 31.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.6495, Loss: 0.1636\n",
      "[Epoch 38] lambda_mga: 0.2480\n",
      "Val Acc: 0.8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 39]: 100%|██████████| 467/467 [00:13<00:00, 34.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.6677, Loss: 0.1429\n",
      "[Epoch 39] lambda_mga: 0.2520\n",
      "Val Acc: 0.8812\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 40]: 100%|██████████| 467/467 [00:12<00:00, 38.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.4266, Loss: 0.1472\n",
      "[Epoch 40] lambda_mga: 0.2560\n",
      "Val Acc: 0.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 41]: 100%|██████████| 467/467 [00:14<00:00, 31.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.5606, Loss: 0.1499\n",
      "[Epoch 41] lambda_mga: 0.2600\n",
      "Val Acc: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 42]: 100%|██████████| 467/467 [00:14<00:00, 31.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.8821, Loss: 0.1390\n",
      "[Epoch 42] lambda_mga: 0.2640\n",
      "Val Acc: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 43]: 100%|██████████| 467/467 [00:14<00:00, 31.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.3194, Loss: 0.1600\n",
      "[Epoch 43] lambda_mga: 0.2680\n",
      "Val Acc: 0.8425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 44]: 100%|██████████| 467/467 [00:14<00:00, 32.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.9893, Loss: 0.1437\n",
      "[Epoch 44] lambda_mga: 0.2720\n",
      "Val Acc: 0.8738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 45]: 100%|██████████| 467/467 [00:12<00:00, 37.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.7213, Loss: 0.1396\n",
      "[Epoch 45] lambda_mga: 0.2760\n",
      "Val Acc: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 46]: 100%|██████████| 467/467 [00:13<00:00, 34.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.0429, Loss: 0.1374\n",
      "[Epoch 46] lambda_mga: 0.2800\n",
      "Val Acc: 0.8725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 47]: 100%|██████████| 467/467 [00:14<00:00, 32.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.7749, Loss: 0.1450\n",
      "[Epoch 47] lambda_mga: 0.2840\n",
      "Val Acc: 0.8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 48]: 100%|██████████| 467/467 [00:14<00:00, 31.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0343, Loss: 0.1147\n",
      "[Epoch 48] lambda_mga: 0.2880\n",
      "Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 49]: 100%|██████████| 467/467 [00:14<00:00, 31.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.1233, Loss: 0.1282\n",
      "[Epoch 49] lambda_mga: 0.2920\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 50]: 100%|██████████| 467/467 [00:12<00:00, 38.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0879, Loss: 0.1168\n",
      "[Epoch 50] lambda_mga: 0.2960\n",
      "Val Acc: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 51]: 100%|██████████| 467/467 [00:13<00:00, 33.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.4716, Loss: 0.1240\n",
      "[Epoch 51] lambda_mga: 0.3000\n",
      "Val Acc: 0.8612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 52]: 100%|██████████| 467/467 [00:14<00:00, 31.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.3376, Loss: 0.1267\n",
      "[Epoch 52] lambda_mga: 0.3040\n",
      "Val Acc: 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 53]: 100%|██████████| 467/467 [00:14<00:00, 31.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.6592, Loss: 0.1202\n",
      "[Epoch 53] lambda_mga: 0.3080\n",
      "Val Acc: 0.8925\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 54]: 100%|██████████| 467/467 [00:14<00:00, 31.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.9539, Loss: 0.1161\n",
      "[Epoch 54] lambda_mga: 0.3120\n",
      "Val Acc: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 55]: 100%|██████████| 467/467 [00:12<00:00, 37.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0611, Loss: 0.1120\n",
      "[Epoch 55] lambda_mga: 0.3160\n",
      "Val Acc: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 56]: 100%|██████████| 467/467 [00:13<00:00, 35.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3558, Loss: 0.1092\n",
      "[Epoch 56] lambda_mga: 0.3200\n",
      "Val Acc: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 57]: 100%|██████████| 467/467 [00:14<00:00, 32.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.1951, Loss: 0.1038\n",
      "[Epoch 57] lambda_mga: 0.3240\n",
      "Val Acc: 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 58]: 100%|██████████| 467/467 [00:12<00:00, 36.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.5702, Loss: 0.0962\n",
      "[Epoch 58] lambda_mga: 0.3280\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 59]: 100%|██████████| 467/467 [00:14<00:00, 31.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0611, Loss: 0.1142\n",
      "[Epoch 59] lambda_mga: 0.3320\n",
      "Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 60]: 100%|██████████| 467/467 [00:13<00:00, 33.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7042, Loss: 0.0969\n",
      "[Epoch 60] lambda_mga: 0.3360\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 61]: 100%|██████████| 467/467 [00:11<00:00, 39.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7042, Loss: 0.0970\n",
      "[Epoch 61] lambda_mga: 0.3400\n",
      "Val Acc: 0.8938\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 62]: 100%|██████████| 467/467 [00:14<00:00, 31.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.8114, Loss: 0.0932\n",
      "[Epoch 62] lambda_mga: 0.3440\n",
      "Val Acc: 0.8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 63]: 100%|██████████| 467/467 [00:14<00:00, 31.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.6506, Loss: 0.0988\n",
      "[Epoch 63] lambda_mga: 0.3480\n",
      "Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 64]: 100%|██████████| 467/467 [00:14<00:00, 31.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.6506, Loss: 0.0936\n",
      "[Epoch 64] lambda_mga: 0.3520\n",
      "Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 65]: 100%|██████████| 467/467 [00:14<00:00, 32.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.1329, Loss: 0.0823\n",
      "[Epoch 65] lambda_mga: 0.3560\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 66]: 100%|██████████| 467/467 [00:12<00:00, 38.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.8382, Loss: 0.0973\n",
      "[Epoch 66] lambda_mga: 0.3600\n",
      "Val Acc: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 67]: 100%|██████████| 467/467 [00:13<00:00, 34.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.4898, Loss: 0.0929\n",
      "[Epoch 67] lambda_mga: 0.3640\n",
      "Val Acc: 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 68]: 100%|██████████| 467/467 [00:14<00:00, 31.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.8114, Loss: 0.0841\n",
      "[Epoch 68] lambda_mga: 0.3680\n",
      "Val Acc: 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 69]: 100%|██████████| 467/467 [00:14<00:00, 32.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.8382, Loss: 0.0935\n",
      "[Epoch 69] lambda_mga: 0.3720\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 70]: 100%|██████████| 467/467 [00:13<00:00, 34.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9185, Loss: 0.0912\n",
      "[Epoch 70] lambda_mga: 0.3760\n",
      "Val Acc: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 71]: 100%|██████████| 467/467 [00:13<00:00, 34.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9453, Loss: 0.0882\n",
      "[Epoch 71] lambda_mga: 0.3800\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 72]: 100%|██████████| 467/467 [00:12<00:00, 38.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.5434, Loss: 0.0996\n",
      "[Epoch 72] lambda_mga: 0.3840\n",
      "Val Acc: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 73]: 100%|██████████| 467/467 [00:14<00:00, 31.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.2669, Loss: 0.0798\n",
      "[Epoch 73] lambda_mga: 0.3880\n",
      "Val Acc: 0.8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 74]: 100%|██████████| 467/467 [00:14<00:00, 31.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4277, Loss: 0.0790\n",
      "[Epoch 74] lambda_mga: 0.3920\n",
      "Val Acc: 0.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 75]: 100%|██████████| 467/467 [00:14<00:00, 31.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6152, Loss: 0.0778\n",
      "[Epoch 75] lambda_mga: 0.3960\n",
      "Val Acc: 0.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 76]: 100%|██████████| 467/467 [00:14<00:00, 31.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.8650, Loss: 0.0825\n",
      "[Epoch 76] lambda_mga: 0.4000\n",
      "Val Acc: 0.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 77]: 100%|██████████| 467/467 [00:12<00:00, 37.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.6506, Loss: 0.0920\n",
      "[Epoch 77] lambda_mga: 0.4040\n",
      "Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 78]: 100%|██████████| 467/467 [00:14<00:00, 31.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6956, Loss: 0.0643\n",
      "[Epoch 78] lambda_mga: 0.4080\n",
      "Val Acc: 0.8113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 79]: 100%|██████████| 467/467 [00:14<00:00, 31.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6420, Loss: 0.0706\n",
      "[Epoch 79] lambda_mga: 0.4120\n",
      "Val Acc: 0.8938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 80]: 100%|██████████| 467/467 [00:14<00:00, 32.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4277, Loss: 0.0696\n",
      "[Epoch 80] lambda_mga: 0.4160\n",
      "Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 81]: 100%|██████████| 467/467 [00:13<00:00, 33.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4009, Loss: 0.0731\n",
      "[Epoch 81] lambda_mga: 0.4200\n",
      "Val Acc: 0.8938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 82]: 100%|██████████| 467/467 [00:11<00:00, 40.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6152, Loss: 0.0712\n",
      "[Epoch 82] lambda_mga: 0.4240\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 83]: 100%|██████████| 467/467 [00:13<00:00, 33.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4009, Loss: 0.0741\n",
      "[Epoch 83] lambda_mga: 0.4280\n",
      "Val Acc: 0.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 84]: 100%|██████████| 467/467 [00:15<00:00, 30.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.1061, Loss: 0.0803\n",
      "[Epoch 84] lambda_mga: 0.4320\n",
      "Val Acc: 0.8725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 85]: 100%|██████████| 467/467 [00:15<00:00, 29.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.2401, Loss: 0.0794\n",
      "[Epoch 85] lambda_mga: 0.4360\n",
      "Val Acc: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 86]: 100%|██████████| 467/467 [00:13<00:00, 34.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6152, Loss: 0.0731\n",
      "[Epoch 86] lambda_mga: 0.4400\n",
      "Val Acc: 0.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 87]: 100%|██████████| 467/467 [00:11<00:00, 40.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.3473, Loss: 0.0760\n",
      "[Epoch 87] lambda_mga: 0.4440\n",
      "Val Acc: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 88]: 100%|██████████| 467/467 [00:15<00:00, 29.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9453, Loss: 0.0814\n",
      "[Epoch 88] lambda_mga: 0.4480\n",
      "Val Acc: 0.8962\n",
      "✅ Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 89]: 100%|██████████| 467/467 [00:15<00:00, 31.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.2315, Loss: 0.0525\n",
      "[Epoch 89] lambda_mga: 0.4520\n",
      "Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 90]: 100%|██████████| 467/467 [00:15<00:00, 29.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.0975, Loss: 0.0498\n",
      "[Epoch 90] lambda_mga: 0.4560\n",
      "Val Acc: 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 91]: 100%|██████████| 467/467 [00:11<00:00, 41.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4009, Loss: 0.0757\n",
      "[Epoch 91] lambda_mga: 0.4600\n",
      "Val Acc: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 92]: 100%|██████████| 467/467 [00:14<00:00, 31.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7224, Loss: 0.0675\n",
      "[Epoch 92] lambda_mga: 0.4640\n",
      "Val Acc: 0.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 93]: 100%|██████████| 467/467 [00:11<00:00, 40.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.0975, Loss: 0.0535\n",
      "[Epoch 93] lambda_mga: 0.4680\n",
      "Val Acc: 0.8962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 94]: 100%|██████████| 467/467 [00:15<00:00, 30.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6152, Loss: 0.0683\n",
      "[Epoch 94] lambda_mga: 0.4720\n",
      "Val Acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 95]: 100%|██████████| 467/467 [00:14<00:00, 31.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8832, Loss: 0.0539\n",
      "[Epoch 95] lambda_mga: 0.4760\n",
      "Val Acc: 0.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 96]: 100%|██████████| 467/467 [00:11<00:00, 41.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.3473, Loss: 0.0727\n",
      "[Epoch 96] lambda_mga: 0.4800\n",
      "Val Acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 97]: 100%|██████████| 467/467 [00:15<00:00, 29.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.0707, Loss: 0.0547\n",
      "[Epoch 97] lambda_mga: 0.4840\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 98]: 100%|██████████| 467/467 [00:15<00:00, 30.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7492, Loss: 0.0615\n",
      "[Epoch 98] lambda_mga: 0.4880\n",
      "Val Acc: 0.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 99]: 100%|██████████| 467/467 [00:15<00:00, 30.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.9368, Loss: 0.0599\n",
      "[Epoch 99] lambda_mga: 0.4920\n",
      "Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 100]: 100%|██████████| 467/467 [00:11<00:00, 41.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.1511, Loss: 0.0582\n",
      "[Epoch 100] lambda_mga: 0.4960\n",
      "Val Acc: 0.8725\n",
      "\n",
      "📊 Test Evaluation:\n",
      "✅ Test Accuracy         : 90.62%\n",
      "🎯 AUC                   : 0.9408\n",
      "📌 Precision             : 0.9261\n",
      "📌 Recall (Sensitivity)  : 0.9314\n",
      "📌 Specificity           : 0.8582\n",
      "📌 F1 Score              : 0.9288\n",
      "📌 Balanced Accuracy     : 0.8948\n",
      "📌 MCC                   : 0.7917\n",
      "\n",
      "📌 Confusion Matrix:\n",
      "[[236  39]\n",
      " [ 36 489]]\n",
      "\n",
      "📁 테스트 지표 저장 완료: logs/final_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# 👍👍👍👍 ✅ Test Accuracy         : 90.62%\n",
    "# 🎯 AUC                   : 0.9408\n",
    "# 📌 Precision             : 0.9261\n",
    "# 📌 Recall (Sensitivity)  : 0.9314\n",
    "# 📌 Specificity           : 0.8582\n",
    "# 📌 F1 Score              : 0.9288\n",
    "# 📌 Balanced Accuracy     : 0.8948\n",
    "# 📌 MCC                   : 0.7917\n",
    "\n",
    "# 📌 Confusion Matrix:\n",
    "# [[236  39]\n",
    "#  [ 36 489]]\n",
    "# r18_cbam_mga_aug_lr4_ep100_weight.pth\n",
    "# 전체코드: ResNet18 + CBAM + MGA Loss (CE Weight ver)\n",
    "\n",
    "import os, re, numpy as np, torch, gc\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# -------------------- 디바이스 설정 --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- 하이퍼파라미터 설정 --------------------\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# lambda MGA 스케줄 설정\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "total_epochs = num_epochs\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # numpy or tensor 이미지를 PIL 이미지 객체로 변환\n",
    "    transforms.Resize((224, 224)),  # 이미지를 224x224로 resize\n",
    "    transforms.RandomHorizontalFlip(),  # 이미지를 50% 확률로 좌우 반전\n",
    "    transforms.RandomRotation(10),  # 이미지를 -10도 ~ +10도 사이로 랜덤 회전, 촬영 자세나 기울어짐에 대한 회전 강건성확보\n",
    "    transforms.ToTensor(),  # PIL이미지 -> PyTorch Tensor로 변환, (H, W, C) -> (C, H, W), 값도 0255 -> 01 사이즈로 스케일 조정\n",
    "    transforms.Normalize([0.5], [0.5]), # 평균 0.5, 표준편차 0.5로 정규화 -> 결과적으로 01 -> 11로 바뀜\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
    "])  # 전체 이미지의 일부분 지우고 0으로 채움 (검은 사각형 생김)\n",
    "    # p=0.5 : 50% 확률로 이 증강 적용\n",
    "    # scale : 전체 이미지 대비 삭제 영역의 크기 비율\n",
    "    # ratio : 지우는 사각형의 가로:세로 비율 범위\n",
    "    # value=0 : 지운 곳을 검은색(0)으로 덮음\n",
    "    # 폐 CT에서 병변이 항상 일정한 위치에 나오지 않으니까 모델이 특정 위치에 과적합되는걸 방지함 (overfitting 예방)\n",
    "\n",
    "# 검증/테스트는 모델이 학습하지 않은 깨긋한 상태의 이미지로 정확도를 확인하기 위해서 검증용은 깔끔하게\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # PIL 이미지 객체로 변환\n",
    "    transforms.Resize((224, 224)),  # 사이즈 맞추기\n",
    "    transforms.ToTensor(),  # PIL 이미지 -> PyTorch Tensor로 변환\n",
    "    transforms.Normalize([0.5], [0.5])  # 정규화\n",
    "])\n",
    "\n",
    "# -------------------- Bounding Box를 Binary Mask로 --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    # bbox_list : 한 이미지에 들어있는 bounding box 리스트\n",
    "    # image_size : 출력할 마스크 크기. 보통 이미지와 동일한 (height, width) -> 디폴트는 224x224\n",
    "    # bbox들을 binary mask로 바꿔주는 함수\n",
    "    masks = []  # 여러 개의 bbox가 들어오니까, 각각의 마스크를 하나씩 리스트에 쌓기 위한 빈 리스트\n",
    "    for bbox in bbox_list:  # bbox_list를 하나씩 돌면서 처리 -> [x_min, y_min, x_max, y_max]네 좌표로 구성된 하나의 사각형 영역 \n",
    "        mask = np.zeros(image_size, dtype=np.float32)   # 224x224짜리 0으로 꽉 찬 2D 배열을 하나 생성\n",
    "        # 배경이 흰 종이를 만드는 느낌으로 만들고, 사각 영역만 1로 덧칠할거임\n",
    "        x_min, y_min, x_max, y_max = bbox   # 각 bbox의 네 좌표값을 각각 변수로 언팩. -> 마스크의 해당 영역에 사각형을 칠하기 위해서\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0    # y_min, y_max, x_min, x_max까지의 범위에 1.0을 채워 넣음\n",
    "        # -> 마스크에서 bbox에 해당하는 사각형 영역만 1(foreground)로 표시됨. 나머진 여전히 0(background)\n",
    "        masks.append(mask)  # 지금 만든 마스크(2D 배열)를 리스트에 추가 -> [mask1, mask2, ...]이렇게 쌓임\n",
    "\n",
    "    masks = np.stack(masks) # 리스트를 하나의 3D 배열로 합침 -> shape : [N, H, W] -> N은 bbox 개수\n",
    "    masks = np.expand_dims(masks, axis=1)   # 텐서 shape을 [N, 1, H, W]로 바꿈\n",
    "    # PyTorch 모델에서 기대하는 (batch x channel x height x width) 포맷 맞추기\n",
    "\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "    # numpy 배열을 PyTorch 텐서로 변환해서 리턴\n",
    "\n",
    "    # 한 bbox → 하나의 마스크 → 여러 개면 쌓아서 batch 형태로\n",
    "# -------------------- Bounding Box CSV 로드 --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    # csv_path : bounding box 정보가 들어있는 CSV 파일 경로\n",
    "    # 반환값 : {filename:[bbox1, bbox2, ...]} 형태의 딕셔너리\n",
    "    df = pd.read_csv(csv_path)  # CSV파일을 pandas DataFrame으로 읽어옴\n",
    "    bbox_dict = {}\n",
    "    # key : 슬라이스 파일 이름 (ex. \"LIDC-IDRI-1012_slice0004.npy\")\n",
    "    # value : 해당 슬라이스에 존재하는 bbox들의 리스트\n",
    "    for _, row in df.iterrows():    # DataFrame의 모든 행(row)를 하나씩 순회\n",
    "        # row는 한 줄(=한 bbox)의 정보를 담고 있음\n",
    "\n",
    "        pid = row['pid']    # 환자 ID (예: \"LIDC-IDRI-1012\") -> 이미지 이름 구성 요소\n",
    "        slice_str = row['slice']    # 슬라이스 정보가 들어있는 문자열 (예: \"slice_0039\")\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])  # re.findall()로 문자열에서 숫자만 뽑아냄\n",
    "        # \"slice_0039\" -> ['0039'] -> [0] -> 39 (슬라이스 번호를 정수로 추출함)\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"   # 파일명 구성 (예: \"LIDC-IDRI-1012_slice0039.npy\")\n",
    "        # {:04d}는 4자리 정수로 만들고 빈자리는 0으로 채워줌 (39 -> 0039)\n",
    "        bbox = eval(row['bb'])  # row['bb']는 문자열 형태의 bbox (예: \"[20, 30, 80, 100]\")\n",
    "        # eval()을 써서 문자열을 리스트로 바꿔줌\n",
    "        # 주의 : 보안 상 위험할 수 있는 함수지만, 여긴 내부 데이터라 사용중\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)    # fname이라는 key가 딕셔너리에 없으면 []로 초기화하고,\n",
    "        # 거기에 bbox를 append -> 슬라이스 하나에 bbox 여러개 있어도 전부 리스트로 모아줌\n",
    "    return bbox_dict    # 최종적으로 {filename: [bbox1, bbox2, ...]} 형태의 딕셔너리 반환\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "# 실제로 csv_path에 있는 정보를 불러와서 bbox_dict에 저장함\n",
    "# 이걸 나주에 Dataset 클래스에서 fname 기준을 꺼내쓰게 됨\n",
    "\n",
    "# -------------------- 라벨 추출 --------------------\n",
    "def extract_label_from_filename(fname): # fname : 파일 이름 (예: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # 이 이름에서 malignancy score(악성도 점수)를 추출해서 라벨로 변환\n",
    "    try:    # 파일명이 이상하거나 에러나면 except로 빠져나가서 None 반환함 (안전장치)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # 파일명에서 _ 제외하고 나머지 것들 중에 마지막에꺼를 가져와서 .npy를 \"\" 이렇게 공백으로 처리함\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- 이게 malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # 라벨 결정 로직으로\n",
    "        # score == 3 -> 중립 -> None 반환 -> 학습에서 제외\n",
    "        # score >= 4 -> 암(양성) -> 1\n",
    "        # score <= 2 -> 정상(음성) -> 0\n",
    "        # int(score >= 4)는 파이썬에서 True -> 1\n",
    "        # False -> 0 이니깐 자동으로 라벨이 됨\n",
    "    except:\n",
    "        return None\n",
    "        # 혹시 split이나 replace, int 변환이 실패하면 그냥 None 반환하고 무시\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    # PyTorch의 Dataset 클래스를 상속해서 커ㅡ텀 데이터셋 정의\n",
    "    # 나중에 DataLoader랑 같이 쓰이기 때문에 __len__()이랑 __getitem__()을 꼭 넣어줘야함\n",
    "    def __init__(self, paths, labels, transform=None):  # 생성자 : 세개의 인자를 받음\n",
    "        # paths : 이미지 .npy 파일 경로 리스트\n",
    "        # labels : 각 이미지에 대한 라벨 리스트 (0, 1 or None)\n",
    "        # transform : 이미지 증강 설정 (train_transform, val_transform 등)\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # 받은 인자를 멤버 변수로 저장. 나중에 gettem()에서 접근함\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoader가 이걸 호출할 때 index에 해당하는 sample 하나를 반환\n",
    "        # 이미지, 라벨, 마스크( = MGA용 target) 3개를 리턴함\n",
    "        file_path = self.paths[idx] # 파일 경로 불러오기\n",
    "        label = self.labels[idx]    # 라벨 불러오기\n",
    "        fname = os.path.basename(file_path) # 전체 경로에서 파일 이름만 추출 -> 나중에 bbox_dict[fname] 찾을때 쓰임\n",
    "\n",
    "        img = np.load(file_path)    # .npy 파일에서 CT 슬라이스 불러오기 -> 흑백 CT 이미지, shape은 (H, W)\n",
    "        img = np.clip(img, -1000, 400)  # CT 이미지 HU 값이 너무 크거나 작으면 노이즈 -> -1000(공기) ~ 400(연조직)으로 클리핑해서 노이즈 제거\n",
    "        img = (img + 1000) / 1400.  # 정규화 : -1000 -> 0, 400 -> 1 사이 값으로 바꿔줌 -> 모델이 안정적으로 학습할 수 있도록 함\n",
    "        img = np.expand_dims(img, axis=-1)  # CT는 채널이 1개니깐 (H, W) -> (H, w, 1)로 바꿔줌\n",
    "        # 나중에 PyTorch에서 (C, H, W)로 바꾸기 위함\n",
    "\n",
    "        if self.transform:  # 데이터 증강(transform)이 있다면 적용\n",
    "            img = self.transform(img)   \n",
    "        else:   # 없으면 numpy -> tensor 변환하고 (H, W, C) -> (C, H, W)로 순서 바꿈\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "\n",
    "        if fname in bbox_dict:  # 이 이미지에 bbox가 존재하면 -> 마스크 생성\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(224, 224))\n",
    "            # image_size는 transform과 동일하게 224x224\n",
    "        else:   # bbox가 없다면 전부 0으로 채워진 마스크 생성 -> MGA Loss 계산 시 참고용으로 쓰일 수 있음\n",
    "            mask = torch.zeros((1, 224, 224), dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask.squeeze(0)\n",
    "        # 반환값 3개 :\n",
    "        # img : shape[1, 224, 224]\n",
    "        # label : int(0 or 1)\n",
    "        # mask : [224, 224] <- squeeze로 채널 1개 제거\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    # 전체 데이터셋 길이 반환 -> DataLoader가 아라야 배치 쪼갤 수 있음.\n",
    "\n",
    "# -------------------- CBAM 정의 (MGA 포함) --------------------\n",
    "# 2 Step : Channel Attention(어떤 채널에 집중할지) * Spatial Attention(어디에 집중할지) = 최종 Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # 입력 feature map의 채널별 중요도를 계산해서 강조함\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : 입력 채널 수\n",
    "        # ratio : 중간 채널 축소 비율. 기본 1/16으로 bottlenck 구성\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP 역할을 하는 1x1 conv 블록 -> 채널 압축 -> 비선형 -> 복원 (shared는 avg/max 둘다에서 같이 씀)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # 평균 풀링 / 최대 풀링으로 두가지 전역 정보를 추출\n",
    "        # 마지막 sigmoid는 attention weight로 스케일링\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max 풀링 경과를 각각 shape MLP에 통과시키고, 더한 후 sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> 채널마다 중요도 weight를 곱하게 됨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # 공간적으로 어디에 집중할지를 결정 -> 각 채널 내부에서 중요한 위치 찾기\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # 채널 차원은 평균, 최대 두 개만 써서 concat\n",
    "    # 그걸 1채널로 줄여주는 conv\n",
    "    # 커널 크기 k=7이면 넓은 영역까지 감지 가능\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # 입력 feature map에서 :\n",
    "    # 평균, 최대값을 각 spatial 위치별로 구함 -> [B, 1, H, W] 두 개\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> 위치별 중요도 map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttention을 내부에 선언\n",
    "    # MGA를 위해 마지막 attention map을 저장하는 변수 포함\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # 채널 중요도 -> 곱함\n",
    "    # 위치 중요도 -> 곱함\n",
    "    # 둘 다 반영된 최종 feature map 리턴\n",
    "\n",
    "# -------------------- ResNet18 + CBAM 모델 정의 --------------------\n",
    "# BasicBlockCBAM : ResNet의 기본 Residual Block 하나를 정의\n",
    "# → conv → BN → ReLU → conv → BN → (CBAM optional) → Add → ReLU\n",
    "\n",
    "# ResNet18_CBAM : ResNet18 구조로 전체 네트워크 쌓기\n",
    "# → conv1 → layer1~3 → layer4 → avgpool → fc\n",
    "\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        # 입력 채널: in_planes, 출력 채널: out_planes, 3x3 커널, padding=1로 크기 유지, stride로 크기 조절\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)   # 배치 정규화\n",
    "        self.relu = nn.ReLU()   # 비선형 활성화 함수\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        # 두번째 conv, 채널 수 유지, 크기 유지\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)   # 배치 정규화\n",
    "\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None  # CBAM 모듈 사용 여부\n",
    "        self.downsample = downsample    # residual 연결 시 차원 맞추는 conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # skip connection용 입력 저장\n",
    "\n",
    "        out = self.conv1(x) # 첫 번째 conv\n",
    "        out = self.bn1(out) # 정규화\n",
    "        out = self.relu(out)  # 활성화\n",
    "\n",
    "        out = self.conv2(out)   # 두 번째 conv\n",
    "        out = self.bn2(out) # 정규화\n",
    "\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)    # CBAM 적용\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)   # shortcut 경로 보정\n",
    "\n",
    "        out += residual # skip connection\n",
    "        out = self.relu(out)    # 출력에 ReLU 적용\n",
    "\n",
    "        return out  # 결과 반환\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64 # 조기 입력 채널 수 설정\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # 입력: [B, 1, 224, 224] -> 출력: [B, 64, 112, 112], 큰 커널로 넓은 영역 캡처 \n",
    "        self.bn1 = nn.BatchNorm2d(64)   # 정규화\n",
    "        self.relu = nn.ReLU()   # 활성화\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # 풀링: [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        self.layer1 = self._make_layer(64, blocks=2)  # [B, 64, 56, 56] 유지\n",
    "        self.layer2 = self._make_layer(128, blocks=2, stride=2)  # [B, 128, 28, 28] 다운샘플링\n",
    "        self.layer3 = self._make_layer(256, blocks=2, stride=2)  # [B, 256, 14, 14] 다운샘플링\n",
    "        self.layer4 = self._make_layer(512, blocks=2, stride=2, use_cbam=False)  # [B, 512, 7, 7], CBAM 미사용\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # [B, 512, 7, 7] -> [B, 512, 1, 1]\n",
    "        self.fc = nn.Linear(512, num_classes)  # [B, 512] -> [B, num_classes]\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        # Planes : 해당 레이어의 출력 채널 수\n",
    "        # # blocks : 블록 수\n",
    "        # stride=2인 경우 다운샘플링 (해상도 절반)\n",
    "\n",
    "        downsample = None   # 스킵 연결해서 입력/출력 크기가 다르면 맞춰야 함\n",
    "\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                # 1x1 conv로 채널 수   및 공간 크기 맞춤\n",
    "                nn.BatchNorm2d(planes))\n",
    "            \n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam=use_cbam)]\n",
    "        # 첫 블록은 다운샘플링 적용 가능성 있음\n",
    "        self.in_planes = planes # 이후 블록을 위한 입력 채널 업데이트\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "            # 나머지 블록은 stride=1로 동일한 해상도 유지\n",
    "\n",
    "        return nn.Sequential(*layers)   # 블록들을 Seguential로 묶어 반환\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # 입력: [B, 1, 224, 224] -> [B, 64, 112, 112]\n",
    "        x = self.bn1(x)    # 정규화\n",
    "        x = self.relu(x)   # ReLU 활성화\n",
    "        x = self.maxpool(x)  # [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        x = self.layer1(x)  # [B, 64, 56, 56]\n",
    "        x = self.layer2(x)  # [B, 128, 28, 28]\n",
    "        x = self.layer3(x)  # [B, 256, 14, 14]\n",
    "        x = self.layer4(x)  # [B, 512, 7, 7]\n",
    "\n",
    "        x = self.avgpool(x)  # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # [B, 512]\n",
    "        x = self.fc(x)  # [B, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------- 학습 루프 --------------------\n",
    "def run():\n",
    "    # 모든 CT 슬라이스 파일 경로 불러오기 (LIDC-IDRI 환자 폴더 안의 .npy 파일들)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "\n",
    "    # 파일 경로와 해당 파일의 라벨을 튜플로 저장\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    # 라벨이 None이 아닌 데이터만 필터링 (중립 제외)\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "\n",
    "    # 파일, 라벨을 리스트로 분리\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    # 전체 데이터를 train(70%), val(15%), test(15%)로 분할\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    # 데이터 불러오기\n",
    "    train_dataset = CTDataset(train_files, train_labels, transform=train_transform)\n",
    "    val_dataset = CTDataset(val_files, val_labels, transform=val_transform)\n",
    "    test_dataset = CTDataset(test_files, test_labels, transform=val_transform)\n",
    "\n",
    "    # 데이터 로더\n",
    "    train_loader = DataLoader(train_dataset,  batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # 모델, 손실함수, 옵티마이저 정의\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.6653, 0.3347], device=device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    best_acc = 0.0  # 가장 높은 val accuracy를 저장\n",
    "    save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"r18_cbam_mga_aug_lr4_ep100_weight.pth\")\n",
    "\n",
    "    # 학습 루프 시작\n",
    "    for epoch in range(num_epochs):\n",
    "        # MGA 스케쥴링: 초기 lambda -> 점점 증가시킴\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "\n",
    "        model.train()  # 학습 모드로 변경\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # 한 epoch 동안 모든 train 데이터를 학습\n",
    "        for images, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)  # forward pass\n",
    "            ce_loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "            # -------------------- MGA Loss 계산 위치 --------------------\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # attention map 꺼내오기\n",
    "\n",
    "            if attn_map is not None:\n",
    "                attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                attn_loss = F.mse_loss(attn_map, masks)  # mask와의 MSE loss\n",
    "                loss = ce_loss + lambda_mga * attn_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Acc: {(correct/total)*100:.4f}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] lambda_mga: {lambda_mga:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()  # 메모리 정리\n",
    "\n",
    "        # -------------------- 검증 --------------------\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iamegs, labels, masks in val_loader:\n",
    "                iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "                outputs = model(iamegs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"✅ Saved best model!\")\n",
    "\n",
    "    # -------------------- 테스트 --------------------\n",
    "    print(\"\\n📊 Test Evaluation:\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # numpy 배열로 변환\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    # 지표 계산\n",
    "    from sklearn.metrics import (\n",
    "        classification_report, roc_auc_score, confusion_matrix,\n",
    "        precision_score, recall_score, balanced_accuracy_score,\n",
    "        matthews_corrcoef, f1_score\n",
    "    )\n",
    "\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    # 📋 출력\n",
    "    print(f\"✅ Test Accuracy         : {acc*100:.2f}%\")\n",
    "    print(f\"🎯 AUC                   : {auc:.4f}\")\n",
    "    print(f\"📌 Precision             : {precision:.4f}\")\n",
    "    print(f\"📌 Recall (Sensitivity)  : {recall:.4f}\")\n",
    "    print(f\"📌 Specificity           : {specificity:.4f}\")\n",
    "    print(f\"📌 F1 Score              : {f1:.4f}\")\n",
    "    print(f\"📌 Balanced Accuracy     : {balanced_acc:.4f}\")\n",
    "    print(f\"📌 MCC                   : {mcc:.4f}\")\n",
    "    print(\"\\n📌 Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # 📁 CSV로 저장\n",
    "    test_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"phase\": \"test\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "\n",
    "    csv_path = \"logs/final_test_metrics.csv\"\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=test_metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(test_metrics)\n",
    "\n",
    "    print(f\"\\n📁 테스트 지표 저장 완료: {csv_path}\")\n",
    "\n",
    "# 진입점\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 라벨 분포\n",
      "Class 0: 1784개\n",
      "Class 1: 3548개\n",
      "Class None: 2517개\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 📂 전체 슬라이스 파일 경로 가져오기\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "\n",
    "# 🏷️ 파일 이름에서 라벨 추출 함수\n",
    "def extract_label_from_filename(fname):\n",
    "    try:\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        if score == 3:\n",
    "            return None  # 중립은 제외\n",
    "        return int(score >= 4)  # 0 or 1\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# 📊 라벨 카운트\n",
    "label_counts = {\"0\": 0, \"1\": 0, \"None\": 0}\n",
    "for f in all_files:\n",
    "    label = extract_label_from_filename(f)\n",
    "    if label is None:\n",
    "        label_counts[\"None\"] += 1\n",
    "    else:\n",
    "        label_counts[str(label)] += 1\n",
    "\n",
    "# 출력\n",
    "print(\"✅ 라벨 분포\")\n",
    "for k, v in label_counts.items():\n",
    "    print(f\"Class {k}: {v}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 👍👍👍 전체코드: ResNet18 + CBAM + MGA Loss + Lambda Scheduling (기본) \n",
    "# + 데이터 증강 (Resize 224 / RandomHorizontalFlip / RandomRotation 10 / RandomErasing)\n",
    "\n",
    "import os, re, numpy as np, torch, gc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------- 디바이스 설정 --------------------\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- 하이퍼파라미터 설정 --------------------\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# lambda MGA 스케줄 설정\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "total_epochs = num_epochs\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # numpy or tensor 이미지를 PIL 이미지 객체로 변환\n",
    "    transforms.Resize((224, 224)),  # 이미지를 224x224로 resize\n",
    "    transforms.RandomHorizontalFlip(),  # 이미지를 50% 확률로 좌우 반전\n",
    "    transforms.RandomRotation(10),  # 이미지를 -10도 ~ +10도 사이로 랜덤 회전, 촬영 자세나 기울어짐에 대한 회전 강건성확보\n",
    "    transforms.ToTensor(),  # PIL이미지 -> PyTorch Tensor로 변환, (H, W, C) -> (C, H, W), 값도 0255 -> 01 사이즈로 스케일 조정\n",
    "    transforms.Normalize([0.5], [0.5]), # 평균 0.5, 표준편차 0.5로 정규화 -> 결과적으로 01 -> 11로 바뀜\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
    "])  # 전체 이미지의 일부분 지우고 0으로 채움 (검은 사각형 생김)\n",
    "    # p=0.5 : 50% 확률로 이 증강 적용\n",
    "    # scale : 전체 이미지 대비 삭제 영역의 크기 비율\n",
    "    # ratio : 지우는 사각형의 가로:세로 비율 범위\n",
    "    # value=0 : 지운 곳을 검은색(0)으로 덮음\n",
    "    # 폐 CT에서 병변이 항상 일정한 위치에 나오지 않으니까 모델이 특정 위치에 과적합되는걸 방지함 (overfitting 예방)\n",
    "\n",
    "# 검증/테스트는 모델이 학습하지 않은 깨긋한 상태의 이미지로 정확도를 확인하기 위해서 검증용은 깔끔하게\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # PIL 이미지 객체로 변환\n",
    "    transforms.Resize((224, 224)),  # 사이즈 맞추기\n",
    "    transforms.ToTensor(),  # PIL 이미지 -> PyTorch Tensor로 변환\n",
    "    transforms.Normalize([0.5], [0.5])  # 정규화\n",
    "])\n",
    "\n",
    "# -------------------- Bounding Box를 Binary Mask로 --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    # bbox_list : 한 이미지에 들어있는 bounding box 리스트\n",
    "    # image_size : 출력할 마스크 크기. 보통 이미지와 동일한 (height, width) -> 디폴트는 224x224\n",
    "    # bbox들을 binary mask로 바꿔주는 함수\n",
    "    masks = []  # 여러 개의 bbox가 들어오니까, 각각의 마스크를 하나씩 리스트에 쌓기 위한 빈 리스트\n",
    "    for bbox in bbox_list:  # bbox_list를 하나씩 돌면서 처리 -> [x_min, y_min, x_max, y_max]네 좌표로 구성된 하나의 사각형 영역 \n",
    "        mask = np.zeros(image_size, dtype=np.float32)   # 224x224짜리 0으로 꽉 찬 2D 배열을 하나 생성\n",
    "        # 배경이 흰 종이를 만드는 느낌으로 만들고, 사각 영역만 1로 덧칠할거임\n",
    "        x_min, y_min, x_max, y_max = bbox   # 각 bbox의 네 좌표값을 각각 변수로 언팩. -> 마스크의 해당 영역에 사각형을 칠하기 위해서\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0    # y_min, y_max, x_min, x_max까지의 범위에 1.0을 채워 넣음\n",
    "        # -> 마스크에서 bbox에 해당하는 사각형 영역만 1(foreground)로 표시됨. 나머진 여전히 0(background)\n",
    "        masks.append(mask)  # 지금 만든 마스크(2D 배열)를 리스트에 추가 -> [mask1, mask2, ...]이렇게 쌓임\n",
    "\n",
    "    masks = np.stack(masks) # 리스트를 하나의 3D 배열로 합침 -> shape : [N, H, W] -> N은 bbox 개수\n",
    "    masks = np.expand_dims(masks, axis=1)   # 텐서 shape을 [N, 1, H, W]로 바꿈\n",
    "    # PyTorch 모델에서 기대하는 (batch x channel x height x width) 포맷 맞추기\n",
    "\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "    # numpy 배열을 PyTorch 텐서로 변환해서 리턴\n",
    "\n",
    "    # 한 bbox → 하나의 마스크 → 여러 개면 쌓아서 batch 형태로\n",
    "# -------------------- Bounding Box CSV 로드 --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    # csv_path : bounding box 정보가 들어있는 CSV 파일 경로\n",
    "    # 반환값 : {filename:[bbox1, bbox2, ...]} 형태의 딕셔너리\n",
    "    df = pd.read_csv(csv_path)  # CSV파일을 pandas DataFrame으로 읽어옴\n",
    "    bbox_dict = {}\n",
    "    # key : 슬라이스 파일 이름 (ex. \"LIDC-IDRI-1012_slice0004.npy\")\n",
    "    # value : 해당 슬라이스에 존재하는 bbox들의 리스트\n",
    "    for _, row in df.iterrows():    # DataFrame의 모든 행(row)를 하나씩 순회\n",
    "        # row는 한 줄(=한 bbox)의 정보를 담고 있음\n",
    "\n",
    "        pid = row['pid']    # 환자 ID (예: \"LIDC-IDRI-1012\") -> 이미지 이름 구성 요소\n",
    "        slice_str = row['slice']    # 슬라이스 정보가 들어있는 문자열 (예: \"slice_0039\")\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])  # re.findall()로 문자열에서 숫자만 뽑아냄\n",
    "        # \"slice_0039\" -> ['0039'] -> [0] -> 39 (슬라이스 번호를 정수로 추출함)\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"   # 파일명 구성 (예: \"LIDC-IDRI-1012_slice0039.npy\")\n",
    "        # {:04d}는 4자리 정수로 만들고 빈자리는 0으로 채워줌 (39 -> 0039)\n",
    "        bbox = eval(row['bb'])  # row['bb']는 문자열 형태의 bbox (예: \"[20, 30, 80, 100]\")\n",
    "        # eval()을 써서 문자열을 리스트로 바꿔줌\n",
    "        # 주의 : 보안 상 위험할 수 있는 함수지만, 여긴 내부 데이터라 사용중\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)    # fname이라는 key가 딕셔너리에 없으면 []로 초기화하고,\n",
    "        # 거기에 bbox를 append -> 슬라이스 하나에 bbox 여러개 있어도 전부 리스트로 모아줌\n",
    "    return bbox_dict    # 최종적으로 {filename: [bbox1, bbox2, ...]} 형태의 딕셔너리 반환\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "# 실제로 csv_path에 있는 정보를 불러와서 bbox_dict에 저장함\n",
    "# 이걸 나주에 Dataset 클래스에서 fname 기준을 꺼내쓰게 됨\n",
    "\n",
    "# -------------------- 라벨 추출 --------------------\n",
    "def extract_label_from_filename(fname): # fname : 파일 이름 (예: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # 이 이름에서 malignancy score(악성도 점수)를 추출해서 라벨로 변환\n",
    "    try:    # 파일명이 이상하거나 에러나면 except로 빠져나가서 None 반환함 (안전장치)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # 파일명에서 _ 제외하고 나머지 것들 중에 마지막에꺼를 가져와서 .npy를 \"\" 이렇게 공백으로 처리함\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- 이게 malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # 라벨 결정 로직으로\n",
    "        # score == 3 -> 중립 -> None 반환 -> 학습에서 제외\n",
    "        # score >= 4 -> 암(양성) -> 1\n",
    "        # score <= 2 -> 정상(음성) -> 0\n",
    "        # int(score >= 4)는 파이썬에서 True -> 1\n",
    "        # False -> 0 이니깐 자동으로 라벨이 됨\n",
    "    except:\n",
    "        return None\n",
    "        # 혹시 split이나 replace, int 변환이 실패하면 그냥 None 반환하고 무시\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    # PyTorch의 Dataset 클래스를 상속해서 커ㅡ텀 데이터셋 정의\n",
    "    # 나중에 DataLoader랑 같이 쓰이기 때문에 __len__()이랑 __getitem__()을 꼭 넣어줘야함\n",
    "    def __init__(self, paths, labels, transform=None):  # 생성자 : 세개의 인자를 받음\n",
    "        # paths : 이미지 .npy 파일 경로 리스트\n",
    "        # labels : 각 이미지에 대한 라벨 리스트 (0, 1 or None)\n",
    "        # transform : 이미지 증강 설정 (train_transform, val_transform 등)\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # 받은 인자를 멤버 변수로 저장. 나중에 gettem()에서 접근함\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoader가 이걸 호출할 때 index에 해당하는 sample 하나를 반환\n",
    "        # 이미지, 라벨, 마스크( = MGA용 target) 3개를 리턴함\n",
    "        file_path = self.paths[idx] # 파일 경로 불러오기\n",
    "        label = self.labels[idx]    # 라벨 불러오기\n",
    "        fname = os.path.basename(file_path) # 전체 경로에서 파일 이름만 추출 -> 나중에 bbox_dict[fname] 찾을때 쓰임\n",
    "\n",
    "        img = np.load(file_path)    # .npy 파일에서 CT 슬라이스 불러오기 -> 흑백 CT 이미지, shape은 (H, W)\n",
    "        img = np.clip(img, -1000, 400)  # CT 이미지 HU 값이 너무 크거나 작으면 노이즈 -> -1000(공기) ~ 400(연조직)으로 클리핑해서 노이즈 제거\n",
    "        img = (img + 1000) / 1400.  # 정규화 : -1000 -> 0, 400 -> 1 사이 값으로 바꿔줌 -> 모델이 안정적으로 학습할 수 있도록 함\n",
    "        img = np.expand_dims(img, axis=-1)  # CT는 채널이 1개니깐 (H, W) -> (H, w, 1)로 바꿔줌\n",
    "        # 나중에 PyTorch에서 (C, H, W)로 바꾸기 위함\n",
    "\n",
    "        if self.transform:  # 데이터 증강(transform)이 있다면 적용\n",
    "            img = self.transform(img)   \n",
    "        else:   # 없으면 numpy -> tensor 변환하고 (H, W, C) -> (C, H, W)로 순서 바꿈\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "\n",
    "        if fname in bbox_dict:  # 이 이미지에 bbox가 존재하면 -> 마스크 생성\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(224, 224))\n",
    "            # image_size는 transform과 동일하게 224x224\n",
    "        else:   # bbox가 없다면 전부 0으로 채워진 마스크 생성 -> MGA Loss 계산 시 참고용으로 쓰일 수 있음\n",
    "            mask = torch.zeros((1, 224, 224), dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask.squeeze(0)\n",
    "        # 반환값 3개 :\n",
    "        # img : shape[1, 224, 224]\n",
    "        # label : int(0 or 1)\n",
    "        # mask : [224, 224] <- squeeze로 채널 1개 제거\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    # 전체 데이터셋 길이 반환 -> DataLoader가 아라야 배치 쪼갤 수 있음.\n",
    "\n",
    "# -------------------- CBAM 정의 (MGA 포함) --------------------\n",
    "# 2 Step : Channel Attention(어떤 채널에 집중할지) * Spatial Attention(어디에 집중할지) = 최종 Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # 입력 feature map의 채널별 중요도를 계산해서 강조함\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : 입력 채널 수\n",
    "        # ratio : 중간 채널 축소 비율. 기본 1/16으로 bottlenck 구성\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP 역할을 하는 1x1 conv 블록 -> 채널 압축 -> 비선형 -> 복원 (shared는 avg/max 둘다에서 같이 씀)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # 평균 풀링 / 최대 풀링으로 두가지 전역 정보를 추출\n",
    "        # 마지막 sigmoid는 attention weight로 스케일링\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max 풀링 경과를 각각 shape MLP에 통과시키고, 더한 후 sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> 채널마다 중요도 weight를 곱하게 됨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # 공간적으로 어디에 집중할지를 결정 -> 각 채널 내부에서 중요한 위치 찾기\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # 채널 차원은 평균, 최대 두 개만 써서 concat\n",
    "    # 그걸 1채널로 줄여주는 conv\n",
    "    # 커널 크기 k=7이면 넓은 영역까지 감지 가능\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # 입력 feature map에서 :\n",
    "    # 평균, 최대값을 각 spatial 위치별로 구함 -> [B, 1, H, W] 두 개\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> 위치별 중요도 map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttention을 내부에 선언\n",
    "    # MGA를 위해 마지막 attention map을 저장하는 변수 포함\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # 채널 중요도 -> 곱함\n",
    "    # 위치 중요도 -> 곱함\n",
    "    # 둘 다 반영된 최종 feature map 리턴\n",
    "\n",
    "# -------------------- ResNet18 + CBAM 모델 정의 --------------------\n",
    "# BasicBlockCBAM : ResNet의 기본 Residual Block 하나를 정의\n",
    "# → conv → BN → ReLU → conv → BN → (CBAM optional) → Add → ReLU\n",
    "\n",
    "# ResNet18_CBAM : ResNet18 구조로 전체 네트워크 쌓기\n",
    "# → conv1 → layer1~3 → layer4 → avgpool → fc\n",
    "\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        # 입력 채널: in_planes, 출력 채널: out_planes, 3x3 커널, padding=1로 크기 유지, stride로 크기 조절\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)   # 배치 정규화\n",
    "        self.relu = nn.ReLU()   # 비선형 활성화 함수\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        # 두번째 conv, 채널 수 유지, 크기 유지\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)   # 배치 정규화\n",
    "\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None  # CBAM 모듈 사용 여부\n",
    "        self.downsample = downsample    # residual 연결 시 차원 맞추는 conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # skip connection용 입력 저장\n",
    "\n",
    "        out = self.conv1(x) # 첫 번째 conv\n",
    "        out = self.bn1(out) # 정규화\n",
    "        out = self.relu(out)  # 활성화\n",
    "\n",
    "        out = self.conv2(out)   # 두 번째 conv\n",
    "        out = self.bn2(out) # 정규화\n",
    "\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)    # CBAM 적용\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)   # shortcut 경로 보정\n",
    "\n",
    "        out += residual # skip connection\n",
    "        out = self.relu(out)    # 출력에 ReLU 적용\n",
    "\n",
    "        return out  # 결과 반환\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64 # 조기 입력 채널 수 설정\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # 입력: [B, 1, 224, 224] -> 출력: [B, 64, 112, 112], 큰 커널로 넓은 영역 캡처 \n",
    "        self.bn1 = nn.BatchNorm2d(64)   # 정규화\n",
    "        self.relu = nn.ReLU()   # 활성화\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # 풀링: [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        self.layer1 = self._make_layer(64, blocks=2)  # [B, 64, 56, 56] 유지\n",
    "        self.layer2 = self._make_layer(128, blocks=2, stride=2)  # [B, 128, 28, 28] 다운샘플링\n",
    "        self.layer3 = self._make_layer(256, blocks=2, stride=2)  # [B, 256, 14, 14] 다운샘플링\n",
    "        self.layer4 = self._make_layer(512, blocks=2, stride=2, use_cbam=False)  # [B, 512, 7, 7], CBAM 미사용\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # [B, 512, 7, 7] -> [B, 512, 1, 1]\n",
    "        self.fc = nn.Linear(512, num_classes)  # [B, 512] -> [B, num_classes]\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        # Planes : 해당 레이어의 출력 채널 수\n",
    "        # # blocks : 블록 수\n",
    "        # stride=2인 경우 다운샘플링 (해상도 절반)\n",
    "\n",
    "        downsample = None   # 스킵 연결해서 입력/출력 크기가 다르면 맞춰야 함\n",
    "\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                # 1x1 conv로 채널 수   및 공간 크기 맞춤\n",
    "                nn.BatchNorm2d(planes))\n",
    "            \n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam=use_cbam)]\n",
    "        # 첫 블록은 다운샘플링 적용 가능성 있음\n",
    "        self.in_planes = planes # 이후 블록을 위한 입력 채널 업데이트\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "            # 나머지 블록은 stride=1로 동일한 해상도 유지\n",
    "\n",
    "        return nn.Sequential(*layers)   # 블록들을 Seguential로 묶어 반환\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # 입력: [B, 1, 224, 224] -> [B, 64, 112, 112]\n",
    "        x = self.bn1(x)    # 정규화\n",
    "        x = self.relu(x)   # ReLU 활성화\n",
    "        x = self.maxpool(x)  # [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        x = self.layer1(x)  # [B, 64, 56, 56]\n",
    "        x = self.layer2(x)  # [B, 128, 28, 28]\n",
    "        x = self.layer3(x)  # [B, 256, 14, 14]\n",
    "        x = self.layer4(x)  # [B, 512, 7, 7]\n",
    "\n",
    "        x = self.avgpool(x)  # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # [B, 512]\n",
    "        x = self.fc(x)  # [B, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------- 학습 루프 --------------------\n",
    "def run():\n",
    "    # 모든 CT 슬라이스 파일 경로 불러오기 (LIDC-IDRI 환자 폴더 안의 .npy 파일들)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "\n",
    "    # 파일 경로와 해당 파일의 라벨을 튜플로 저장\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    # 라벨이 None이 아닌 데이터만 필터링 (중립 제외)\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "\n",
    "    # 파일, 라벨을 리스트로 분리\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    # 전체 데이터를 train(70%), val(15%), test(15%)로 분할\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    # 데이터 불러오기\n",
    "    train_dataset = CTDataset(train_files, train_labels, transform=train_transform)\n",
    "    val_dataset = CTDataset(val_files, val_labels, transform=val_transform)\n",
    "    test_dataset = CTDataset(test_files, test_labels, transform=val_transform)\n",
    "\n",
    "    # 데이터 로더\n",
    "    train_loader = DataLoader(train_dataset,  batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # 모델, 손실함수, 옵티마이저 정의\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    best_acc = 0.0  # 가장 높은 val accuracy를 저장\n",
    "    save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"r18_cbam_mga_aug_lr4_ep100_1t.pth\")\n",
    "\n",
    "    # 학습 루프 시작\n",
    "    for epoch in range(num_epochs):\n",
    "        # MGA 스케쥴링: 초기 lambda -> 점점 증가시킴\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "\n",
    "        model.train()  # 학습 모드로 변경\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # 한 epoch 동안 모든 train 데이터를 학습\n",
    "        for images, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)  # forward pass\n",
    "            ce_loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "            # -------------------- MGA Loss 계산 위치 --------------------\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # attention map 꺼내오기\n",
    "\n",
    "            if attn_map is not None:\n",
    "                attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                attn_loss = F.mse_loss(attn_map, masks)  # mask와의 MSE loss\n",
    "                loss = ce_loss + lambda_mga * attn_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Acc: {(correct/total)*100:.4f}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] lambda_mga: {lambda_mga:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()  # 메모리 정리\n",
    "\n",
    "        # -------------------- 검증 --------------------\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iamegs, labels, masks in val_loader:\n",
    "                iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "                outputs = model(iamegs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"✅ Saved best model!\")\n",
    "\n",
    "    # -------------------- 테스트 --------------------\n",
    "    print(\"\\n📊 Test Evaluation:\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for iamegs, labels, masks in test_loader:\n",
    "            iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "            outputs = model(iamegs)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # 최종 테스트 결과 출력\n",
    "    print(f\"✅ Test Accuracy: {(np.array(y_pred) == np.array(y_true)).mean() * 100:.2f}%\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "    print(f\"AUC: {roc_auc_score(y_true, y_probs):.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# 진입점\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
