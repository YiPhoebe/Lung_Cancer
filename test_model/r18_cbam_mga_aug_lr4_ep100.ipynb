{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ PID: 3616504\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"í˜„ì¬ PID: {os.getpid()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 58.3869, Loss: 0.6954\n",
      "[Epoch 1] lambda_mga: 0.1000\n",
      "Val Acc: 0.3912\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 62.0311, Loss: 0.6558\n",
      "[Epoch 2] lambda_mga: 0.1040\n",
      "Val Acc: 0.5650\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 64.2283, Loss: 0.6419\n",
      "[Epoch 3] lambda_mga: 0.1080\n",
      "Val Acc: 0.6525\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 67.9528, Loss: 0.6124\n",
      "[Epoch 4] lambda_mga: 0.1120\n",
      "Val Acc: 0.7013\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 68.8639, Loss: 0.5925\n",
      "[Epoch 5] lambda_mga: 0.1160\n",
      "Val Acc: 0.6388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 71.6238, Loss: 0.5737\n",
      "[Epoch 6] lambda_mga: 0.1200\n",
      "Val Acc: 0.6388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 30.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 73.5798, Loss: 0.5419\n",
      "[Epoch 7] lambda_mga: 0.1240\n",
      "Val Acc: 0.6125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:06<00:00, 33.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 76.1790, Loss: 0.5144\n",
      "[Epoch 8] lambda_mga: 0.1280\n",
      "Val Acc: 0.7412\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 30.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 76.9293, Loss: 0.4961\n",
      "[Epoch 9] lambda_mga: 0.1320\n",
      "Val Acc: 0.7550\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 77.8135, Loss: 0.4746\n",
      "[Epoch 10] lambda_mga: 0.1360\n",
      "Val Acc: 0.7175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 11]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 79.2069, Loss: 0.4550\n",
      "[Epoch 11] lambda_mga: 0.1400\n",
      "Val Acc: 0.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 12]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 81.8060, Loss: 0.4130\n",
      "[Epoch 12] lambda_mga: 0.1440\n",
      "Val Acc: 0.7638\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 13]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 82.6902, Loss: 0.3959\n",
      "[Epoch 13] lambda_mga: 0.1480\n",
      "Val Acc: 0.8013\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 14]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 83.2529, Loss: 0.3808\n",
      "[Epoch 14] lambda_mga: 0.1520\n",
      "Val Acc: 0.8137\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 15]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 84.9678, Loss: 0.3510\n",
      "[Epoch 15] lambda_mga: 0.1560\n",
      "Val Acc: 0.7950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 16]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 85.5305, Loss: 0.3357\n",
      "[Epoch 16] lambda_mga: 0.1600\n",
      "Val Acc: 0.8013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 86.6292, Loss: 0.3142\n",
      "[Epoch 17] lambda_mga: 0.1640\n",
      "Val Acc: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 18]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 87.4598, Loss: 0.2962\n",
      "[Epoch 18] lambda_mga: 0.1680\n",
      "Val Acc: 0.8063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 19]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 88.7192, Loss: 0.2792\n",
      "[Epoch 19] lambda_mga: 0.1720\n",
      "Val Acc: 0.8263\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 20]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 88.6656, Loss: 0.2749\n",
      "[Epoch 20] lambda_mga: 0.1760\n",
      "Val Acc: 0.8425\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 21]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 89.7910, Loss: 0.2509\n",
      "[Epoch 21] lambda_mga: 0.1800\n",
      "Val Acc: 0.8337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 22]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 90.3805, Loss: 0.2461\n",
      "[Epoch 22] lambda_mga: 0.1840\n",
      "Val Acc: 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 23]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.1308, Loss: 0.2302\n",
      "[Epoch 23] lambda_mga: 0.1880\n",
      "Val Acc: 0.7937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 24]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 29.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 90.8896, Loss: 0.2315\n",
      "[Epoch 24] lambda_mga: 0.1920\n",
      "Val Acc: 0.7825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 25]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:06<00:00, 33.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 90.4341, Loss: 0.2386\n",
      "[Epoch 25] lambda_mga: 0.1960\n",
      "Val Acc: 0.8475\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 26]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 32.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.8542, Loss: 0.2229\n",
      "[Epoch 26] lambda_mga: 0.2000\n",
      "Val Acc: 0.8512\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 27]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.2208, Loss: 0.1916\n",
      "[Epoch 27] lambda_mga: 0.2040\n",
      "Val Acc: 0.8625\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 28]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.4169, Loss: 0.1876\n",
      "[Epoch 28] lambda_mga: 0.2080\n",
      "Val Acc: 0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 29]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.4705, Loss: 0.1978\n",
      "[Epoch 29] lambda_mga: 0.2120\n",
      "Val Acc: 0.8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.3012, Loss: 0.1728\n",
      "[Epoch 30] lambda_mga: 0.2160\n",
      "Val Acc: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 31]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.0600, Loss: 0.1844\n",
      "[Epoch 31] lambda_mga: 0.2200\n",
      "Val Acc: 0.8562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 32]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.2294, Loss: 0.2010\n",
      "[Epoch 32] lambda_mga: 0.2240\n",
      "Val Acc: 0.8812\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 33]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.2122, Loss: 0.1662\n",
      "[Epoch 33] lambda_mga: 0.2280\n",
      "Val Acc: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 34]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.9443, Loss: 0.1744\n",
      "[Epoch 34] lambda_mga: 0.2320\n",
      "Val Acc: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 35]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.2390, Loss: 0.1551\n",
      "[Epoch 35] lambda_mga: 0.2360\n",
      "Val Acc: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 36]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.9089, Loss: 0.1387\n",
      "[Epoch 36] lambda_mga: 0.2400\n",
      "Val Acc: 0.8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 37]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.7835, Loss: 0.1558\n",
      "[Epoch 37] lambda_mga: 0.2440\n",
      "Val Acc: 0.8438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 38]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.2840, Loss: 0.1351\n",
      "[Epoch 38] lambda_mga: 0.2480\n",
      "Val Acc: 0.8662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 39]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.5606, Loss: 0.1511\n",
      "[Epoch 39] lambda_mga: 0.2520\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 40]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.6677, Loss: 0.1453\n",
      "[Epoch 40] lambda_mga: 0.2560\n",
      "Val Acc: 0.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 41]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 32.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.5606, Loss: 0.1404\n",
      "[Epoch 41] lambda_mga: 0.2600\n",
      "Val Acc: 0.8850\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 42]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 32.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.2036, Loss: 0.1339\n",
      "[Epoch 42] lambda_mga: 0.2640\n",
      "Val Acc: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 43]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 30.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.6592, Loss: 0.1209\n",
      "[Epoch 43] lambda_mga: 0.2680\n",
      "Val Acc: 0.8662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 44]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.0429, Loss: 0.1256\n",
      "[Epoch 44] lambda_mga: 0.2720\n",
      "Val Acc: 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 45]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.1233, Loss: 0.1314\n",
      "[Epoch 45] lambda_mga: 0.2760\n",
      "Val Acc: 0.8875\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 46]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.8285, Loss: 0.1388\n",
      "[Epoch 46] lambda_mga: 0.2800\n",
      "Val Acc: 0.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 47]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.1501, Loss: 0.1280\n",
      "[Epoch 47] lambda_mga: 0.2840\n",
      "Val Acc: 0.8100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.6592, Loss: 0.1318\n",
      "[Epoch 48] lambda_mga: 0.2880\n",
      "Val Acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 49]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.1683, Loss: 0.1125\n",
      "[Epoch 49] lambda_mga: 0.2920\n",
      "Val Acc: 0.8925\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 50]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3023, Loss: 0.1049\n",
      "[Epoch 50] lambda_mga: 0.2960\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 51]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.2572, Loss: 0.1252\n",
      "[Epoch 51] lambda_mga: 0.3000\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 52]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3826, Loss: 0.0981\n",
      "[Epoch 52] lambda_mga: 0.3040\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 53]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.1415, Loss: 0.1122\n",
      "[Epoch 53] lambda_mga: 0.3080\n",
      "Val Acc: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 54]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3023, Loss: 0.1055\n",
      "[Epoch 54] lambda_mga: 0.3120\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 55]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.4094, Loss: 0.0986\n",
      "[Epoch 55] lambda_mga: 0.3160\n",
      "Val Acc: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 56]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3023, Loss: 0.1061\n",
      "[Epoch 56] lambda_mga: 0.3200\n",
      "Val Acc: 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 57]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.8467, Loss: 0.1076\n",
      "[Epoch 57] lambda_mga: 0.3240\n",
      "Val Acc: 0.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 58]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:06<00:00, 34.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7310, Loss: 0.0977\n",
      "[Epoch 58] lambda_mga: 0.3280\n",
      "Val Acc: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 59]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 32.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3558, Loss: 0.1008\n",
      "[Epoch 59] lambda_mga: 0.3320\n",
      "Val Acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 60]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 28.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0879, Loss: 0.1061\n",
      "[Epoch 60] lambda_mga: 0.3360\n",
      "Val Acc: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 61]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9721, Loss: 0.0914\n",
      "[Epoch 61] lambda_mga: 0.3400\n",
      "Val Acc: 0.8750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 62]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.4898, Loss: 0.0919\n",
      "[Epoch 62] lambda_mga: 0.3440\n",
      "Val Acc: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 63]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.4094, Loss: 0.0960\n",
      "[Epoch 63] lambda_mga: 0.3480\n",
      "Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 64]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7310, Loss: 0.0928\n",
      "[Epoch 64] lambda_mga: 0.3520\n",
      "Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 65]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.0793, Loss: 0.0876\n",
      "[Epoch 65] lambda_mga: 0.3560\n",
      "Val Acc: 0.8975\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 66]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.0793, Loss: 0.0854\n",
      "[Epoch 66] lambda_mga: 0.3600\n",
      "Val Acc: 0.9000\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 67]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9453, Loss: 0.0819\n",
      "[Epoch 67] lambda_mga: 0.3640\n",
      "Val Acc: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 68]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9185, Loss: 0.0871\n",
      "[Epoch 68] lambda_mga: 0.3680\n",
      "Val Acc: 0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 69]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.2401, Loss: 0.0830\n",
      "[Epoch 69] lambda_mga: 0.3720\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 70]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4812, Loss: 0.0733\n",
      "[Epoch 70] lambda_mga: 0.3760\n",
      "Val Acc: 0.9038\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 71]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7310, Loss: 0.0990\n",
      "[Epoch 71] lambda_mga: 0.3800\n",
      "Val Acc: 0.8413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 72]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.2401, Loss: 0.0802\n",
      "[Epoch 72] lambda_mga: 0.3840\n",
      "Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 73]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3558, Loss: 0.0955\n",
      "[Epoch 73] lambda_mga: 0.3880\n",
      "Val Acc: 0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 74]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9453, Loss: 0.0863\n",
      "[Epoch 74] lambda_mga: 0.3920\n",
      "Val Acc: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 75]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 33.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.0793, Loss: 0.0848\n",
      "[Epoch 75] lambda_mga: 0.3960\n",
      "Val Acc: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 76]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 28.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.1061, Loss: 0.0825\n",
      "[Epoch 76] lambda_mga: 0.4000\n",
      "Val Acc: 0.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 77]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 28.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.1865, Loss: 0.0789\n",
      "[Epoch 77] lambda_mga: 0.4040\n",
      "Val Acc: 0.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 78]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6956, Loss: 0.0684\n",
      "[Epoch 78] lambda_mga: 0.4080\n",
      "Val Acc: 0.8925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 79]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5080, Loss: 0.0737\n",
      "[Epoch 79] lambda_mga: 0.4120\n",
      "Val Acc: 0.8962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 80]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6956, Loss: 0.0720\n",
      "[Epoch 80] lambda_mga: 0.4160\n",
      "Val Acc: 0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 81]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.8382, Loss: 0.0838\n",
      "[Epoch 81] lambda_mga: 0.4200\n",
      "Val Acc: 0.9050\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 82]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8296, Loss: 0.0653\n",
      "[Epoch 82] lambda_mga: 0.4240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 83]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7224, Loss: 0.0638\n",
      "[Epoch 83] lambda_mga: 0.4280\n",
      "Val Acc: 0.8962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 84]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 26.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5616, Loss: 0.0735\n",
      "[Epoch 84] lambda_mga: 0.4320\n",
      "Val Acc: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 85]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.0793, Loss: 0.0823\n",
      "[Epoch 85] lambda_mga: 0.4360\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 86]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6688, Loss: 0.0709\n",
      "[Epoch 86] lambda_mga: 0.4400\n",
      "Val Acc: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 87]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7846, Loss: 0.0810\n",
      "[Epoch 87] lambda_mga: 0.4440\n",
      "Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 88]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8028, Loss: 0.0622\n",
      "[Epoch 88] lambda_mga: 0.4480\n",
      "Val Acc: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 89]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8028, Loss: 0.0669\n",
      "[Epoch 89] lambda_mga: 0.4520\n",
      "Val Acc: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 90]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.2047, Loss: 0.0563\n",
      "[Epoch 90] lambda_mga: 0.4560\n",
      "Val Acc: 0.8950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 91]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5616, Loss: 0.0697\n",
      "[Epoch 91] lambda_mga: 0.4600\n",
      "Val Acc: 0.8988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 92]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 30.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8028, Loss: 0.0669\n",
      "[Epoch 92] lambda_mga: 0.4640\n",
      "Val Acc: 0.8912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 93]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:06<00:00, 33.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6152, Loss: 0.0678\n",
      "[Epoch 93] lambda_mga: 0.4680\n",
      "Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 94]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 31.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8296, Loss: 0.0658\n",
      "[Epoch 94] lambda_mga: 0.4720\n",
      "Val Acc: 0.8975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 95]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5080, Loss: 0.0647\n",
      "[Epoch 95] lambda_mga: 0.4760\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 96]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8564, Loss: 0.0664\n",
      "[Epoch 96] lambda_mga: 0.4800\n",
      "Val Acc: 0.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 97]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7492, Loss: 0.0584\n",
      "[Epoch 97] lambda_mga: 0.4840\n",
      "Val Acc: 0.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 98]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.9100, Loss: 0.0617\n",
      "[Epoch 98] lambda_mga: 0.4880\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 99]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7760, Loss: 0.0656\n",
      "[Epoch 99] lambda_mga: 0.4920\n",
      "Val Acc: 0.8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5884, Loss: 0.0733\n",
      "[Epoch 100] lambda_mga: 0.4960\n",
      "Val Acc: 0.8912\n",
      "\n",
      "ğŸ“Š Test Evaluation:\n",
      "âœ… Test Accuracy         : 89.38%\n",
      "ğŸ¯ AUC                   : 0.9391\n",
      "ğŸ“Œ Precision             : 0.9104\n",
      "ğŸ“Œ Recall (Sensitivity)  : 0.9295\n",
      "ğŸ“Œ Specificity           : 0.8255\n",
      "ğŸ“Œ F1 Score              : 0.9199\n",
      "ğŸ“Œ Balanced Accuracy     : 0.8775\n",
      "ğŸ“Œ MCC                   : 0.7626\n",
      "\n",
      "ğŸ“Œ Confusion Matrix:\n",
      "[[227  48]\n",
      " [ 37 488]]\n",
      "\n",
      "ğŸ“ í…ŒìŠ¤íŠ¸ ì§€í‘œ ì €ì¥ ì™„ë£Œ: logs/final_test_metrics.csv\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mí˜„ì¬ ì…€ ë˜ëŠ” ì´ì „ ì…€ì—ì„œ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ëŠ” ë™ì•ˆ Kernelì´ ì¶©ëŒí–ˆìŠµë‹ˆë‹¤. \n",
      "\u001b[1;31mì…€ì˜ ì½”ë“œë¥¼ ê²€í† í•˜ì—¬ ê°€ëŠ¥í•œ ì˜¤ë¥˜ ì›ì¸ì„ ì‹ë³„í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì„ ë³´ë ¤ë©´ <a href='https://aka.ms/vscodeJupyterKernelCrash'>ì—¬ê¸°</a>ë¥¼ í´ë¦­í•˜ì„¸ìš”. \n",
      "\u001b[1;31mìì„¸í•œ ë‚´ìš©ì€ Jupyter <a href='command:jupyter.viewOutput'>ë¡œê·¸</a>ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
     ]
    }
   ],
   "source": [
    "# ë² ìŠ¤íŠ¸ ëª¨ë¸ ì‹œë“œ ê³ ì •\n",
    "\n",
    "# ì „ì²´ì½”ë“œ: ResNet18 + CBAM + MGA Loss + Lambda Scheduling (CE Weight ver)\n",
    "\n",
    "import os, re, numpy as np, torch, gc\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "# -------------------- ë””ë°”ì´ìŠ¤ ì„¤ì • --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • --------------------\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "seed_list = [42, 123, 2025, 777, 999]\n",
    "all_metrics = []\n",
    "\n",
    "# lambda MGA ìŠ¤ì¼€ì¤„ ì„¤ì •\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "total_epochs = num_epochs\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # numpy or tensor ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜\n",
    "    transforms.Resize((224, 224)),  # ì´ë¯¸ì§€ë¥¼ 224x224ë¡œ resize\n",
    "    transforms.RandomHorizontalFlip(),  # ì´ë¯¸ì§€ë¥¼ 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „\n",
    "    transforms.RandomRotation(10),  # ì´ë¯¸ì§€ë¥¼ -10ë„ ~ +10ë„ ì‚¬ì´ë¡œ ëœë¤ íšŒì „, ì´¬ì˜ ìì„¸ë‚˜ ê¸°ìš¸ì–´ì§ì— ëŒ€í•œ íšŒì „ ê°•ê±´ì„±í™•ë³´\n",
    "    transforms.ToTensor(),  # PILì´ë¯¸ì§€ -> PyTorch Tensorë¡œ ë³€í™˜, (H, W, C) -> (C, H, W), ê°’ë„ 0255 -> 01 ì‚¬ì´ì¦ˆë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
    "    transforms.Normalize([0.5], [0.5]), # í‰ê·  0.5, í‘œì¤€í¸ì°¨ 0.5ë¡œ ì •ê·œí™” -> ê²°ê³¼ì ìœ¼ë¡œ 01 -> 11ë¡œ ë°”ë€œ\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
    "])  # ì „ì²´ ì´ë¯¸ì§€ì˜ ì¼ë¶€ë¶„ ì§€ìš°ê³  0ìœ¼ë¡œ ì±„ì›€ (ê²€ì€ ì‚¬ê°í˜• ìƒê¹€)\n",
    "    # p=0.5 : 50% í™•ë¥ ë¡œ ì´ ì¦ê°• ì ìš©\n",
    "    # scale : ì „ì²´ ì´ë¯¸ì§€ ëŒ€ë¹„ ì‚­ì œ ì˜ì—­ì˜ í¬ê¸° ë¹„ìœ¨\n",
    "    # ratio : ì§€ìš°ëŠ” ì‚¬ê°í˜•ì˜ ê°€ë¡œ:ì„¸ë¡œ ë¹„ìœ¨ ë²”ìœ„\n",
    "    # value=0 : ì§€ìš´ ê³³ì„ ê²€ì€ìƒ‰(0)ìœ¼ë¡œ ë®ìŒ\n",
    "    # í CTì—ì„œ ë³‘ë³€ì´ í•­ìƒ ì¼ì •í•œ ìœ„ì¹˜ì— ë‚˜ì˜¤ì§€ ì•Šìœ¼ë‹ˆê¹Œ ëª¨ë¸ì´ íŠ¹ì • ìœ„ì¹˜ì— ê³¼ì í•©ë˜ëŠ”ê±¸ ë°©ì§€í•¨ (overfitting ì˜ˆë°©)\n",
    "\n",
    "# ê²€ì¦/í…ŒìŠ¤íŠ¸ëŠ” ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ê¹¨ê¸‹í•œ ìƒíƒœì˜ ì´ë¯¸ì§€ë¡œ ì •í™•ë„ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ ê²€ì¦ìš©ì€ ê¹”ë”í•˜ê²Œ\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # PIL ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜\n",
    "    transforms.Resize((224, 224)),  # ì‚¬ì´ì¦ˆ ë§ì¶”ê¸°\n",
    "    transforms.ToTensor(),  # PIL ì´ë¯¸ì§€ -> PyTorch Tensorë¡œ ë³€í™˜\n",
    "    transforms.Normalize([0.5], [0.5])  # ì •ê·œí™”\n",
    "])\n",
    "\n",
    "# ì‹œë“œ ê³ ì •\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)                         # íŒŒì´ì¬ random\n",
    "    np.random.seed(seed)                      # numpy\n",
    "    torch.manual_seed(seed)                   # torch CPU\n",
    "    torch.cuda.manual_seed(seed)              # torch GPU\n",
    "    torch.cuda.manual_seed_all(seed)          # multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # ì—°ì‚° ë™ì¼í•˜ê²Œ\n",
    "    torch.backends.cudnn.benchmark = False    # ì—°ì‚° ì†ë„ ìµœì í™” OFF (ê°™ì€ ì—°ì‚° ë³´ì¥)\n",
    "\n",
    "# -------------------- Bounding Boxë¥¼ Binary Maskë¡œ --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    # bbox_list : í•œ ì´ë¯¸ì§€ì— ë“¤ì–´ìˆëŠ” bounding box ë¦¬ìŠ¤íŠ¸\n",
    "    # image_size : ì¶œë ¥í•  ë§ˆìŠ¤í¬ í¬ê¸°. ë³´í†µ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ (height, width) -> ë””í´íŠ¸ëŠ” 224x224\n",
    "    # bboxë“¤ì„ binary maskë¡œ ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜\n",
    "    masks = []  # ì—¬ëŸ¬ ê°œì˜ bboxê°€ ë“¤ì–´ì˜¤ë‹ˆê¹Œ, ê°ê°ì˜ ë§ˆìŠ¤í¬ë¥¼ í•˜ë‚˜ì”© ë¦¬ìŠ¤íŠ¸ì— ìŒ“ê¸° ìœ„í•œ ë¹ˆ ë¦¬ìŠ¤íŠ¸\n",
    "    for bbox in bbox_list:  # bbox_listë¥¼ í•˜ë‚˜ì”© ëŒë©´ì„œ ì²˜ë¦¬ -> [x_min, y_min, x_max, y_max]ë„¤ ì¢Œí‘œë¡œ êµ¬ì„±ëœ í•˜ë‚˜ì˜ ì‚¬ê°í˜• ì˜ì—­ \n",
    "        mask = np.zeros(image_size, dtype=np.float32)   # 224x224ì§œë¦¬ 0ìœ¼ë¡œ ê½‰ ì°¬ 2D ë°°ì—´ì„ í•˜ë‚˜ ìƒì„±\n",
    "        # ë°°ê²½ì´ í° ì¢…ì´ë¥¼ ë§Œë“œëŠ” ëŠë‚Œìœ¼ë¡œ ë§Œë“¤ê³ , ì‚¬ê° ì˜ì—­ë§Œ 1ë¡œ ë§ì¹ í• ê±°ì„\n",
    "        x_min, y_min, x_max, y_max = bbox   # ê° bboxì˜ ë„¤ ì¢Œí‘œê°’ì„ ê°ê° ë³€ìˆ˜ë¡œ ì–¸íŒ©. -> ë§ˆìŠ¤í¬ì˜ í•´ë‹¹ ì˜ì—­ì— ì‚¬ê°í˜•ì„ ì¹ í•˜ê¸° ìœ„í•´ì„œ\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0    # y_min, y_max, x_min, x_maxê¹Œì§€ì˜ ë²”ìœ„ì— 1.0ì„ ì±„ì›Œ ë„£ìŒ\n",
    "        # -> ë§ˆìŠ¤í¬ì—ì„œ bboxì— í•´ë‹¹í•˜ëŠ” ì‚¬ê°í˜• ì˜ì—­ë§Œ 1(foreground)ë¡œ í‘œì‹œë¨. ë‚˜ë¨¸ì§„ ì—¬ì „íˆ 0(background)\n",
    "        masks.append(mask)  # ì§€ê¸ˆ ë§Œë“  ë§ˆìŠ¤í¬(2D ë°°ì—´)ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ -> [mask1, mask2, ...]ì´ë ‡ê²Œ ìŒ“ì„\n",
    "\n",
    "    masks = np.stack(masks) # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ 3D ë°°ì—´ë¡œ í•©ì¹¨ -> shape : [N, H, W] -> Nì€ bbox ê°œìˆ˜\n",
    "    masks = np.expand_dims(masks, axis=1)   # í…ì„œ shapeì„ [N, 1, H, W]ë¡œ ë°”ê¿ˆ\n",
    "    # PyTorch ëª¨ë¸ì—ì„œ ê¸°ëŒ€í•˜ëŠ” (batch x channel x height x width) í¬ë§· ë§ì¶”ê¸°\n",
    "\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "    # numpy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜í•´ì„œ ë¦¬í„´\n",
    "\n",
    "    # í•œ bbox â†’ í•˜ë‚˜ì˜ ë§ˆìŠ¤í¬ â†’ ì—¬ëŸ¬ ê°œë©´ ìŒ“ì•„ì„œ batch í˜•íƒœë¡œ\n",
    "# -------------------- Bounding Box CSV ë¡œë“œ --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    # csv_path : bounding box ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” CSV íŒŒì¼ ê²½ë¡œ\n",
    "    # ë°˜í™˜ê°’ : {filename:[bbox1, bbox2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬\n",
    "    df = pd.read_csv(csv_path)  # CSVíŒŒì¼ì„ pandas DataFrameìœ¼ë¡œ ì½ì–´ì˜´\n",
    "    bbox_dict = {}\n",
    "    # key : ìŠ¬ë¼ì´ìŠ¤ íŒŒì¼ ì´ë¦„ (ex. \"LIDC-IDRI-1012_slice0004.npy\")\n",
    "    # value : í•´ë‹¹ ìŠ¬ë¼ì´ìŠ¤ì— ì¡´ì¬í•˜ëŠ” bboxë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "    for _, row in df.iterrows():    # DataFrameì˜ ëª¨ë“  í–‰(row)ë¥¼ í•˜ë‚˜ì”© ìˆœíšŒ\n",
    "        # rowëŠ” í•œ ì¤„(=í•œ bbox)ì˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆìŒ\n",
    "\n",
    "        pid = row['pid']    # í™˜ì ID (ì˜ˆ: \"LIDC-IDRI-1012\") -> ì´ë¯¸ì§€ ì´ë¦„ êµ¬ì„± ìš”ì†Œ\n",
    "        slice_str = row['slice']    # ìŠ¬ë¼ì´ìŠ¤ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” ë¬¸ìì—´ (ì˜ˆ: \"slice_0039\")\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])  # re.findall()ë¡œ ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ë½‘ì•„ëƒ„\n",
    "        # \"slice_0039\" -> ['0039'] -> [0] -> 39 (ìŠ¬ë¼ì´ìŠ¤ ë²ˆí˜¸ë¥¼ ì •ìˆ˜ë¡œ ì¶”ì¶œí•¨)\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"   # íŒŒì¼ëª… êµ¬ì„± (ì˜ˆ: \"LIDC-IDRI-1012_slice0039.npy\")\n",
    "        # {:04d}ëŠ” 4ìë¦¬ ì •ìˆ˜ë¡œ ë§Œë“¤ê³  ë¹ˆìë¦¬ëŠ” 0ìœ¼ë¡œ ì±„ì›Œì¤Œ (39 -> 0039)\n",
    "        bbox = eval(row['bb'])  # row['bb']ëŠ” ë¬¸ìì—´ í˜•íƒœì˜ bbox (ì˜ˆ: \"[20, 30, 80, 100]\")\n",
    "        # eval()ì„ ì¨ì„œ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ê¿”ì¤Œ\n",
    "        # ì£¼ì˜ : ë³´ì•ˆ ìƒ ìœ„í—˜í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ì§€ë§Œ, ì—¬ê¸´ ë‚´ë¶€ ë°ì´í„°ë¼ ì‚¬ìš©ì¤‘\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)    # fnameì´ë¼ëŠ” keyê°€ ë”•ì…”ë„ˆë¦¬ì— ì—†ìœ¼ë©´ []ë¡œ ì´ˆê¸°í™”í•˜ê³ ,\n",
    "        # ê±°ê¸°ì— bboxë¥¼ append -> ìŠ¬ë¼ì´ìŠ¤ í•˜ë‚˜ì— bbox ì—¬ëŸ¬ê°œ ìˆì–´ë„ ì „ë¶€ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ì•„ì¤Œ\n",
    "    return bbox_dict    # ìµœì¢…ì ìœ¼ë¡œ {filename: [bbox1, bbox2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "# ì‹¤ì œë¡œ csv_pathì— ìˆëŠ” ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™€ì„œ bbox_dictì— ì €ì¥í•¨\n",
    "# ì´ê±¸ ë‚˜ì£¼ì— Dataset í´ë˜ìŠ¤ì—ì„œ fname ê¸°ì¤€ì„ êº¼ë‚´ì“°ê²Œ ë¨\n",
    "\n",
    "# -------------------- ë¼ë²¨ ì¶”ì¶œ --------------------\n",
    "def extract_label_from_filename(fname): # fname : íŒŒì¼ ì´ë¦„ (ì˜ˆ: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # ì´ ì´ë¦„ì—ì„œ malignancy score(ì•…ì„±ë„ ì ìˆ˜)ë¥¼ ì¶”ì¶œí•´ì„œ ë¼ë²¨ë¡œ ë³€í™˜\n",
    "    try:    # íŒŒì¼ëª…ì´ ì´ìƒí•˜ê±°ë‚˜ ì—ëŸ¬ë‚˜ë©´ exceptë¡œ ë¹ ì ¸ë‚˜ê°€ì„œ None ë°˜í™˜í•¨ (ì•ˆì „ì¥ì¹˜)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # íŒŒì¼ëª…ì—ì„œ _ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ê²ƒë“¤ ì¤‘ì— ë§ˆì§€ë§‰ì—êº¼ë¥¼ ê°€ì ¸ì™€ì„œ .npyë¥¼ \"\" ì´ë ‡ê²Œ ê³µë°±ìœ¼ë¡œ ì²˜ë¦¬í•¨\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- ì´ê²Œ malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # ë¼ë²¨ ê²°ì • ë¡œì§ìœ¼ë¡œ\n",
    "        # score == 3 -> ì¤‘ë¦½ -> None ë°˜í™˜ -> í•™ìŠµì—ì„œ ì œì™¸\n",
    "        # score >= 4 -> ì•”(ì–‘ì„±) -> 1\n",
    "        # score <= 2 -> ì •ìƒ(ìŒì„±) -> 0\n",
    "        # int(score >= 4)ëŠ” íŒŒì´ì¬ì—ì„œ True -> 1\n",
    "        # False -> 0 ì´ë‹ˆê¹ ìë™ìœ¼ë¡œ ë¼ë²¨ì´ ë¨\n",
    "    except:\n",
    "        return None\n",
    "        # í˜¹ì‹œ splitì´ë‚˜ replace, int ë³€í™˜ì´ ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ None ë°˜í™˜í•˜ê³  ë¬´ì‹œ\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    # PyTorchì˜ Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†í•´ì„œ ì»¤ã…¡í…€ ë°ì´í„°ì…‹ ì •ì˜\n",
    "    # ë‚˜ì¤‘ì— DataLoaderë‘ ê°™ì´ ì“°ì´ê¸° ë•Œë¬¸ì— __len__()ì´ë‘ __getitem__()ì„ ê¼­ ë„£ì–´ì¤˜ì•¼í•¨\n",
    "    def __init__(self, paths, labels, transform=None):  # ìƒì„±ì : ì„¸ê°œì˜ ì¸ìë¥¼ ë°›ìŒ\n",
    "        # paths : ì´ë¯¸ì§€ .npy íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "        # labels : ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ (0, 1 or None)\n",
    "        # transform : ì´ë¯¸ì§€ ì¦ê°• ì„¤ì • (train_transform, val_transform ë“±)\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # ë°›ì€ ì¸ìë¥¼ ë©¤ë²„ ë³€ìˆ˜ë¡œ ì €ì¥. ë‚˜ì¤‘ì— gettem()ì—ì„œ ì ‘ê·¼í•¨\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoaderê°€ ì´ê±¸ í˜¸ì¶œí•  ë•Œ indexì— í•´ë‹¹í•˜ëŠ” sample í•˜ë‚˜ë¥¼ ë°˜í™˜\n",
    "        # ì´ë¯¸ì§€, ë¼ë²¨, ë§ˆìŠ¤í¬( = MGAìš© target) 3ê°œë¥¼ ë¦¬í„´í•¨\n",
    "        file_path = self.paths[idx] # íŒŒì¼ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        label = self.labels[idx]    # ë¼ë²¨ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        fname = os.path.basename(file_path) # ì „ì²´ ê²½ë¡œì—ì„œ íŒŒì¼ ì´ë¦„ë§Œ ì¶”ì¶œ -> ë‚˜ì¤‘ì— bbox_dict[fname] ì°¾ì„ë•Œ ì“°ì„\n",
    "\n",
    "        img = np.load(file_path)    # .npy íŒŒì¼ì—ì„œ CT ìŠ¬ë¼ì´ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° -> í‘ë°± CT ì´ë¯¸ì§€, shapeì€ (H, W)\n",
    "        img = np.clip(img, -1000, 400)  # CT ì´ë¯¸ì§€ HU ê°’ì´ ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´ ë…¸ì´ì¦ˆ -> -1000(ê³µê¸°) ~ 400(ì—°ì¡°ì§)ìœ¼ë¡œ í´ë¦¬í•‘í•´ì„œ ë…¸ì´ì¦ˆ ì œê±°\n",
    "        img = (img + 1000) / 1400.  # ì •ê·œí™” : -1000 -> 0, 400 -> 1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë°”ê¿”ì¤Œ -> ëª¨ë¸ì´ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•¨\n",
    "        img = np.expand_dims(img, axis=-1)  # CTëŠ” ì±„ë„ì´ 1ê°œë‹ˆê¹ (H, W) -> (H, w, 1)ë¡œ ë°”ê¿”ì¤Œ\n",
    "        # ë‚˜ì¤‘ì— PyTorchì—ì„œ (C, H, W)ë¡œ ë°”ê¾¸ê¸° ìœ„í•¨\n",
    "\n",
    "        if self.transform:  # ë°ì´í„° ì¦ê°•(transform)ì´ ìˆë‹¤ë©´ ì ìš©\n",
    "            img = self.transform(img)   \n",
    "        else:   # ì—†ìœ¼ë©´ numpy -> tensor ë³€í™˜í•˜ê³  (H, W, C) -> (C, H, W)ë¡œ ìˆœì„œ ë°”ê¿ˆ\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "\n",
    "        if fname in bbox_dict:  # ì´ ì´ë¯¸ì§€ì— bboxê°€ ì¡´ì¬í•˜ë©´ -> ë§ˆìŠ¤í¬ ìƒì„±\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(224, 224))\n",
    "            # image_sizeëŠ” transformê³¼ ë™ì¼í•˜ê²Œ 224x224\n",
    "        else:   # bboxê°€ ì—†ë‹¤ë©´ ì „ë¶€ 0ìœ¼ë¡œ ì±„ì›Œì§„ ë§ˆìŠ¤í¬ ìƒì„± -> MGA Loss ê³„ì‚° ì‹œ ì°¸ê³ ìš©ìœ¼ë¡œ ì“°ì¼ ìˆ˜ ìˆìŒ\n",
    "            mask = torch.zeros((1, 224, 224), dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask.squeeze(0)\n",
    "        # ë°˜í™˜ê°’ 3ê°œ :\n",
    "        # img : shape[1, 224, 224]\n",
    "        # label : int(0 or 1)\n",
    "        # mask : [224, 224] <- squeezeë¡œ ì±„ë„ 1ê°œ ì œê±°\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    # ì „ì²´ ë°ì´í„°ì…‹ ê¸¸ì´ ë°˜í™˜ -> DataLoaderê°€ ì•„ë¼ì•¼ ë°°ì¹˜ ìª¼ê°¤ ìˆ˜ ìˆìŒ.\n",
    "\n",
    "# -------------------- CBAM ì •ì˜ (MGA í¬í•¨) --------------------\n",
    "# 2 Step : Channel Attention(ì–´ë–¤ ì±„ë„ì— ì§‘ì¤‘í• ì§€) * Spatial Attention(ì–´ë””ì— ì§‘ì¤‘í• ì§€) = ìµœì¢… Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # ì…ë ¥ feature mapì˜ ì±„ë„ë³„ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•´ì„œ ê°•ì¡°í•¨\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : ì…ë ¥ ì±„ë„ ìˆ˜\n",
    "        # ratio : ì¤‘ê°„ ì±„ë„ ì¶•ì†Œ ë¹„ìœ¨. ê¸°ë³¸ 1/16ìœ¼ë¡œ bottlenck êµ¬ì„±\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP ì—­í• ì„ í•˜ëŠ” 1x1 conv ë¸”ë¡ -> ì±„ë„ ì••ì¶• -> ë¹„ì„ í˜• -> ë³µì› (sharedëŠ” avg/max ë‘˜ë‹¤ì—ì„œ ê°™ì´ ì”€)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # í‰ê·  í’€ë§ / ìµœëŒ€ í’€ë§ìœ¼ë¡œ ë‘ê°€ì§€ ì „ì—­ ì •ë³´ë¥¼ ì¶”ì¶œ\n",
    "        # ë§ˆì§€ë§‰ sigmoidëŠ” attention weightë¡œ ìŠ¤ì¼€ì¼ë§\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max í’€ë§ ê²½ê³¼ë¥¼ ê°ê° shape MLPì— í†µê³¼ì‹œí‚¤ê³ , ë”í•œ í›„ sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> ì±„ë„ë§ˆë‹¤ ì¤‘ìš”ë„ weightë¥¼ ê³±í•˜ê²Œ ë¨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # ê³µê°„ì ìœ¼ë¡œ ì–´ë””ì— ì§‘ì¤‘í• ì§€ë¥¼ ê²°ì • -> ê° ì±„ë„ ë‚´ë¶€ì—ì„œ ì¤‘ìš”í•œ ìœ„ì¹˜ ì°¾ê¸°\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # ì±„ë„ ì°¨ì›ì€ í‰ê· , ìµœëŒ€ ë‘ ê°œë§Œ ì¨ì„œ concat\n",
    "    # ê·¸ê±¸ 1ì±„ë„ë¡œ ì¤„ì—¬ì£¼ëŠ” conv\n",
    "    # ì»¤ë„ í¬ê¸° k=7ì´ë©´ ë„“ì€ ì˜ì—­ê¹Œì§€ ê°ì§€ ê°€ëŠ¥\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # ì…ë ¥ feature mapì—ì„œ :\n",
    "    # í‰ê· , ìµœëŒ€ê°’ì„ ê° spatial ìœ„ì¹˜ë³„ë¡œ êµ¬í•¨ -> [B, 1, H, W] ë‘ ê°œ\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> ìœ„ì¹˜ë³„ ì¤‘ìš”ë„ map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttentionì„ ë‚´ë¶€ì— ì„ ì–¸\n",
    "    # MGAë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ attention mapì„ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ í¬í•¨\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # ì±„ë„ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ìœ„ì¹˜ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ë‘˜ ë‹¤ ë°˜ì˜ëœ ìµœì¢… feature map ë¦¬í„´\n",
    "\n",
    "# -------------------- ResNet18 + CBAM ëª¨ë¸ ì •ì˜ --------------------\n",
    "# BasicBlockCBAM : ResNetì˜ ê¸°ë³¸ Residual Block í•˜ë‚˜ë¥¼ ì •ì˜\n",
    "# â†’ conv â†’ BN â†’ ReLU â†’ conv â†’ BN â†’ (CBAM optional) â†’ Add â†’ ReLU\n",
    "\n",
    "# ResNet18_CBAM : ResNet18 êµ¬ì¡°ë¡œ ì „ì²´ ë„¤íŠ¸ì›Œí¬ ìŒ“ê¸°\n",
    "# â†’ conv1 â†’ layer1~3 â†’ layer4 â†’ avgpool â†’ fc\n",
    "\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        # ì…ë ¥ ì±„ë„: in_planes, ì¶œë ¥ ì±„ë„: out_planes, 3x3 ì»¤ë„, padding=1ë¡œ í¬ê¸° ìœ ì§€, strideë¡œ í¬ê¸° ì¡°ì ˆ\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)   # ë°°ì¹˜ ì •ê·œí™”\n",
    "        self.relu = nn.ReLU()   # ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        # ë‘ë²ˆì§¸ conv, ì±„ë„ ìˆ˜ ìœ ì§€, í¬ê¸° ìœ ì§€\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)   # ë°°ì¹˜ ì •ê·œí™”\n",
    "\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None  # CBAM ëª¨ë“ˆ ì‚¬ìš© ì—¬ë¶€\n",
    "        self.downsample = downsample    # residual ì—°ê²° ì‹œ ì°¨ì› ë§ì¶”ëŠ” conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # skip connectionìš© ì…ë ¥ ì €ì¥\n",
    "\n",
    "        out = self.conv1(x) # ì²« ë²ˆì§¸ conv\n",
    "        out = self.bn1(out) # ì •ê·œí™”\n",
    "        out = self.relu(out)  # í™œì„±í™”\n",
    "\n",
    "        out = self.conv2(out)   # ë‘ ë²ˆì§¸ conv\n",
    "        out = self.bn2(out) # ì •ê·œí™”\n",
    "\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)    # CBAM ì ìš©\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)   # shortcut ê²½ë¡œ ë³´ì •\n",
    "\n",
    "        out += residual # skip connection\n",
    "        out = self.relu(out)    # ì¶œë ¥ì— ReLU ì ìš©\n",
    "\n",
    "        return out  # ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64 # ì¡°ê¸° ì…ë ¥ ì±„ë„ ìˆ˜ ì„¤ì •\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # ì…ë ¥: [B, 1, 224, 224] -> ì¶œë ¥: [B, 64, 112, 112], í° ì»¤ë„ë¡œ ë„“ì€ ì˜ì—­ ìº¡ì²˜ \n",
    "        self.bn1 = nn.BatchNorm2d(64)   # ì •ê·œí™”\n",
    "        self.relu = nn.ReLU()   # í™œì„±í™”\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # í’€ë§: [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        self.layer1 = self._make_layer(64, blocks=2)  # [B, 64, 56, 56] ìœ ì§€\n",
    "        self.layer2 = self._make_layer(128, blocks=2, stride=2)  # [B, 128, 28, 28] ë‹¤ìš´ìƒ˜í”Œë§\n",
    "        self.layer3 = self._make_layer(256, blocks=2, stride=2)  # [B, 256, 14, 14] ë‹¤ìš´ìƒ˜í”Œë§\n",
    "        self.layer4 = self._make_layer(512, blocks=2, stride=2, use_cbam=False)  # [B, 512, 7, 7], CBAM ë¯¸ì‚¬ìš©\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # [B, 512, 7, 7] -> [B, 512, 1, 1]\n",
    "        self.fc = nn.Linear(512, num_classes)  # [B, 512] -> [B, num_classes]\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        # Planes : í•´ë‹¹ ë ˆì´ì–´ì˜ ì¶œë ¥ ì±„ë„ ìˆ˜\n",
    "        # # blocks : ë¸”ë¡ ìˆ˜\n",
    "        # stride=2ì¸ ê²½ìš° ë‹¤ìš´ìƒ˜í”Œë§ (í•´ìƒë„ ì ˆë°˜)\n",
    "\n",
    "        downsample = None   # ìŠ¤í‚µ ì—°ê²°í•´ì„œ ì…ë ¥/ì¶œë ¥ í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ë§ì¶°ì•¼ í•¨\n",
    "\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                # 1x1 convë¡œ ì±„ë„ ìˆ˜   ë° ê³µê°„ í¬ê¸° ë§ì¶¤\n",
    "                nn.BatchNorm2d(planes))\n",
    "            \n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam=use_cbam)]\n",
    "        # ì²« ë¸”ë¡ì€ ë‹¤ìš´ìƒ˜í”Œë§ ì ìš© ê°€ëŠ¥ì„± ìˆìŒ\n",
    "        self.in_planes = planes # ì´í›„ ë¸”ë¡ì„ ìœ„í•œ ì…ë ¥ ì±„ë„ ì—…ë°ì´íŠ¸\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "            # ë‚˜ë¨¸ì§€ ë¸”ë¡ì€ stride=1ë¡œ ë™ì¼í•œ í•´ìƒë„ ìœ ì§€\n",
    "\n",
    "        return nn.Sequential(*layers)   # ë¸”ë¡ë“¤ì„ Seguentialë¡œ ë¬¶ì–´ ë°˜í™˜\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # ì…ë ¥: [B, 1, 224, 224] -> [B, 64, 112, 112]\n",
    "        x = self.bn1(x)    # ì •ê·œí™”\n",
    "        x = self.relu(x)   # ReLU í™œì„±í™”\n",
    "        x = self.maxpool(x)  # [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        x = self.layer1(x)  # [B, 64, 56, 56]\n",
    "        x = self.layer2(x)  # [B, 128, 28, 28]\n",
    "        x = self.layer3(x)  # [B, 256, 14, 14]\n",
    "        x = self.layer4(x)  # [B, 512, 7, 7]\n",
    "\n",
    "        x = self.avgpool(x)  # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # [B, 512]\n",
    "        x = self.fc(x)  # [B, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------- í•™ìŠµ ë£¨í”„ --------------------\n",
    "def run(seed=42):\n",
    "    seed_everything(seed)\n",
    "\n",
    "\n",
    "    # ëª¨ë“  CT ìŠ¬ë¼ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸° (LIDC-IDRI í™˜ì í´ë” ì•ˆì˜ .npy íŒŒì¼ë“¤)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "\n",
    "    # íŒŒì¼ ê²½ë¡œì™€ í•´ë‹¹ íŒŒì¼ì˜ ë¼ë²¨ì„ íŠœí”Œë¡œ ì €ì¥\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    # ë¼ë²¨ì´ Noneì´ ì•„ë‹Œ ë°ì´í„°ë§Œ í•„í„°ë§ (ì¤‘ë¦½ ì œì™¸)\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "\n",
    "    # íŒŒì¼, ë¼ë²¨ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„°ë¥¼ train(70%), val(15%), test(15%)ë¡œ ë¶„í• \n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(\n",
    "    files, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(\n",
    "    temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    train_dataset = CTDataset(train_files, train_labels, transform=train_transform)\n",
    "    val_dataset = CTDataset(val_files, val_labels, transform=val_transform)\n",
    "    test_dataset = CTDataset(test_files, test_labels, transform=val_transform)\n",
    "\n",
    "    # ë°ì´í„° ë¡œë”\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    # ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.6653, 0.3347], device=device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_acc = 0.0  # ê°€ì¥ ë†’ì€ val accuracyë¥¼ ì €ì¥\n",
    "    save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"r18_cbam_mga_aug_lr4_ep100_weight_seedfix.pth\")\n",
    "\n",
    "    # í•™ìŠµ ë£¨í”„ ì‹œì‘\n",
    "    for epoch in range(num_epochs):\n",
    "        # MGA ìŠ¤ì¼€ì¥´ë§: ì´ˆê¸° lambda -> ì ì  ì¦ê°€ì‹œí‚´\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "\n",
    "        model.train()  # í•™ìŠµ ëª¨ë“œë¡œ ë³€ê²½\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # í•œ epoch ë™ì•ˆ ëª¨ë“  train ë°ì´í„°ë¥¼ í•™ìŠµ\n",
    "        for images, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)  # forward pass\n",
    "            ce_loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "            # -------------------- MGA Loss ê³„ì‚° ìœ„ì¹˜ --------------------\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # attention map êº¼ë‚´ì˜¤ê¸°\n",
    "\n",
    "            if attn_map is not None:\n",
    "                attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                attn_loss = F.mse_loss(attn_map, masks)  # maskì™€ì˜ MSE loss\n",
    "                loss = ce_loss + lambda_mga * attn_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Acc: {(correct/total)*100:.4f}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] lambda_mga: {lambda_mga:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()  # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "\n",
    "        # -------------------- ê²€ì¦ --------------------\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iamegs, labels, masks in val_loader:\n",
    "                iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "                outputs = model(iamegs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"âœ… Saved best model!\")\n",
    "\n",
    "    # -------------------- í…ŒìŠ¤íŠ¸ --------------------\n",
    "    print(\"\\nğŸ“Š Test Evaluation:\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # numpy ë°°ì—´ë¡œ ë³€í™˜\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    # ì§€í‘œ ê³„ì‚°\n",
    "    from sklearn.metrics import (\n",
    "        classification_report, roc_auc_score, confusion_matrix,\n",
    "        precision_score, recall_score, balanced_accuracy_score,\n",
    "        matthews_corrcoef, f1_score\n",
    "    )\n",
    "\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    # ğŸ“‹ ì¶œë ¥\n",
    "    print(f\"âœ… Test Accuracy         : {acc*100:.2f}%\")\n",
    "    print(f\"ğŸ¯ AUC                   : {auc:.4f}\")\n",
    "    print(f\"ğŸ“Œ Precision             : {precision:.4f}\")\n",
    "    print(f\"ğŸ“Œ Recall (Sensitivity)  : {recall:.4f}\")\n",
    "    print(f\"ğŸ“Œ Specificity           : {specificity:.4f}\")\n",
    "    print(f\"ğŸ“Œ F1 Score              : {f1:.4f}\")\n",
    "    print(f\"ğŸ“Œ Balanced Accuracy     : {balanced_acc:.4f}\")\n",
    "    print(f\"ğŸ“Œ MCC                   : {mcc:.4f}\")\n",
    "    print(\"\\nğŸ“Œ Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # ğŸ“ CSVë¡œ ì €ì¥\n",
    "    test_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"phase\": \"test\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "\n",
    "    csv_path = \"logs/final_test_metrics.csv\"\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=test_metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(test_metrics)\n",
    "\n",
    "    print(f\"\\nğŸ“ í…ŒìŠ¤íŠ¸ ì§€í‘œ ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "\n",
    "# ì§„ì…ì \n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2569359/2177874015.py:60: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(p=0.4, max_holes=1, max_height=32, max_width=32),\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ResNet18_CBAM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 373\u001b[39m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# ì‹¤í–‰\u001b[39;00m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m373\u001b[39m     \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 255\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    252\u001b[39m val_loader = DataLoader(CTDataset(val_files, val_labels, transform=val_transform), batch_size=batch_size)\n\u001b[32m    253\u001b[39m test_loader = DataLoader(test_dataset, batch_size=batch_size)\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m model = \u001b[43mResNet18_CBAM\u001b[49m().to(device)\n\u001b[32m    256\u001b[39m criterion = FocalLoss(weight=torch.tensor([\u001b[32m0.65\u001b[39m, \u001b[32m0.35\u001b[39m], device=device), gamma=\u001b[32m2.0\u001b[39m)\n\u001b[32m    257\u001b[39m optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
      "\u001b[31mNameError\u001b[39m: name 'ResNet18_CBAM' is not defined"
     ]
    }
   ],
   "source": [
    "# âœ… ì „ì²´ì½”ë“œ: ResNet18 + CBAM + MGA + Lambda Scheduling + FocalLoss + TTA\n",
    "# âœ… í•µì‹¬: TTADataset ì ìš© + ë‹¤ì–‘í•œ TTA inference ì§€ì›\n",
    "\n",
    "import os, re, numpy as np, torch, gc, csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score, balanced_accuracy_score, matthews_corrcoef\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ê²½ë¡œ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "batch_size = 16\n",
    "num_epochs = 150\n",
    "learning_rate = 1e-4\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "\n",
    "# FocalLoss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = F.log_softmax(input, dim=1)\n",
    "        ce_loss = F.nll_loss(logp, target, weight=self.weight, reduction='none')\n",
    "        p = torch.exp(-ce_loss)\n",
    "        return ((1 - p) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "# Transform ì„¤ì •\n",
    "def get_tta_transforms():\n",
    "    return [\n",
    "        A.Compose([A.Resize(224, 224), A.Normalize((0.5,), (0.5,)), ToTensorV2()]),\n",
    "        A.Compose([A.HorizontalFlip(p=1.0), A.Resize(224, 224), A.Normalize((0.5,), (0.5,)), ToTensorV2()]),\n",
    "        A.Compose([A.Rotate(limit=15, p=1.0), A.Resize(224, 224), A.Normalize((0.5,), (0.5,)), ToTensorV2()]),\n",
    "        A.Compose([A.RandomBrightnessContrast(p=1.0), A.Resize(224, 224), A.Normalize((0.5,), (0.5,)), ToTensorV2()])\n",
    "    ]\n",
    "\n",
    "tta_transforms = get_tta_transforms()\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.CoarseDropout(p=0.4, max_holes=1, max_height=32, max_width=32),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# ì‹œë“œê³ ì •\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)                         # íŒŒì´ì¬ random\n",
    "    np.random.seed(seed)                      # numpy\n",
    "    torch.manual_seed(seed)                   # torch CPU\n",
    "    torch.cuda.manual_seed(seed)              # torch GPU\n",
    "    torch.cuda.manual_seed_all(seed)          # multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # ì—°ì‚° ë™ì¼í•˜ê²Œ\n",
    "    torch.backends.cudnn.benchmark = False    # ì—°ì‚° ì†ë„ ìµœì í™” OFF (ê°™ì€ ì—°ì‚° ë³´ì¥)\n",
    "\n",
    "# Bounding Boxë¥¼ Binary Maskë¡œ\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    masks = []\n",
    "    for bbox in bbox_list:\n",
    "        mask = np.zeros(image_size, dtype=np.float32)\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0\n",
    "        masks.append(mask)\n",
    "    masks = np.stack(masks)\n",
    "    masks = np.expand_dims(masks, axis=1)\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "\n",
    "def load_bbox_dict(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    bbox_dict = {}\n",
    "    for _, row in df.iterrows():\n",
    "        pid = row['pid']\n",
    "        slice_str = row['slice']\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"\n",
    "        bbox = eval(row['bb'])\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)\n",
    "    return bbox_dict\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "\n",
    "def extract_label_from_filename(fname):\n",
    "    try:\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Dataset\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        fname = os.path.basename(f)\n",
    "\n",
    "        img = np.load(f)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.0\n",
    "        img = np.expand_dims(img.astype(np.float32), axis=-1)\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(h, w))[0].numpy()\n",
    "        else:\n",
    "            mask = np.zeros((h, w), dtype=np.float32)\n",
    "        mask = np.expand_dims(mask, axis=-1).astype(np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "        else:\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "            mask = torch.tensor(mask.squeeze(), dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "        \n",
    "\n",
    "# TTAìš© Dataset\n",
    "class TTADataset(Dataset):\n",
    "    def __init__(self, paths, labels, tta_transforms):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.tta_transforms = tta_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        img = np.load(f)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.0\n",
    "        img = np.expand_dims(img.astype(np.float32), axis=-1)\n",
    "\n",
    "        images = [t(image=img)[\"image\"] for t in self.tta_transforms]\n",
    "        return torch.stack(images), torch.tensor(label).long()\n",
    "\n",
    "\n",
    "# CBAM + ResNet18 ì •ì˜\n",
    "# -------------------- CBAM ì •ì˜ (MGA í¬í•¨) --------------------\n",
    "# 2 Step : Channel Attention(ì–´ë–¤ ì±„ë„ì— ì§‘ì¤‘í• ì§€) * Spatial Attention(ì–´ë””ì— ì§‘ì¤‘í• ì§€) = ìµœì¢… Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # ì…ë ¥ feature mapì˜ ì±„ë„ë³„ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•´ì„œ ê°•ì¡°í•¨\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : ì…ë ¥ ì±„ë„ ìˆ˜\n",
    "        # ratio : ì¤‘ê°„ ì±„ë„ ì¶•ì†Œ ë¹„ìœ¨. ê¸°ë³¸ 1/16ìœ¼ë¡œ bottlenck êµ¬ì„±\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP ì—­í• ì„ í•˜ëŠ” 1x1 conv ë¸”ë¡ -> ì±„ë„ ì••ì¶• -> ë¹„ì„ í˜• -> ë³µì› (sharedëŠ” avg/max ë‘˜ë‹¤ì—ì„œ ê°™ì´ ì”€)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # í‰ê·  í’€ë§ / ìµœëŒ€ í’€ë§ìœ¼ë¡œ ë‘ê°€ì§€ ì „ì—­ ì •ë³´ë¥¼ ì¶”ì¶œ\n",
    "        # ë§ˆì§€ë§‰ sigmoidëŠ” attention weightë¡œ ìŠ¤ì¼€ì¼ë§\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max í’€ë§ ê²½ê³¼ë¥¼ ê°ê° shape MLPì— í†µê³¼ì‹œí‚¤ê³ , ë”í•œ í›„ sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> ì±„ë„ë§ˆë‹¤ ì¤‘ìš”ë„ weightë¥¼ ê³±í•˜ê²Œ ë¨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # ê³µê°„ì ìœ¼ë¡œ ì–´ë””ì— ì§‘ì¤‘í• ì§€ë¥¼ ê²°ì • -> ê° ì±„ë„ ë‚´ë¶€ì—ì„œ ì¤‘ìš”í•œ ìœ„ì¹˜ ì°¾ê¸°\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # ì±„ë„ ì°¨ì›ì€ í‰ê· , ìµœëŒ€ ë‘ ê°œë§Œ ì¨ì„œ concat\n",
    "    # ê·¸ê±¸ 1ì±„ë„ë¡œ ì¤„ì—¬ì£¼ëŠ” conv\n",
    "    # ì»¤ë„ í¬ê¸° k=7ì´ë©´ ë„“ì€ ì˜ì—­ê¹Œì§€ ê°ì§€ ê°€ëŠ¥\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # ì…ë ¥ feature mapì—ì„œ :\n",
    "    # í‰ê· , ìµœëŒ€ê°’ì„ ê° spatial ìœ„ì¹˜ë³„ë¡œ êµ¬í•¨ -> [B, 1, H, W] ë‘ ê°œ\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> ìœ„ì¹˜ë³„ ì¤‘ìš”ë„ map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttentionì„ ë‚´ë¶€ì— ì„ ì–¸\n",
    "    # MGAë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ attention mapì„ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ í¬í•¨\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # ì±„ë„ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ìœ„ì¹˜ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ë‘˜ ë‹¤ ë°˜ì˜ëœ ìµœì¢… feature map ë¦¬í„´\n",
    "\n",
    "\n",
    "\n",
    "# í•™ìŠµ\n",
    "\n",
    "def run():\n",
    "    seed_everything(42)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "    \n",
    "    test_dataset = TTADataset(test_files, test_labels, tta_transforms)\n",
    "\n",
    "    train_loader = DataLoader(CTDataset(train_files, train_labels, transform=train_transform), batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(CTDataset(val_files, val_labels, transform=val_transform), batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = FocalLoss(weight=torch.tensor([0.65, 0.35], device=device), gamma=2.0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    save_path = os.path.join(\"pth\", \"r18_cbam_mga_aug_tta.pth\")\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "    \n",
    "\n",
    "    monitor_start = 80\n",
    "    monitor_window = 10\n",
    "    monitor_threshold = 0.90\n",
    "    recent_val_accs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for imgs, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            imgs, labels, masks = imgs.to(device), labels.to(device), masks.to(device)\n",
    "            outputs = model(imgs)\n",
    "            ce_loss = criterion(outputs, labels)\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # [B, 1, H, W]\n",
    "            attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)  # [B, 224, 224]\n",
    "            masks = masks.view(masks.size(0), 224, 224)  # ê°•ì œë¡œ [B, 224, 224]ë¡œ reshape\n",
    "            mga_loss = F.mse_loss(attn_map, masks.float())\n",
    "            loss = ce_loss + lambda_mga * mga_loss\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        print(f\"Train Acc: {correct/total:.4f}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        model.eval(); val_correct, val_total = 0, 0\n",
    "        min_val_acc = 0.85  # ê¸°ë³¸ ê¸°ì¤€ì„ \n",
    "        patience = 10       # ê¸°ë‹¤ë¦´ ìˆ˜ ìˆëŠ” íšŸìˆ˜\n",
    "        epochs_no_improve = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels, _ in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        val_acc = val_correct / val_total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        recent_val_accs.append(val_acc)\n",
    "        if len(recent_val_accs) > monitor_window:\n",
    "            recent_val_accs.pop(0)\n",
    "\n",
    "        if epoch + 1 >= monitor_start:\n",
    "            if len(recent_val_accs) == monitor_window and all(acc < monitor_threshold for acc in recent_val_accs):\n",
    "                print(f\"ğŸ›‘ Early stopping: Epoch {epoch+1} ê¸°ì¤€ ìµœê·¼ {monitor_window}ë²ˆ val_acc < {monitor_threshold}\")\n",
    "                break\n",
    "\n",
    "    # ---------------- í…ŒìŠ¤íŠ¸ ----------------\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs_batch, labels in test_loader:  # imgs_batch: [B, T, C, H, W]\n",
    "            labels = labels.to(device)\n",
    "            B, T, C, H, W = imgs_batch.shape\n",
    "            imgs_batch = imgs_batch.to(device)  # (B, T, C, H, W)\n",
    "            imgs_batch = imgs_batch.view(-1, C, H, W)  # (B*T, C, H, W)\n",
    "\n",
    "            outputs = model(imgs_batch)  # (B*T, num_classes)\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "            outputs = outputs.view(B, T, -1).mean(dim=1)  # (B, num_classes)\n",
    "\n",
    "            probs = outputs[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true); y_pred = np.array(y_pred); y_probs = np.array(y_probs)\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nğŸ“Š Test Evaluation:\\nâœ… Accuracy: {acc*100:.2f}% | AUC: {auc:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\", cm)\n",
    "\n",
    "    from collections import Counter\n",
    "\n",
    "    counter = Counter(labels)\n",
    "    print(f\"Class distribution: {counter}\")\n",
    "\n",
    "    metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "    with open(\"logs/final_test_metrics.csv\", 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=metrics.keys())\n",
    "        if not os.path.exists(\"logs/final_test_metrics.csv\"):\n",
    "            writer.writeheader()\n",
    "        writer.writerow(metrics)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r18_cbam_mga_aug_focal150_2.pth\n",
    "# âœ… ì „ì²´ì½”ë“œ: ResNet18 + CBAM + MGA + Lambda Scheduling\n",
    "# âœ… ì¶”ì²œ ì‹¤í—˜ ì¡°í•© í¬í•¨:\n",
    "# - Weighted FocalLoss (gamma=2.0)\n",
    "# - Data Aug: Resize + Flip + Rotate(15) + BrightnessContrast + Dropout\n",
    "# - Evaluation Metrics + CSV ì €ì¥ + tqdm\n",
    "\n",
    "import os, re, numpy as np, torch, gc, csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ê²½ë¡œ & í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "batch_size = 16\n",
    "num_epochs = 150\n",
    "learning_rate = 1e-4\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "\n",
    "# FocalLoss êµ¬í˜„\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = F.log_softmax(input, dim=1)\n",
    "        ce_loss = F.nll_loss(logp, target, weight=self.weight, reduction='none')\n",
    "        p = torch.exp(-ce_loss)\n",
    "        return ((1 - p) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "# Transform (Albumentations)\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.CoarseDropout(p=0.4, max_holes=1, max_height=32, max_width=32),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# BBox -> ë§ˆìŠ¤í¬\n",
    "# -------------------- Bounding Boxë¥¼ Binary Maskë¡œ --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    # bbox_list : í•œ ì´ë¯¸ì§€ì— ë“¤ì–´ìˆëŠ” bounding box ë¦¬ìŠ¤íŠ¸\n",
    "    # image_size : ì¶œë ¥í•  ë§ˆìŠ¤í¬ í¬ê¸°. ë³´í†µ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ (height, width) -> ë””í´íŠ¸ëŠ” 224x224\n",
    "    # bboxë“¤ì„ binary maskë¡œ ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜\n",
    "    masks = []  # ì—¬ëŸ¬ ê°œì˜ bboxê°€ ë“¤ì–´ì˜¤ë‹ˆê¹Œ, ê°ê°ì˜ ë§ˆìŠ¤í¬ë¥¼ í•˜ë‚˜ì”© ë¦¬ìŠ¤íŠ¸ì— ìŒ“ê¸° ìœ„í•œ ë¹ˆ ë¦¬ìŠ¤íŠ¸\n",
    "    for bbox in bbox_list:  # bbox_listë¥¼ í•˜ë‚˜ì”© ëŒë©´ì„œ ì²˜ë¦¬ -> [x_min, y_min, x_max, y_max]ë„¤ ì¢Œí‘œë¡œ êµ¬ì„±ëœ í•˜ë‚˜ì˜ ì‚¬ê°í˜• ì˜ì—­ \n",
    "        mask = np.zeros(image_size, dtype=np.float32)   # 224x224ì§œë¦¬ 0ìœ¼ë¡œ ê½‰ ì°¬ 2D ë°°ì—´ì„ í•˜ë‚˜ ìƒì„±\n",
    "        # ë°°ê²½ì´ í° ì¢…ì´ë¥¼ ë§Œë“œëŠ” ëŠë‚Œìœ¼ë¡œ ë§Œë“¤ê³ , ì‚¬ê° ì˜ì—­ë§Œ 1ë¡œ ë§ì¹ í• ê±°ì„\n",
    "        x_min, y_min, x_max, y_max = bbox   # ê° bboxì˜ ë„¤ ì¢Œí‘œê°’ì„ ê°ê° ë³€ìˆ˜ë¡œ ì–¸íŒ©. -> ë§ˆìŠ¤í¬ì˜ í•´ë‹¹ ì˜ì—­ì— ì‚¬ê°í˜•ì„ ì¹ í•˜ê¸° ìœ„í•´ì„œ\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0    # y_min, y_max, x_min, x_maxê¹Œì§€ì˜ ë²”ìœ„ì— 1.0ì„ ì±„ì›Œ ë„£ìŒ\n",
    "        # -> ë§ˆìŠ¤í¬ì—ì„œ bboxì— í•´ë‹¹í•˜ëŠ” ì‚¬ê°í˜• ì˜ì—­ë§Œ 1(foreground)ë¡œ í‘œì‹œë¨. ë‚˜ë¨¸ì§„ ì—¬ì „íˆ 0(background)\n",
    "        masks.append(mask)  # ì§€ê¸ˆ ë§Œë“  ë§ˆìŠ¤í¬(2D ë°°ì—´)ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ -> [mask1, mask2, ...]ì´ë ‡ê²Œ ìŒ“ì„\n",
    "\n",
    "    masks = np.stack(masks) # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ 3D ë°°ì—´ë¡œ í•©ì¹¨ -> shape : [N, H, W] -> Nì€ bbox ê°œìˆ˜\n",
    "    masks = np.expand_dims(masks, axis=1)   # í…ì„œ shapeì„ [N, 1, H, W]ë¡œ ë°”ê¿ˆ\n",
    "    # PyTorch ëª¨ë¸ì—ì„œ ê¸°ëŒ€í•˜ëŠ” (batch x channel x height x width) í¬ë§· ë§ì¶”ê¸°\n",
    "\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "    # numpy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜í•´ì„œ ë¦¬í„´\n",
    "\n",
    "    # í•œ bbox â†’ í•˜ë‚˜ì˜ ë§ˆìŠ¤í¬ â†’ ì—¬ëŸ¬ ê°œë©´ ìŒ“ì•„ì„œ batch í˜•íƒœë¡œ\n",
    "# -------------------- Bounding Box CSV ë¡œë“œ --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    # csv_path : bounding box ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” CSV íŒŒì¼ ê²½ë¡œ\n",
    "    # ë°˜í™˜ê°’ : {filename:[bbox1, bbox2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬\n",
    "    df = pd.read_csv(csv_path)  # CSVíŒŒì¼ì„ pandas DataFrameìœ¼ë¡œ ì½ì–´ì˜´\n",
    "    bbox_dict = {}\n",
    "    # key : ìŠ¬ë¼ì´ìŠ¤ íŒŒì¼ ì´ë¦„ (ex. \"LIDC-IDRI-1012_slice0004.npy\")\n",
    "    # value : í•´ë‹¹ ìŠ¬ë¼ì´ìŠ¤ì— ì¡´ì¬í•˜ëŠ” bboxë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "    for _, row in df.iterrows():    # DataFrameì˜ ëª¨ë“  í–‰(row)ë¥¼ í•˜ë‚˜ì”© ìˆœíšŒ\n",
    "        # rowëŠ” í•œ ì¤„(=í•œ bbox)ì˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆìŒ\n",
    "\n",
    "        pid = row['pid']    # í™˜ì ID (ì˜ˆ: \"LIDC-IDRI-1012\") -> ì´ë¯¸ì§€ ì´ë¦„ êµ¬ì„± ìš”ì†Œ\n",
    "        slice_str = row['slice']    # ìŠ¬ë¼ì´ìŠ¤ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” ë¬¸ìì—´ (ì˜ˆ: \"slice_0039\")\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])  # re.findall()ë¡œ ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ë½‘ì•„ëƒ„\n",
    "        # \"slice_0039\" -> ['0039'] -> [0] -> 39 (ìŠ¬ë¼ì´ìŠ¤ ë²ˆí˜¸ë¥¼ ì •ìˆ˜ë¡œ ì¶”ì¶œí•¨)\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"   # íŒŒì¼ëª… êµ¬ì„± (ì˜ˆ: \"LIDC-IDRI-1012_slice0039.npy\")\n",
    "        # {:04d}ëŠ” 4ìë¦¬ ì •ìˆ˜ë¡œ ë§Œë“¤ê³  ë¹ˆìë¦¬ëŠ” 0ìœ¼ë¡œ ì±„ì›Œì¤Œ (39 -> 0039)\n",
    "        bbox = eval(row['bb'])  # row['bb']ëŠ” ë¬¸ìì—´ í˜•íƒœì˜ bbox (ì˜ˆ: \"[20, 30, 80, 100]\")\n",
    "        # eval()ì„ ì¨ì„œ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ê¿”ì¤Œ\n",
    "        # ì£¼ì˜ : ë³´ì•ˆ ìƒ ìœ„í—˜í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ì§€ë§Œ, ì—¬ê¸´ ë‚´ë¶€ ë°ì´í„°ë¼ ì‚¬ìš©ì¤‘\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)    # fnameì´ë¼ëŠ” keyê°€ ë”•ì…”ë„ˆë¦¬ì— ì—†ìœ¼ë©´ []ë¡œ ì´ˆê¸°í™”í•˜ê³ ,\n",
    "        # ê±°ê¸°ì— bboxë¥¼ append -> ìŠ¬ë¼ì´ìŠ¤ í•˜ë‚˜ì— bbox ì—¬ëŸ¬ê°œ ìˆì–´ë„ ì „ë¶€ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ì•„ì¤Œ\n",
    "    return bbox_dict    # ìµœì¢…ì ìœ¼ë¡œ {filename: [bbox1, bbox2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "# ì‹¤ì œë¡œ csv_pathì— ìˆëŠ” ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™€ì„œ bbox_dictì— ì €ì¥í•¨\n",
    "# ì´ê±¸ ë‚˜ì£¼ì— Dataset í´ë˜ìŠ¤ì—ì„œ fname ê¸°ì¤€ì„ êº¼ë‚´ì“°ê²Œ ë¨\n",
    "\n",
    "# -------------------- ë¼ë²¨ ì¶”ì¶œ --------------------\n",
    "def extract_label_from_filename(fname): # fname : íŒŒì¼ ì´ë¦„ (ì˜ˆ: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # ì´ ì´ë¦„ì—ì„œ malignancy score(ì•…ì„±ë„ ì ìˆ˜)ë¥¼ ì¶”ì¶œí•´ì„œ ë¼ë²¨ë¡œ ë³€í™˜\n",
    "    try:    # íŒŒì¼ëª…ì´ ì´ìƒí•˜ê±°ë‚˜ ì—ëŸ¬ë‚˜ë©´ exceptë¡œ ë¹ ì ¸ë‚˜ê°€ì„œ None ë°˜í™˜í•¨ (ì•ˆì „ì¥ì¹˜)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # íŒŒì¼ëª…ì—ì„œ _ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ê²ƒë“¤ ì¤‘ì— ë§ˆì§€ë§‰ì—êº¼ë¥¼ ê°€ì ¸ì™€ì„œ .npyë¥¼ \"\" ì´ë ‡ê²Œ ê³µë°±ìœ¼ë¡œ ì²˜ë¦¬í•¨\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- ì´ê²Œ malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # ë¼ë²¨ ê²°ì • ë¡œì§ìœ¼ë¡œ\n",
    "        # score == 3 -> ì¤‘ë¦½ -> None ë°˜í™˜ -> í•™ìŠµì—ì„œ ì œì™¸\n",
    "        # score >= 4 -> ì•”(ì–‘ì„±) -> 1\n",
    "        # score <= 2 -> ì •ìƒ(ìŒì„±) -> 0\n",
    "        # int(score >= 4)ëŠ” íŒŒì´ì¬ì—ì„œ True -> 1\n",
    "        # False -> 0 ì´ë‹ˆê¹ ìë™ìœ¼ë¡œ ë¼ë²¨ì´ ë¨\n",
    "    except:\n",
    "        return None\n",
    "        # í˜¹ì‹œ splitì´ë‚˜ replace, int ë³€í™˜ì´ ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ None ë°˜í™˜í•˜ê³  ë¬´ì‹œ\n",
    "\n",
    "# ì‹œë“œ ê³ ì •\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)                         # íŒŒì´ì¬ random\n",
    "    np.random.seed(seed)                      # numpy\n",
    "    torch.manual_seed(seed)                   # torch CPU\n",
    "    torch.cuda.manual_seed(seed)              # torch GPU\n",
    "    torch.cuda.manual_seed_all(seed)          # multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # ì—°ì‚° ë™ì¼í•˜ê²Œ\n",
    "    torch.backends.cudnn.benchmark = False    # ì—°ì‚° ì†ë„ ìµœì í™” OFF (ê°™ì€ ì—°ì‚° ë³´ì¥)\n",
    "\n",
    "    \n",
    "# Dataset (Albumentations ì ìš©)\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        fname = os.path.basename(f)\n",
    "\n",
    "        img = np.load(f)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.0\n",
    "        mask = np.zeros((224, 224), dtype=np.float32)\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(224, 224)).sum(0).squeeze().numpy()\n",
    "\n",
    "        augmented = self.transform(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "        return img.unsqueeze(0), torch.tensor(label).long(), mask\n",
    "\n",
    "    def __len__(self): return len(self.paths)\n",
    "\n",
    "# CBAM + ResNet18 ì •ì˜\n",
    "...\n",
    "\n",
    "# í•™ìŠµ\n",
    "\n",
    "def run():\n",
    "    seed_everything(42)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_loader = DataLoader(CTDataset(train_files, train_labels, transform=train_transform), batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(CTDataset(val_files, val_labels, transform=val_transform), batch_size=batch_size)\n",
    "    test_loader = DataLoader(CTDataset(test_files, test_labels, transform=val_transform), batch_size=batch_size)\n",
    "\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = FocalLoss(weight=torch.tensor([0.65, 0.35], device=device), gamma=2.0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    save_path = os.path.join(\"pth\", \"r18_cbam_mga_aug_focal150_2.pth\")\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for imgs, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            imgs, labels, masks = imgs.to(device), labels.to(device), masks.to(device)\n",
    "            outputs = model(imgs)\n",
    "            ce_loss = criterion(outputs, labels)\n",
    "            attn_map = model.layer3[1].cbam.last_attention\n",
    "            attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "            mga_loss = F.mse_loss(attn_map, masks)\n",
    "            loss = ce_loss + lambda_mga * mga_loss\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        print(f\"Train Acc: {correct/total:.4f}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        model.eval(); val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels, _ in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        val_acc = val_correct / val_total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"âœ… Saved best model!\")\n",
    "\n",
    "    # ---------------- í…ŒìŠ¤íŠ¸ ----------------\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, _ in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true); y_pred = np.array(y_pred); y_probs = np.array(y_probs)\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nğŸ“Š Test Evaluation:\\nâœ… Accuracy: {acc*100:.2f}% | AUC: {auc:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\", cm)\n",
    "\n",
    "    metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "    with open(\"logs/final_test_metrics.csv\", 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=metrics.keys())\n",
    "        if not os.path.exists(\"logs/final_test_metrics.csv\"):\n",
    "            writer.writeheader()\n",
    "        writer.writerow(metrics)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1974167/4093859747.py:52: UserWarning: Argument(s) 'max_holes, max_height, max_width' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(p=0.4, max_holes=1, max_height=32, max_width=32),\n",
      "[Epoch 1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3540, Loss: 0.0447\n",
      "Val Acc: 0.3113\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3631, Loss: 0.0262\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 26.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3650, Loss: 0.0249\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 28.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3652, Loss: 0.0246\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3569, Loss: 0.0244\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3719, Loss: 0.0241\n",
      "Val Acc: 0.6550\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3633, Loss: 0.0242\n",
      "Val Acc: 0.6887\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3786, Loss: 0.0240\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3909, Loss: 0.0238\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3864, Loss: 0.0238\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 11]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:10<00:00, 22.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.3864, Loss: 0.0240\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 12]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4148, Loss: 0.0237\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 13]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 26.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4223, Loss: 0.0234\n",
      "Val Acc: 0.4175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 14]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4432, Loss: 0.0233\n",
      "Val Acc: 0.3225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 15]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4373, Loss: 0.0232\n",
      "Val Acc: 0.3325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 16]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4735, Loss: 0.0228\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.4815, Loss: 0.0227\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 18]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.5019, Loss: 0.0219\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 19]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.5040, Loss: 0.0216\n",
      "Val Acc: 0.5088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 20]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.5480, Loss: 0.0211\n",
      "Val Acc: 0.5150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 21]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 28.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.5648, Loss: 0.0205\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 22]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:11<00:00, 20.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.5793, Loss: 0.0204\n",
      "Val Acc: 0.4213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 23]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6112, Loss: 0.0198\n",
      "Val Acc: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 24]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6367, Loss: 0.0189\n",
      "Val Acc: 0.6987\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 25]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6447, Loss: 0.0185\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 26]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6693, Loss: 0.0180\n",
      "Val Acc: 0.6388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 27]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6838, Loss: 0.0178\n",
      "Val Acc: 0.6725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 28]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.6943, Loss: 0.0173\n",
      "Val Acc: 0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 29]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 31.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7141, Loss: 0.0164\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 27.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7395, Loss: 0.0155\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 31]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 19.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7406, Loss: 0.0154\n",
      "Val Acc: 0.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 32]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7655, Loss: 0.0149\n",
      "Val Acc: 0.5025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 33]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7779, Loss: 0.0140\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 34]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7889, Loss: 0.0137\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 35]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.7923, Loss: 0.0134\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 36]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8025, Loss: 0.0127\n",
      "Val Acc: 0.4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 37]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8065, Loss: 0.0127\n",
      "Val Acc: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 38]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 29.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8106, Loss: 0.0128\n",
      "Val Acc: 0.5188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 39]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8242, Loss: 0.0120\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 40]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:10<00:00, 21.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8315, Loss: 0.0119\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 41]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8309, Loss: 0.0116\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 42]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8344, Loss: 0.0112\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 43]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8518, Loss: 0.0110\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 44]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8360, Loss: 0.0109\n",
      "Val Acc: 0.8087\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 45]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8569, Loss: 0.0106\n",
      "Val Acc: 0.6338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 46]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8494, Loss: 0.0106\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 47]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 29.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8599, Loss: 0.0095\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 28.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8655, Loss: 0.0099\n",
      "Val Acc: 0.4437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 49]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8762, Loss: 0.0093\n",
      "Val Acc: 0.4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 50]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8708, Loss: 0.0098\n",
      "Val Acc: 0.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 51]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8743, Loss: 0.0095\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 52]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8880, Loss: 0.0089\n",
      "Val Acc: 0.6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 53]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8842, Loss: 0.0086\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 54]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8920, Loss: 0.0088\n",
      "Val Acc: 0.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 55]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 19.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8867, Loss: 0.0089\n",
      "Val Acc: 0.3475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 56]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 29.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8958, Loss: 0.0079\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 57]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 27.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9009, Loss: 0.0078\n",
      "Val Acc: 0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 58]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9027, Loss: 0.0081\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 59]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9086, Loss: 0.0073\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 60]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9017, Loss: 0.0080\n",
      "Val Acc: 0.4200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 61]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.8971, Loss: 0.0079\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 62]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9110, Loss: 0.0073\n",
      "Val Acc: 0.3162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 63]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9159, Loss: 0.0069\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 64]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:11<00:00, 20.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9073, Loss: 0.0072\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 65]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 28.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9159, Loss: 0.0067\n",
      "Val Acc: 0.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 66]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9196, Loss: 0.0064\n",
      "Val Acc: 0.5675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 67]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9159, Loss: 0.0064\n",
      "Val Acc: 0.5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 68]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9086, Loss: 0.0076\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 69]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9175, Loss: 0.0067\n",
      "Val Acc: 0.8425\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 70]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9223, Loss: 0.0066\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 71]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9156, Loss: 0.0067\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 72]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9223, Loss: 0.0064\n",
      "Val Acc: 0.3175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 73]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 24.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9260, Loss: 0.0059\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 74]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9226, Loss: 0.0063\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 75]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9094, Loss: 0.0073\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 76]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:14<00:00, 16.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9306, Loss: 0.0055\n",
      "Val Acc: 0.4188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 77]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:15<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9287, Loss: 0.0054\n",
      "Val Acc: 0.6925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 78]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9293, Loss: 0.0057\n",
      "Val Acc: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 79]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9255, Loss: 0.0055\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 80]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9258, Loss: 0.0060\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 81]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9311, Loss: 0.0056\n",
      "Val Acc: 0.5763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 82]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:10<00:00, 23.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9370, Loss: 0.0054\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 83]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:11<00:00, 20.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9357, Loss: 0.0060\n",
      "Val Acc: 0.3650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 84]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9381, Loss: 0.0052\n",
      "Val Acc: 0.3337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 85]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9362, Loss: 0.0056\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 86]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9389, Loss: 0.0053\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 87]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9362, Loss: 0.0057\n",
      "Val Acc: 0.4825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 88]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9322, Loss: 0.0055\n",
      "Val Acc: 0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 89]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9429, Loss: 0.0051\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 90]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9440, Loss: 0.0050\n",
      "Val Acc: 0.8588\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 91]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9483, Loss: 0.0047\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 92]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:10<00:00, 21.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9515, Loss: 0.0044\n",
      "Val Acc: 0.4525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 93]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9510, Loss: 0.0043\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 94]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9408, Loss: 0.0050\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 95]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9499, Loss: 0.0044\n",
      "Val Acc: 0.6488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 96]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9486, Loss: 0.0044\n",
      "Val Acc: 0.4037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 97]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9285, Loss: 0.0058\n",
      "Val Acc: 0.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 98]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9456, Loss: 0.0050\n",
      "Val Acc: 0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 99]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9553, Loss: 0.0036\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 28.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9502, Loss: 0.0043\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 101]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 28.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9459, Loss: 0.0047\n",
      "Val Acc: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 102]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 19.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9330, Loss: 0.0055\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 103]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9365, Loss: 0.0052\n",
      "Val Acc: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 104]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9526, Loss: 0.0038\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 105]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:16<00:00, 14.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9408, Loss: 0.0050\n",
      "Val Acc: 0.5600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 106]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 16.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9400, Loss: 0.0049\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 107]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9515, Loss: 0.0040\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 108]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9579, Loss: 0.0035\n",
      "Val Acc: 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 109]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 31.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9515, Loss: 0.0044\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 110]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 29.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9593, Loss: 0.0039\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 111]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:11<00:00, 21.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9448, Loss: 0.0046\n",
      "Val Acc: 0.7113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 112]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9547, Loss: 0.0040\n",
      "Val Acc: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 113]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9561, Loss: 0.0039\n",
      "Val Acc: 0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 114]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9277, Loss: 0.0056\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 115]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9558, Loss: 0.0040\n",
      "Val Acc: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 116]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9469, Loss: 0.0045\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 117]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9518, Loss: 0.0044\n",
      "Val Acc: 0.6787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 118]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 29.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9477, Loss: 0.0042\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 119]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 29.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9531, Loss: 0.0042\n",
      "Val Acc: 0.5413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 120]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9609, Loss: 0.0033\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 121]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9582, Loss: 0.0037\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 122]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9652, Loss: 0.0035\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 123]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9483, Loss: 0.0044\n",
      "Val Acc: 0.7900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 124]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9628, Loss: 0.0035\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 125]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9622, Loss: 0.0034\n",
      "Val Acc: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 126]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9553, Loss: 0.0036\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 127]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 29.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9633, Loss: 0.0034\n",
      "Val Acc: 0.6525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 128]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 31.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9665, Loss: 0.0034\n",
      "Val Acc: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 129]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:11<00:00, 20.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9609, Loss: 0.0033\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 130]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9569, Loss: 0.0037\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 131]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9601, Loss: 0.0035\n",
      "Val Acc: 0.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 132]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9689, Loss: 0.0027\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 133]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9689, Loss: 0.0031\n",
      "Val Acc: 0.8275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 134]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9614, Loss: 0.0035\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 135]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 16.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9654, Loss: 0.0031\n",
      "Val Acc: 0.4238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 136]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 29.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9464, Loss: 0.0048\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 137]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 29.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9595, Loss: 0.0037\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 138]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9579, Loss: 0.0037\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 139]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9574, Loss: 0.0036\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 140]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9601, Loss: 0.0033\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 141]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9652, Loss: 0.0031\n",
      "Val Acc: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 142]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9628, Loss: 0.0035\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 143]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9686, Loss: 0.0027\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 144]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 18.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9638, Loss: 0.0034\n",
      "Val Acc: 0.3812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 145]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 27.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9646, Loss: 0.0031\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 146]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:07<00:00, 30.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9625, Loss: 0.0034\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 147]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9641, Loss: 0.0035\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 148]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9705, Loss: 0.0029\n",
      "Val Acc: 0.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 149]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9703, Loss: 0.0027\n",
      "Val Acc: 0.7275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 150]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:13<00:00, 17.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 0.9665, Loss: 0.0035\n",
      "Val Acc: 0.6362\n",
      "\n",
      "ğŸ“Š Test Evaluation:\n",
      "âœ… Accuracy: 88.50% | AUC: 0.9253 | F1: 0.9148\n",
      "Confusion Matrix: [[214  61]\n",
      " [ 31 494]]\n"
     ]
    }
   ],
   "source": [
    "# âœ… Test Accuracy: 88.50% | AUC: 0.9253 | F1: 0.9148\n",
    "# Confusion Matrix: [[214  61]\n",
    "#  [ 31 494]]\n",
    "#r18_cbam_mga_aug_focal150.pth\n",
    "\n",
    "# âœ… ì „ì²´ì½”ë“œ: ResNet18 + CBAM + MGA + Lambda Scheduling\n",
    "\n",
    "# âœ… ì¶”ì²œ ì‹¤í—˜ ì¡°í•© í¬í•¨:\n",
    "# - Weighted FocalLoss (gamma=2.0)\n",
    "# - Data Aug: Resize + Flip + Rotate(15) + BrightnessContrast + Dropout\n",
    "# - Evaluation Metrics + CSV ì €ì¥ + tqdm\n",
    "\n",
    "import os, re, numpy as np, torch, gc, csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from datetime import datetime\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ê²½ë¡œ & í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "batch_size = 16\n",
    "num_epochs = 150\n",
    "learning_rate = 1e-4\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "\n",
    "# FocalLoss êµ¬í˜„\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, weight=None, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = F.log_softmax(input, dim=1)\n",
    "        ce_loss = F.nll_loss(logp, target, weight=self.weight, reduction='none')\n",
    "        p = torch.exp(-ce_loss)\n",
    "        return ((1 - p) ** self.gamma * ce_loss).mean()\n",
    "\n",
    "# Transform (Albumentations)\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.CoarseDropout(p=0.4, max_holes=1, max_height=32, max_width=32),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# -------------------- Bounding Boxë¥¼ Binary Maskë¡œ --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    # bbox_list : í•œ ì´ë¯¸ì§€ì— ë“¤ì–´ìˆëŠ” bounding box ë¦¬ìŠ¤íŠ¸\n",
    "    # image_size : ì¶œë ¥í•  ë§ˆìŠ¤í¬ í¬ê¸°. ë³´í†µ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ (height, width) -> ë””í´íŠ¸ëŠ” 224x224\n",
    "    # bboxë“¤ì„ binary maskë¡œ ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜\n",
    "    masks = []  # ì—¬ëŸ¬ ê°œì˜ bboxê°€ ë“¤ì–´ì˜¤ë‹ˆê¹Œ, ê°ê°ì˜ ë§ˆìŠ¤í¬ë¥¼ í•˜ë‚˜ì”© ë¦¬ìŠ¤íŠ¸ì— ìŒ“ê¸° ìœ„í•œ ë¹ˆ ë¦¬ìŠ¤íŠ¸\n",
    "    for bbox in bbox_list:  # bbox_listë¥¼ í•˜ë‚˜ì”© ëŒë©´ì„œ ì²˜ë¦¬ -> [x_min, y_min, x_max, y_max]ë„¤ ì¢Œí‘œë¡œ êµ¬ì„±ëœ í•˜ë‚˜ì˜ ì‚¬ê°í˜• ì˜ì—­ \n",
    "        mask = np.zeros(image_size, dtype=np.float32)   # 224x224ì§œë¦¬ 0ìœ¼ë¡œ ê½‰ ì°¬ 2D ë°°ì—´ì„ í•˜ë‚˜ ìƒì„±\n",
    "        # ë°°ê²½ì´ í° ì¢…ì´ë¥¼ ë§Œë“œëŠ” ëŠë‚Œìœ¼ë¡œ ë§Œë“¤ê³ , ì‚¬ê° ì˜ì—­ë§Œ 1ë¡œ ë§ì¹ í• ê±°ì„\n",
    "        x_min, y_min, x_max, y_max = bbox   # ê° bboxì˜ ë„¤ ì¢Œí‘œê°’ì„ ê°ê° ë³€ìˆ˜ë¡œ ì–¸íŒ©. -> ë§ˆìŠ¤í¬ì˜ í•´ë‹¹ ì˜ì—­ì— ì‚¬ê°í˜•ì„ ì¹ í•˜ê¸° ìœ„í•´ì„œ\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0    # y_min, y_max, x_min, x_maxê¹Œì§€ì˜ ë²”ìœ„ì— 1.0ì„ ì±„ì›Œ ë„£ìŒ\n",
    "        # -> ë§ˆìŠ¤í¬ì—ì„œ bboxì— í•´ë‹¹í•˜ëŠ” ì‚¬ê°í˜• ì˜ì—­ë§Œ 1(foreground)ë¡œ í‘œì‹œë¨. ë‚˜ë¨¸ì§„ ì—¬ì „íˆ 0(background)\n",
    "        masks.append(mask)  # ì§€ê¸ˆ ë§Œë“  ë§ˆìŠ¤í¬(2D ë°°ì—´)ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ -> [mask1, mask2, ...]ì´ë ‡ê²Œ ìŒ“ì„\n",
    "\n",
    "    masks = np.stack(masks) # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ 3D ë°°ì—´ë¡œ í•©ì¹¨ -> shape : [N, H, W] -> Nì€ bbox ê°œìˆ˜\n",
    "    masks = np.expand_dims(masks, axis=1)   # í…ì„œ shapeì„ [N, 1, H, W]ë¡œ ë°”ê¿ˆ\n",
    "    # PyTorch ëª¨ë¸ì—ì„œ ê¸°ëŒ€í•˜ëŠ” (batch x channel x height x width) í¬ë§· ë§ì¶”ê¸°\n",
    "\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "    # numpy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜í•´ì„œ ë¦¬í„´\n",
    "\n",
    "    # í•œ bbox â†’ í•˜ë‚˜ì˜ ë§ˆìŠ¤í¬ â†’ ì—¬ëŸ¬ ê°œë©´ ìŒ“ì•„ì„œ batch í˜•íƒœë¡œ\n",
    "# -------------------- Bounding Box CSV ë¡œë“œ --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    # csv_path : bounding box ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” CSV íŒŒì¼ ê²½ë¡œ\n",
    "    # ë°˜í™˜ê°’ : {filename:[bbox1, bbox2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬\n",
    "    df = pd.read_csv(csv_path)  # CSVíŒŒì¼ì„ pandas DataFrameìœ¼ë¡œ ì½ì–´ì˜´\n",
    "    bbox_dict = {}\n",
    "    # key : ìŠ¬ë¼ì´ìŠ¤ íŒŒì¼ ì´ë¦„ (ex. \"LIDC-IDRI-1012_slice0004.npy\")\n",
    "    # value : í•´ë‹¹ ìŠ¬ë¼ì´ìŠ¤ì— ì¡´ì¬í•˜ëŠ” bboxë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "    for _, row in df.iterrows():    # DataFrameì˜ ëª¨ë“  í–‰(row)ë¥¼ í•˜ë‚˜ì”© ìˆœíšŒ\n",
    "        # rowëŠ” í•œ ì¤„(=í•œ bbox)ì˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆìŒ\n",
    "\n",
    "        pid = row['pid']    # í™˜ì ID (ì˜ˆ: \"LIDC-IDRI-1012\") -> ì´ë¯¸ì§€ ì´ë¦„ êµ¬ì„± ìš”ì†Œ\n",
    "        slice_str = row['slice']    # ìŠ¬ë¼ì´ìŠ¤ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” ë¬¸ìì—´ (ì˜ˆ: \"slice_0039\")\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])  # re.findall()ë¡œ ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ë½‘ì•„ëƒ„\n",
    "        # \"slice_0039\" -> ['0039'] -> [0] -> 39 (ìŠ¬ë¼ì´ìŠ¤ ë²ˆí˜¸ë¥¼ ì •ìˆ˜ë¡œ ì¶”ì¶œí•¨)\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"   # íŒŒì¼ëª… êµ¬ì„± (ì˜ˆ: \"LIDC-IDRI-1012_slice0039.npy\")\n",
    "        # {:04d}ëŠ” 4ìë¦¬ ì •ìˆ˜ë¡œ ë§Œë“¤ê³  ë¹ˆìë¦¬ëŠ” 0ìœ¼ë¡œ ì±„ì›Œì¤Œ (39 -> 0039)\n",
    "        bbox = eval(row['bb'])  # row['bb']ëŠ” ë¬¸ìì—´ í˜•íƒœì˜ bbox (ì˜ˆ: \"[20, 30, 80, 100]\")\n",
    "        # eval()ì„ ì¨ì„œ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ê¿”ì¤Œ\n",
    "        # ì£¼ì˜ : ë³´ì•ˆ ìƒ ìœ„í—˜í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ì§€ë§Œ, ì—¬ê¸´ ë‚´ë¶€ ë°ì´í„°ë¼ ì‚¬ìš©ì¤‘\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)    # fnameì´ë¼ëŠ” keyê°€ ë”•ì…”ë„ˆë¦¬ì— ì—†ìœ¼ë©´ []ë¡œ ì´ˆê¸°í™”í•˜ê³ ,\n",
    "        # ê±°ê¸°ì— bboxë¥¼ append -> ìŠ¬ë¼ì´ìŠ¤ í•˜ë‚˜ì— bbox ì—¬ëŸ¬ê°œ ìˆì–´ë„ ì „ë¶€ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ì•„ì¤Œ\n",
    "    return bbox_dict    # ìµœì¢…ì ìœ¼ë¡œ {filename: [bbox1, bbox2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "# ì‹¤ì œë¡œ csv_pathì— ìˆëŠ” ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™€ì„œ bbox_dictì— ì €ì¥í•¨\n",
    "# ì´ê±¸ ë‚˜ì£¼ì— Dataset í´ë˜ìŠ¤ì—ì„œ fname ê¸°ì¤€ì„ êº¼ë‚´ì“°ê²Œ ë¨\n",
    "\n",
    "# -------------------- ë¼ë²¨ ì¶”ì¶œ --------------------\n",
    "def extract_label_from_filename(fname): # fname : íŒŒì¼ ì´ë¦„ (ì˜ˆ: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # ì´ ì´ë¦„ì—ì„œ malignancy score(ì•…ì„±ë„ ì ìˆ˜)ë¥¼ ì¶”ì¶œí•´ì„œ ë¼ë²¨ë¡œ ë³€í™˜\n",
    "    try:    # íŒŒì¼ëª…ì´ ì´ìƒí•˜ê±°ë‚˜ ì—ëŸ¬ë‚˜ë©´ exceptë¡œ ë¹ ì ¸ë‚˜ê°€ì„œ None ë°˜í™˜í•¨ (ì•ˆì „ì¥ì¹˜)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # íŒŒì¼ëª…ì—ì„œ _ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ê²ƒë“¤ ì¤‘ì— ë§ˆì§€ë§‰ì—êº¼ë¥¼ ê°€ì ¸ì™€ì„œ .npyë¥¼ \"\" ì´ë ‡ê²Œ ê³µë°±ìœ¼ë¡œ ì²˜ë¦¬í•¨\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- ì´ê²Œ malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # ë¼ë²¨ ê²°ì • ë¡œì§ìœ¼ë¡œ\n",
    "        # score == 3 -> ì¤‘ë¦½ -> None ë°˜í™˜ -> í•™ìŠµì—ì„œ ì œì™¸\n",
    "        # score >= 4 -> ì•”(ì–‘ì„±) -> 1\n",
    "        # score <= 2 -> ì •ìƒ(ìŒì„±) -> 0\n",
    "        # int(score >= 4)ëŠ” íŒŒì´ì¬ì—ì„œ True -> 1\n",
    "        # False -> 0 ì´ë‹ˆê¹ ìë™ìœ¼ë¡œ ë¼ë²¨ì´ ë¨\n",
    "    except:\n",
    "        return None\n",
    "        # í˜¹ì‹œ splitì´ë‚˜ replace, int ë³€í™˜ì´ ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ None ë°˜í™˜í•˜ê³  ë¬´ì‹œ\n",
    "\n",
    "# Dataset (Albumentations ì ìš©)\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        f = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        fname = os.path.basename(f)\n",
    "\n",
    "        img = np.load(f)  # ì›ë˜ ì´ë¯¸ì§€\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.0\n",
    "        img = img.astype(np.float32)\n",
    "        img = np.expand_dims(img, axis=-1)  # (H, W, 1)\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # === (1) ì›ë³¸ ì´ë¯¸ì§€ì™€ ê°™ì€ í¬ê¸°ë¡œ ë§ˆìŠ¤í¬ ìƒì„± ===\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(h, w))[0].numpy()\n",
    "        else:\n",
    "            mask = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "        mask = np.expand_dims(mask, axis=-1).astype(np.float32)  # (H, W, 1)\n",
    "\n",
    "        # === (2) Albumentations transform: ê°™ì´ resize ì‹œí‚´ ===\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "        else:\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "            mask = torch.tensor(mask.squeeze(), dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "# CBAM + ResNet18 ì •ì˜\n",
    "# -------------------- CBAM ì •ì˜ (MGA í¬í•¨) --------------------\n",
    "# 2 Step : Channel Attention(ì–´ë–¤ ì±„ë„ì— ì§‘ì¤‘í• ì§€) * Spatial Attention(ì–´ë””ì— ì§‘ì¤‘í• ì§€) = ìµœì¢… Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # ì…ë ¥ feature mapì˜ ì±„ë„ë³„ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•´ì„œ ê°•ì¡°í•¨\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : ì…ë ¥ ì±„ë„ ìˆ˜\n",
    "        # ratio : ì¤‘ê°„ ì±„ë„ ì¶•ì†Œ ë¹„ìœ¨. ê¸°ë³¸ 1/16ìœ¼ë¡œ bottlenck êµ¬ì„±\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP ì—­í• ì„ í•˜ëŠ” 1x1 conv ë¸”ë¡ -> ì±„ë„ ì••ì¶• -> ë¹„ì„ í˜• -> ë³µì› (sharedëŠ” avg/max ë‘˜ë‹¤ì—ì„œ ê°™ì´ ì”€)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # í‰ê·  í’€ë§ / ìµœëŒ€ í’€ë§ìœ¼ë¡œ ë‘ê°€ì§€ ì „ì—­ ì •ë³´ë¥¼ ì¶”ì¶œ\n",
    "        # ë§ˆì§€ë§‰ sigmoidëŠ” attention weightë¡œ ìŠ¤ì¼€ì¼ë§\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max í’€ë§ ê²½ê³¼ë¥¼ ê°ê° shape MLPì— í†µê³¼ì‹œí‚¤ê³ , ë”í•œ í›„ sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> ì±„ë„ë§ˆë‹¤ ì¤‘ìš”ë„ weightë¥¼ ê³±í•˜ê²Œ ë¨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # ê³µê°„ì ìœ¼ë¡œ ì–´ë””ì— ì§‘ì¤‘í• ì§€ë¥¼ ê²°ì • -> ê° ì±„ë„ ë‚´ë¶€ì—ì„œ ì¤‘ìš”í•œ ìœ„ì¹˜ ì°¾ê¸°\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # ì±„ë„ ì°¨ì›ì€ í‰ê· , ìµœëŒ€ ë‘ ê°œë§Œ ì¨ì„œ concat\n",
    "    # ê·¸ê±¸ 1ì±„ë„ë¡œ ì¤„ì—¬ì£¼ëŠ” conv\n",
    "    # ì»¤ë„ í¬ê¸° k=7ì´ë©´ ë„“ì€ ì˜ì—­ê¹Œì§€ ê°ì§€ ê°€ëŠ¥\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # ì…ë ¥ feature mapì—ì„œ :\n",
    "    # í‰ê· , ìµœëŒ€ê°’ì„ ê° spatial ìœ„ì¹˜ë³„ë¡œ êµ¬í•¨ -> [B, 1, H, W] ë‘ ê°œ\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> ìœ„ì¹˜ë³„ ì¤‘ìš”ë„ map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttentionì„ ë‚´ë¶€ì— ì„ ì–¸\n",
    "    # MGAë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ attention mapì„ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ í¬í•¨\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # ì±„ë„ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ìœ„ì¹˜ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ë‘˜ ë‹¤ ë°˜ì˜ëœ ìµœì¢… feature map ë¦¬í„´\n",
    "\n",
    "\n",
    "\n",
    "# í•™ìŠµ\n",
    "\n",
    "def run():\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_loader = DataLoader(CTDataset(train_files, train_labels, transform=train_transform), batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(CTDataset(val_files, val_labels, transform=val_transform), batch_size=batch_size)\n",
    "    test_loader = DataLoader(CTDataset(test_files, test_labels, transform=val_transform), batch_size=batch_size)\n",
    "\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = FocalLoss(weight=torch.tensor([0.65, 0.35], device=device), gamma=2.0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    save_path = os.path.join(\"pth\", \"r18_cbam_mga_aug_focal150.pth\")\n",
    "    os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for imgs, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            imgs, labels, masks = imgs.to(device), labels.to(device), masks.to(device)\n",
    "            outputs = model(imgs)\n",
    "            ce_loss = criterion(outputs, labels)\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # [B, 1, H, W]\n",
    "            attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)  # [B, 224, 224]\n",
    "            masks = masks.view(masks.size(0), 224, 224)  # ê°•ì œë¡œ [B, 224, 224]ë¡œ reshape\n",
    "            mga_loss = F.mse_loss(attn_map, masks.float())\n",
    "            loss = ce_loss + lambda_mga * mga_loss\n",
    "            optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        print(f\"Train Acc: {correct/total:.4f}, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        model.eval(); val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels, _ in val_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                val_correct += (outputs.argmax(1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        val_acc = val_correct / val_total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"âœ… Saved best model!\")\n",
    "\n",
    "    # ---------------- í…ŒìŠ¤íŠ¸ ----------------\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, _ in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(y_true); y_pred = np.array(y_pred); y_probs = np.array(y_probs)\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nğŸ“Š Test Evaluation:\\nâœ… Accuracy: {acc*100:.2f}% | AUC: {auc:.4f} | F1: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\", cm)\n",
    "\n",
    "    metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "    with open(\"logs/final_test_metrics.csv\", 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=metrics.keys())\n",
    "        if not os.path.exists(\"logs/final_test_metrics.csv\"):\n",
    "            writer.writeheader()\n",
    "        writer.writerow(metrics)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1974167/24495587.py:42: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(\n",
      "[Epoch 1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 65.2465, Loss: 0.6626\n",
      "[Epoch 1] lambda_mga: 0.1000\n",
      "Val Acc: 0.6675\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 65.1661, Loss: 0.6476\n",
      "[Epoch 2] lambda_mga: 0.1040\n",
      "Val Acc: 0.6887\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 65.8628, Loss: 0.6447\n",
      "[Epoch 3] lambda_mga: 0.1080\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 66.6399, Loss: 0.6412\n",
      "[Epoch 4] lambda_mga: 0.1120\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 66.2379, Loss: 0.6384\n",
      "[Epoch 5] lambda_mga: 0.1160\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 66.2915, Loss: 0.6366\n",
      "[Epoch 6] lambda_mga: 0.1200\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 67.6045, Loss: 0.6311\n",
      "[Epoch 7] lambda_mga: 0.1240\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 67.4705, Loss: 0.6256\n",
      "[Epoch 8] lambda_mga: 0.1280\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:10<00:00, 46.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 67.8457, Loss: 0.6211\n",
      "[Epoch 9] lambda_mga: 0.1320\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:10<00:00, 46.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 68.2476, Loss: 0.6190\n",
      "[Epoch 10] lambda_mga: 0.1360\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 11]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 69.6945, Loss: 0.6101\n",
      "[Epoch 11] lambda_mga: 0.1400\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 12]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 70.4984, Loss: 0.6013\n",
      "[Epoch 12] lambda_mga: 0.1440\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 13]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 70.9271, Loss: 0.5925\n",
      "[Epoch 13] lambda_mga: 0.1480\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 14]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 71.3023, Loss: 0.5832\n",
      "[Epoch 14] lambda_mga: 0.1520\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 15]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 73.7406, Loss: 0.5655\n",
      "[Epoch 15] lambda_mga: 0.1560\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 16]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 31.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 74.6249, Loss: 0.5557\n",
      "[Epoch 16] lambda_mga: 0.1600\n",
      "Val Acc: 0.3175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 76.6077, Loss: 0.5363\n",
      "[Epoch 17] lambda_mga: 0.1640\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 18]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 78.5102, Loss: 0.5172\n",
      "[Epoch 18] lambda_mga: 0.1680\n",
      "Val Acc: 0.6412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 19]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 79.4748, Loss: 0.4997\n",
      "[Epoch 19] lambda_mga: 0.1720\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 20]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:10<00:00, 45.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 81.3773, Loss: 0.4790\n",
      "[Epoch 20] lambda_mga: 0.1760\n",
      "Val Acc: 0.3362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 21]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:10<00:00, 43.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 82.1543, Loss: 0.4692\n",
      "[Epoch 21] lambda_mga: 0.1800\n",
      "Val Acc: 0.6813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 22]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 31.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 83.6817, Loss: 0.4481\n",
      "[Epoch 22] lambda_mga: 0.1840\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 23]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 84.4855, Loss: 0.4397\n",
      "[Epoch 23] lambda_mga: 0.1880\n",
      "Val Acc: 0.3125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 24]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 85.9593, Loss: 0.4178\n",
      "[Epoch 24] lambda_mga: 0.1920\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 25]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 86.5756, Loss: 0.4155\n",
      "[Epoch 25] lambda_mga: 0.1960\n",
      "Val Acc: 0.5775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 26]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 31.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 86.2272, Loss: 0.4088\n",
      "[Epoch 26] lambda_mga: 0.2000\n",
      "Val Acc: 0.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 27]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 88.1565, Loss: 0.3864\n",
      "[Epoch 27] lambda_mga: 0.2040\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 28]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 88.5048, Loss: 0.3826\n",
      "[Epoch 28] lambda_mga: 0.2080\n",
      "Val Acc: 0.7050\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 29]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 90.0054, Loss: 0.3671\n",
      "[Epoch 29] lambda_mga: 0.2120\n",
      "Val Acc: 0.7362\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 39.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.6131, Loss: 0.3476\n",
      "[Epoch 30] lambda_mga: 0.2160\n",
      "Val Acc: 0.6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 31]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:10<00:00, 42.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.8006, Loss: 0.3463\n",
      "[Epoch 31] lambda_mga: 0.2200\n",
      "Val Acc: 0.3488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 32]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 37.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.9882, Loss: 0.3368\n",
      "[Epoch 32] lambda_mga: 0.2240\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 33]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 31.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.0954, Loss: 0.3332\n",
      "[Epoch 33] lambda_mga: 0.2280\n",
      "Val Acc: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 34]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.7653, Loss: 0.3254\n",
      "[Epoch 34] lambda_mga: 0.2320\n",
      "Val Acc: 0.4163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 35]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.3012, Loss: 0.3175\n",
      "[Epoch 35] lambda_mga: 0.2360\n",
      "Val Acc: 0.7250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 36]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.5959, Loss: 0.3152\n",
      "[Epoch 36] lambda_mga: 0.2400\n",
      "Val Acc: 0.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 37]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.3730, Loss: 0.3054\n",
      "[Epoch 37] lambda_mga: 0.2440\n",
      "Val Acc: 0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 38]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.5691, Loss: 0.3117\n",
      "[Epoch 38] lambda_mga: 0.2480\n",
      "Val Acc: 0.7400\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 39]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 31.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.9175, Loss: 0.3085\n",
      "[Epoch 39] lambda_mga: 0.2520\n",
      "Val Acc: 0.3900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 40]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.5606, Loss: 0.3028\n",
      "[Epoch 40] lambda_mga: 0.2560\n",
      "Val Acc: 0.6850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 41]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:10<00:00, 46.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.0429, Loss: 0.2940\n",
      "[Epoch 41] lambda_mga: 0.2600\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 42]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:09<00:00, 47.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.0965, Loss: 0.2864\n",
      "[Epoch 42] lambda_mga: 0.2640\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 43]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.3912, Loss: 0.2815\n",
      "[Epoch 43] lambda_mga: 0.2680\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 44]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.9357, Loss: 0.2897\n",
      "[Epoch 44] lambda_mga: 0.2720\n",
      "Val Acc: 0.6737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 45]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.0429, Loss: 0.2890\n",
      "[Epoch 45] lambda_mga: 0.2760\n",
      "Val Acc: 0.8662\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 46]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.1768, Loss: 0.2852\n",
      "[Epoch 46] lambda_mga: 0.2800\n",
      "Val Acc: 0.6787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 47]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0611, Loss: 0.2754\n",
      "[Epoch 47] lambda_mga: 0.2840\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.5788, Loss: 0.2792\n",
      "[Epoch 48] lambda_mga: 0.2880\n",
      "Val Acc: 0.5950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 49]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0611, Loss: 0.2754\n",
      "[Epoch 49] lambda_mga: 0.2920\n",
      "Val Acc: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 50]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0879, Loss: 0.2748\n",
      "[Epoch 50] lambda_mga: 0.2960\n",
      "Val Acc: 0.6987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 51]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 36.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7846, Loss: 0.2645\n",
      "[Epoch 51] lambda_mga: 0.3000\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 52]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:10<00:00, 43.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.2755, Loss: 0.2662\n",
      "[Epoch 52] lambda_mga: 0.3040\n",
      "Val Acc: 0.5487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 53]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 39.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3826, Loss: 0.2669\n",
      "[Epoch 53] lambda_mga: 0.3080\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 54]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.4094, Loss: 0.2689\n",
      "[Epoch 54] lambda_mga: 0.3120\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 55]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7578, Loss: 0.2607\n",
      "[Epoch 55] lambda_mga: 0.3160\n",
      "Val Acc: 0.3425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 56]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.4898, Loss: 0.2636\n",
      "[Epoch 56] lambda_mga: 0.3200\n",
      "Val Acc: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 57]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.5166, Loss: 0.2648\n",
      "[Epoch 57] lambda_mga: 0.3240\n",
      "Val Acc: 0.7087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 58]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9721, Loss: 0.2568\n",
      "[Epoch 58] lambda_mga: 0.3280\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 59]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9721, Loss: 0.2548\n",
      "[Epoch 59] lambda_mga: 0.3320\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 60]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9721, Loss: 0.2571\n",
      "[Epoch 60] lambda_mga: 0.3360\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 61]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.5434, Loss: 0.2634\n",
      "[Epoch 61] lambda_mga: 0.3400\n",
      "Val Acc: 0.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 62]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 41.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7846, Loss: 0.2562\n",
      "[Epoch 62] lambda_mga: 0.3440\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 63]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:10<00:00, 42.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7578, Loss: 0.2571\n",
      "[Epoch 63] lambda_mga: 0.3480\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 64]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 29.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.0525, Loss: 0.2522\n",
      "[Epoch 64] lambda_mga: 0.3520\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 65]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.3473, Loss: 0.2473\n",
      "[Epoch 65] lambda_mga: 0.3560\n",
      "Val Acc: 0.6713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 66]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6420, Loss: 0.2523\n",
      "[Epoch 66] lambda_mga: 0.3600\n",
      "Val Acc: 0.8425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 67]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.1597, Loss: 0.2574\n",
      "[Epoch 67] lambda_mga: 0.3640\n",
      "Val Acc: 0.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 68]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.2937, Loss: 0.2475\n",
      "[Epoch 68] lambda_mga: 0.3680\n",
      "Val Acc: 0.4138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 69]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5884, Loss: 0.2453\n",
      "[Epoch 69] lambda_mga: 0.3720\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 70]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6420, Loss: 0.2440\n",
      "[Epoch 70] lambda_mga: 0.3760\n",
      "Val Acc: 0.6787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 71]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 32.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4544, Loss: 0.2468\n",
      "[Epoch 71] lambda_mga: 0.3800\n",
      "Val Acc: 0.5938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 72]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 42.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8564, Loss: 0.2409\n",
      "[Epoch 72] lambda_mga: 0.3840\n",
      "Val Acc: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 73]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:10<00:00, 43.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6152, Loss: 0.2444\n",
      "[Epoch 73] lambda_mga: 0.3880\n",
      "Val Acc: 0.3987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 74]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7760, Loss: 0.2419\n",
      "[Epoch 74] lambda_mga: 0.3920\n",
      "Val Acc: 0.6750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 75]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7492, Loss: 0.2451\n",
      "[Epoch 75] lambda_mga: 0.3960\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 76]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7224, Loss: 0.2405\n",
      "[Epoch 76] lambda_mga: 0.4000\n",
      "Val Acc: 0.6900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 77]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.3387, Loss: 0.2357\n",
      "[Epoch 77] lambda_mga: 0.4040\n",
      "Val Acc: 0.6700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 78]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.1597, Loss: 0.2482\n",
      "[Epoch 78] lambda_mga: 0.4080\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 79]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8564, Loss: 0.2392\n",
      "[Epoch 79] lambda_mga: 0.4120\n",
      "Val Acc: 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 80]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8028, Loss: 0.2394\n",
      "[Epoch 80] lambda_mga: 0.4160\n",
      "Val Acc: 0.6625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 81]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 33.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.5080, Loss: 0.2417\n",
      "[Epoch 81] lambda_mga: 0.4200\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 82]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 41.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8296, Loss: 0.2372\n",
      "[Epoch 82] lambda_mga: 0.4240\n",
      "Val Acc: 0.3362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 83]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 41.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8296, Loss: 0.2380\n",
      "[Epoch 83] lambda_mga: 0.4280\n",
      "Val Acc: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 84]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4812, Loss: 0.2453\n",
      "[Epoch 84] lambda_mga: 0.4320\n",
      "Val Acc: 0.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 85]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.2047, Loss: 0.2331\n",
      "[Epoch 85] lambda_mga: 0.4360\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 86]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.9904, Loss: 0.2363\n",
      "[Epoch 86] lambda_mga: 0.4400\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 87]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8564, Loss: 0.2376\n",
      "[Epoch 87] lambda_mga: 0.4440\n",
      "Val Acc: 0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 88]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.6602, Loss: 0.2283\n",
      "[Epoch 88] lambda_mga: 0.4480\n",
      "Val Acc: 0.6613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 89]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.2047, Loss: 0.2329\n",
      "[Epoch 89] lambda_mga: 0.4520\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 90]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8296, Loss: 0.2409\n",
      "[Epoch 90] lambda_mga: 0.4560\n",
      "Val Acc: 0.6562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 91]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.4727, Loss: 0.2324\n",
      "[Epoch 91] lambda_mga: 0.4600\n",
      "Val Acc: 0.5988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 92]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 41.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.9904, Loss: 0.2359\n",
      "[Epoch 92] lambda_mga: 0.4640\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 93]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 39.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.4727, Loss: 0.2285\n",
      "[Epoch 93] lambda_mga: 0.4680\n",
      "Val Acc: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 94]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 27.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.6066, Loss: 0.2291\n",
      "[Epoch 94] lambda_mga: 0.4720\n",
      "Val Acc: 0.5275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 95]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.1511, Loss: 0.2345\n",
      "[Epoch 95] lambda_mga: 0.4760\n",
      "Val Acc: 0.6550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 96]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.1779, Loss: 0.2344\n",
      "[Epoch 96] lambda_mga: 0.4800\n",
      "Val Acc: 0.4462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 97]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.9100, Loss: 0.2367\n",
      "[Epoch 97] lambda_mga: 0.4840\n",
      "Val Acc: 0.6025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 98]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.9904, Loss: 0.2361\n",
      "[Epoch 98] lambda_mga: 0.4880\n",
      "Val Acc: 0.8237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 99]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 32.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.6066, Loss: 0.2257\n",
      "[Epoch 99] lambda_mga: 0.4920\n",
      "Val Acc: 0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 32.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.1779, Loss: 0.2302\n",
      "[Epoch 100] lambda_mga: 0.4960\n",
      "Val Acc: 0.5413\n",
      "\n",
      "ğŸ“Š Test Evaluation:\n",
      "âœ… Test Accuracy         : 87.12%\n",
      "ğŸ¯ AUC                   : 0.9110\n",
      "ğŸ“Œ Precision             : 0.9011\n",
      "ğŸ“Œ Recall (Sensitivity)  : 0.9029\n",
      "ğŸ“Œ Specificity           : 0.8109\n",
      "ğŸ“Œ F1 Score              : 0.9020\n",
      "ğŸ“Œ Balanced Accuracy     : 0.8569\n",
      "ğŸ“Œ MCC                   : 0.7144\n",
      "\n",
      "ğŸ“Œ Confusion Matrix:\n",
      "[[223  52]\n",
      " [ 51 474]]\n",
      "\n",
      "ğŸ“ í…ŒìŠ¤íŠ¸ ì§€í‘œ ì €ì¥ ì™„ë£Œ: logs/final_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# âœ… Test Accuracy         : 87.12%\n",
    "# ğŸ¯ AUC                   : 0.9110\n",
    "# ğŸ“Œ Precision             : 0.9011\n",
    "# ğŸ“Œ Recall (Sensitivity)  : 0.9029\n",
    "# ğŸ“Œ Specificity           : 0.8109\n",
    "# ğŸ“Œ F1 Score              : 0.9020\n",
    "# ğŸ“Œ Balanced Accuracy     : 0.8569\n",
    "# ğŸ“Œ MCC                   : 0.7144\n",
    "\n",
    "# ğŸ“Œ Confusion Matrix:\n",
    "# [[223  52]\n",
    "#  [ 51 474]]\n",
    "# r18_cbam_mga_aug_lr4_ep100_label1.pth\n",
    "# ì „ì²´ì½”ë“œ: ResNet18 + CBAM + MGA Loss + Lambda Scheduling (Label Smoothing + )\n",
    "\n",
    "import os, re, numpy as np, torch, gc\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "\n",
    "# -------------------- ë””ë°”ì´ìŠ¤ ì„¤ì • --------------------\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • --------------------\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# lambda MGA ìŠ¤ì¼€ì¤„ ì„¤ì •\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "total_epochs = num_epochs\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=10, p=0.5),\n",
    "    A.CoarseDropout(\n",
    "        max_holes=1, max_height=32, max_width=32, min_holes=1, \n",
    "        min_height=16, min_width=16, fill_value=0, p=0.5),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        fname = os.path.basename(file_path)\n",
    "\n",
    "        img = np.load(file_path)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(img.shape[0], img.shape[1])).sum(axis=0)\n",
    "        else:\n",
    "            mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img, mask=mask)\n",
    "            img = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "        else:\n",
    "            img = torch.tensor(img).unsqueeze(0)\n",
    "            mask = torch.tensor(mask)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "# -------------------- Bounding Box Mask --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    masks = []\n",
    "    for bbox in bbox_list:\n",
    "        mask = np.zeros(image_size, dtype=np.float32)\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0\n",
    "        masks.append(mask)\n",
    "    masks = np.stack(masks)\n",
    "    masks = np.expand_dims(masks, axis=1)\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)                         # íŒŒì´ì¬ random\n",
    "    np.random.seed(seed)                      # numpy\n",
    "    torch.manual_seed(seed)                   # torch CPU\n",
    "    torch.cuda.manual_seed(seed)              # torch GPU\n",
    "    torch.cuda.manual_seed_all(seed)          # multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # ì—°ì‚° ë™ì¼í•˜ê²Œ\n",
    "    torch.backends.cudnn.benchmark = False    # ì—°ì‚° ì†ë„ ìµœì í™” OFF (ê°™ì€ ì—°ì‚° ë³´ì¥)\n",
    "\n",
    "# -------------------- Bounding Box CSV --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    bbox_dict = {}\n",
    "    for _, row in df.iterrows():\n",
    "        pid = row['pid']\n",
    "        slice_idx = int(re.findall(r'\\d+', str(row['slice']))[0])\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"\n",
    "        bbox = eval(row['bb'])\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)\n",
    "    return bbox_dict\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "\n",
    "def extract_label_from_filename(fname):\n",
    "    try:\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# -------------------- ë¼ë²¨ ì¶”ì¶œ --------------------\n",
    "def extract_label_from_filename(fname): # fname : íŒŒì¼ ì´ë¦„ (ì˜ˆ: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # ì´ ì´ë¦„ì—ì„œ malignancy score(ì•…ì„±ë„ ì ìˆ˜)ë¥¼ ì¶”ì¶œí•´ì„œ ë¼ë²¨ë¡œ ë³€í™˜\n",
    "    try:    # íŒŒì¼ëª…ì´ ì´ìƒí•˜ê±°ë‚˜ ì—ëŸ¬ë‚˜ë©´ exceptë¡œ ë¹ ì ¸ë‚˜ê°€ì„œ None ë°˜í™˜í•¨ (ì•ˆì „ì¥ì¹˜)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # íŒŒì¼ëª…ì—ì„œ _ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ê²ƒë“¤ ì¤‘ì— ë§ˆì§€ë§‰ì—êº¼ë¥¼ ê°€ì ¸ì™€ì„œ .npyë¥¼ \"\" ì´ë ‡ê²Œ ê³µë°±ìœ¼ë¡œ ì²˜ë¦¬í•¨\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- ì´ê²Œ malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # ë¼ë²¨ ê²°ì • ë¡œì§ìœ¼ë¡œ\n",
    "        # score == 3 -> ì¤‘ë¦½ -> None ë°˜í™˜ -> í•™ìŠµì—ì„œ ì œì™¸\n",
    "        # score >= 4 -> ì•”(ì–‘ì„±) -> 1\n",
    "        # score <= 2 -> ì •ìƒ(ìŒì„±) -> 0\n",
    "        # int(score >= 4)ëŠ” íŒŒì´ì¬ì—ì„œ True -> 1\n",
    "        # False -> 0 ì´ë‹ˆê¹ ìë™ìœ¼ë¡œ ë¼ë²¨ì´ ë¨\n",
    "    except:\n",
    "        return None\n",
    "        # í˜¹ì‹œ splitì´ë‚˜ replace, int ë³€í™˜ì´ ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ None ë°˜í™˜í•˜ê³  ë¬´ì‹œ\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    # PyTorchì˜ Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†í•´ì„œ ì»¤ã…¡í…€ ë°ì´í„°ì…‹ ì •ì˜\n",
    "    # ë‚˜ì¤‘ì— DataLoaderë‘ ê°™ì´ ì“°ì´ê¸° ë•Œë¬¸ì— __len__()ì´ë‘ __getitem__()ì„ ê¼­ ë„£ì–´ì¤˜ì•¼í•¨\n",
    "    def __init__(self, paths, labels, transform=None):  # ìƒì„±ì : ì„¸ê°œì˜ ì¸ìë¥¼ ë°›ìŒ\n",
    "        # paths : ì´ë¯¸ì§€ .npy íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "        # labels : ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ (0, 1 or None)\n",
    "        # transform : ì´ë¯¸ì§€ ì¦ê°• ì„¤ì • (train_transform, val_transform ë“±)\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # ë°›ì€ ì¸ìë¥¼ ë©¤ë²„ ë³€ìˆ˜ë¡œ ì €ì¥. ë‚˜ì¤‘ì— gettem()ì—ì„œ ì ‘ê·¼í•¨\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoaderê°€ ì´ê±¸ í˜¸ì¶œí•  ë•Œ indexì— í•´ë‹¹í•˜ëŠ” sample í•˜ë‚˜ë¥¼ ë°˜í™˜\n",
    "        # ì´ë¯¸ì§€, ë¼ë²¨, ë§ˆìŠ¤í¬( = MGAìš© target) 3ê°œë¥¼ ë¦¬í„´í•¨\n",
    "        file_path = self.paths[idx] # íŒŒì¼ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        label = self.labels[idx]    # ë¼ë²¨ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        fname = os.path.basename(file_path) # ì „ì²´ ê²½ë¡œì—ì„œ íŒŒì¼ ì´ë¦„ë§Œ ì¶”ì¶œ -> ë‚˜ì¤‘ì— bbox_dict[fname] ì°¾ì„ë•Œ ì“°ì„\n",
    "\n",
    "        img = np.load(file_path)    # .npy íŒŒì¼ì—ì„œ CT ìŠ¬ë¼ì´ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° -> í‘ë°± CT ì´ë¯¸ì§€, shapeì€ (H, W)\n",
    "        img = np.clip(img, -1000, 400)  # CT ì´ë¯¸ì§€ HU ê°’ì´ ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´ ë…¸ì´ì¦ˆ -> -1000(ê³µê¸°) ~ 400(ì—°ì¡°ì§)ìœ¼ë¡œ í´ë¦¬í•‘í•´ì„œ ë…¸ì´ì¦ˆ ì œê±°\n",
    "        img = (img + 1000) / 1400.  # ì •ê·œí™” : -1000 -> 0, 400 -> 1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë°”ê¿”ì¤Œ -> ëª¨ë¸ì´ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•¨\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        h, w = img.shape\n",
    "        img = np.expand_dims(img, axis=-1)  # (H, W, 1)\n",
    "\n",
    "        # ë§ˆìŠ¤í¬ ìƒì„±\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(h, w)).sum(dim=0).numpy()\n",
    "        else:\n",
    "            mask = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "        # transform ì ìš©\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented['image']  # shape: [1, 224, 224]\n",
    "            mask = augmented['mask']  # shape: [224, 224]\n",
    "        else:\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "            mask = torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    # ì „ì²´ ë°ì´í„°ì…‹ ê¸¸ì´ ë°˜í™˜ -> DataLoaderê°€ ì•„ë¼ì•¼ ë°°ì¹˜ ìª¼ê°¤ ìˆ˜ ìˆìŒ.\n",
    "\n",
    "# -------------------- CBAM ì •ì˜ (MGA í¬í•¨) --------------------\n",
    "# 2 Step : Channel Attention(ì–´ë–¤ ì±„ë„ì— ì§‘ì¤‘í• ì§€) * Spatial Attention(ì–´ë””ì— ì§‘ì¤‘í• ì§€) = ìµœì¢… Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # ì…ë ¥ feature mapì˜ ì±„ë„ë³„ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•´ì„œ ê°•ì¡°í•¨\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : ì…ë ¥ ì±„ë„ ìˆ˜\n",
    "        # ratio : ì¤‘ê°„ ì±„ë„ ì¶•ì†Œ ë¹„ìœ¨. ê¸°ë³¸ 1/16ìœ¼ë¡œ bottlenck êµ¬ì„±\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP ì—­í• ì„ í•˜ëŠ” 1x1 conv ë¸”ë¡ -> ì±„ë„ ì••ì¶• -> ë¹„ì„ í˜• -> ë³µì› (sharedëŠ” avg/max ë‘˜ë‹¤ì—ì„œ ê°™ì´ ì”€)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # í‰ê·  í’€ë§ / ìµœëŒ€ í’€ë§ìœ¼ë¡œ ë‘ê°€ì§€ ì „ì—­ ì •ë³´ë¥¼ ì¶”ì¶œ\n",
    "        # ë§ˆì§€ë§‰ sigmoidëŠ” attention weightë¡œ ìŠ¤ì¼€ì¼ë§\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max í’€ë§ ê²½ê³¼ë¥¼ ê°ê° shape MLPì— í†µê³¼ì‹œí‚¤ê³ , ë”í•œ í›„ sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> ì±„ë„ë§ˆë‹¤ ì¤‘ìš”ë„ weightë¥¼ ê³±í•˜ê²Œ ë¨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # ê³µê°„ì ìœ¼ë¡œ ì–´ë””ì— ì§‘ì¤‘í• ì§€ë¥¼ ê²°ì • -> ê° ì±„ë„ ë‚´ë¶€ì—ì„œ ì¤‘ìš”í•œ ìœ„ì¹˜ ì°¾ê¸°\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # ì±„ë„ ì°¨ì›ì€ í‰ê· , ìµœëŒ€ ë‘ ê°œë§Œ ì¨ì„œ concat\n",
    "    # ê·¸ê±¸ 1ì±„ë„ë¡œ ì¤„ì—¬ì£¼ëŠ” conv\n",
    "    # ì»¤ë„ í¬ê¸° k=7ì´ë©´ ë„“ì€ ì˜ì—­ê¹Œì§€ ê°ì§€ ê°€ëŠ¥\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # ì…ë ¥ feature mapì—ì„œ :\n",
    "    # í‰ê· , ìµœëŒ€ê°’ì„ ê° spatial ìœ„ì¹˜ë³„ë¡œ êµ¬í•¨ -> [B, 1, H, W] ë‘ ê°œ\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> ìœ„ì¹˜ë³„ ì¤‘ìš”ë„ map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttentionì„ ë‚´ë¶€ì— ì„ ì–¸\n",
    "    # MGAë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ attention mapì„ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ í¬í•¨\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # ì±„ë„ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ìœ„ì¹˜ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ë‘˜ ë‹¤ ë°˜ì˜ëœ ìµœì¢… feature map ë¦¬í„´\n",
    "\n",
    "# -------------------- ResNet18 + CBAM ëª¨ë¸ ì •ì˜ --------------------\n",
    "# BasicBlockCBAM : ResNetì˜ ê¸°ë³¸ Residual Block í•˜ë‚˜ë¥¼ ì •ì˜\n",
    "# â†’ conv â†’ BN â†’ ReLU â†’ conv â†’ BN â†’ (CBAM optional) â†’ Add â†’ ReLU\n",
    "\n",
    "# ResNet18_CBAM : ResNet18 êµ¬ì¡°ë¡œ ì „ì²´ ë„¤íŠ¸ì›Œí¬ ìŒ“ê¸°\n",
    "# â†’ conv1 â†’ layer1~3 â†’ layer4 â†’ avgpool â†’ fc\n",
    "\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        # ì…ë ¥ ì±„ë„: in_planes, ì¶œë ¥ ì±„ë„: out_planes, 3x3 ì»¤ë„, padding=1ë¡œ í¬ê¸° ìœ ì§€, strideë¡œ í¬ê¸° ì¡°ì ˆ\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)   # ë°°ì¹˜ ì •ê·œí™”\n",
    "        self.relu = nn.ReLU()   # ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        # ë‘ë²ˆì§¸ conv, ì±„ë„ ìˆ˜ ìœ ì§€, í¬ê¸° ìœ ì§€\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)   # ë°°ì¹˜ ì •ê·œí™”\n",
    "\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None  # CBAM ëª¨ë“ˆ ì‚¬ìš© ì—¬ë¶€\n",
    "        self.downsample = downsample    # residual ì—°ê²° ì‹œ ì°¨ì› ë§ì¶”ëŠ” conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # skip connectionìš© ì…ë ¥ ì €ì¥\n",
    "\n",
    "        out = self.conv1(x) # ì²« ë²ˆì§¸ conv\n",
    "        out = self.bn1(out) # ì •ê·œí™”\n",
    "        out = self.relu(out)  # í™œì„±í™”\n",
    "\n",
    "        out = self.conv2(out)   # ë‘ ë²ˆì§¸ conv\n",
    "        out = self.bn2(out) # ì •ê·œí™”\n",
    "\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)    # CBAM ì ìš©\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)   # shortcut ê²½ë¡œ ë³´ì •\n",
    "\n",
    "        out += residual # skip connection\n",
    "        out = self.relu(out)    # ì¶œë ¥ì— ReLU ì ìš©\n",
    "\n",
    "        return out  # ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2, use_cbam=True):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "        self.use_cbam = use_cbam\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, blocks=2, use_cbam=use_cbam)\n",
    "        self.layer2 = self._make_layer(128, blocks=2, stride=2, use_cbam=use_cbam)\n",
    "        self.layer3 = self._make_layer(256, blocks=2, stride=2, use_cbam=use_cbam)\n",
    "        self.layer4 = self._make_layer(512, blocks=2, stride=2, use_cbam=False)  # ë§ˆì§€ë§‰ ë¸”ë¡ì€ CBAM ì œê±°\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam=use_cbam)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "# -------------------- í•™ìŠµ ë£¨í”„ --------------------\n",
    "def run():\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_dataset = CTDataset(train_files, train_labels, transform=train_transform)\n",
    "    val_dataset = CTDataset(val_files, val_labels, transform=val_transform)\n",
    "    test_dataset = CTDataset(test_files, test_labels, transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    best_acc = 0.0  # ê°€ì¥ ë†’ì€ val accuracyë¥¼ ì €ì¥\n",
    "    save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"r18_cbam_mga_aug_lr4_ep100_label1.pth\")\n",
    "\n",
    "    # í•™ìŠµ ë£¨í”„ ì‹œì‘\n",
    "    for epoch in range(num_epochs):\n",
    "        # MGA ìŠ¤ì¼€ì¥´ë§: ì´ˆê¸° lambda -> ì ì  ì¦ê°€ì‹œí‚´\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "\n",
    "        model.train()  # í•™ìŠµ ëª¨ë“œë¡œ ë³€ê²½\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # í•œ epoch ë™ì•ˆ ëª¨ë“  train ë°ì´í„°ë¥¼ í•™ìŠµ\n",
    "        for images, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)  # forward pass\n",
    "            ce_loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "            # -------------------- MGA Loss ê³„ì‚° ìœ„ì¹˜ --------------------\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # attention map êº¼ë‚´ì˜¤ê¸°\n",
    "\n",
    "            if attn_map is not None:\n",
    "                attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                attn_loss = F.mse_loss(attn_map, masks)  # maskì™€ì˜ MSE loss\n",
    "                loss = ce_loss + lambda_mga * attn_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Acc: {(correct/total)*100:.4f}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] lambda_mga: {lambda_mga:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()  # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "\n",
    "        # -------------------- ê²€ì¦ --------------------\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iamegs, labels, masks in val_loader:\n",
    "                iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "                outputs = model(iamegs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"âœ… Saved best model!\")\n",
    "\n",
    "    # -------------------- í…ŒìŠ¤íŠ¸ --------------------\n",
    "    print(\"\\nğŸ“Š Test Evaluation:\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # numpy ë°°ì—´ë¡œ ë³€í™˜\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    # ì§€í‘œ ê³„ì‚°\n",
    "    from sklearn.metrics import (\n",
    "        classification_report, roc_auc_score, confusion_matrix,\n",
    "        precision_score, recall_score, balanced_accuracy_score,\n",
    "        matthews_corrcoef, f1_score\n",
    "    )\n",
    "\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    # ğŸ“‹ ì¶œë ¥\n",
    "    print(f\"âœ… Test Accuracy         : {acc*100:.2f}%\")\n",
    "    print(f\"ğŸ¯ AUC                   : {auc:.4f}\")\n",
    "    print(f\"ğŸ“Œ Precision             : {precision:.4f}\")\n",
    "    print(f\"ğŸ“Œ Recall (Sensitivity)  : {recall:.4f}\")\n",
    "    print(f\"ğŸ“Œ Specificity           : {specificity:.4f}\")\n",
    "    print(f\"ğŸ“Œ F1 Score              : {f1:.4f}\")\n",
    "    print(f\"ğŸ“Œ Balanced Accuracy     : {balanced_acc:.4f}\")\n",
    "    print(f\"ğŸ“Œ MCC                   : {mcc:.4f}\")\n",
    "    print(\"\\nğŸ“Œ Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # ğŸ“ CSVë¡œ ì €ì¥\n",
    "    test_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"phase\": \"test\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "\n",
    "    csv_path = \"logs/final_test_metrics.csv\"\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=test_metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(test_metrics)\n",
    "\n",
    "    print(f\"\\nğŸ“ í…ŒìŠ¤íŠ¸ ì§€í‘œ ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "\n",
    "# ì§„ì…ì \n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… Test Accuracy         : 85.50%\n",
    "# ğŸ¯ AUC                   : 0.9074\n",
    "# ğŸ“Œ Precision             : 0.9034\n",
    "# ğŸ“Œ Recall (Sensitivity)  : 0.8724\n",
    "# ğŸ“Œ Specificity           : 0.8218\n",
    "# ğŸ“Œ F1 Score              : 0.8876\n",
    "# ğŸ“Œ Balanced Accuracy     : 0.8471\n",
    "# ğŸ“Œ MCC                   : 0.6844\n",
    "\n",
    "# ğŸ“Œ Confusion Matrix:\n",
    "# [[226  49]\n",
    "#  [ 67 458]]\n",
    "\n",
    "# r18_cbam_mga_aug_lr4_ep100_weight2.pth\n",
    "# ì „ì²´ì½”ë“œ: ResNet18 + CBAM + MGA Loss + Lambda Scheduling (CE Weight + mask íšŒì „)\n",
    "\n",
    "import os, re, numpy as np, torch, gc\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "\n",
    "# -------------------- ë””ë°”ì´ìŠ¤ ì„¤ì • --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • --------------------\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# lambda MGA ìŠ¤ì¼€ì¤„ ì„¤ì •\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "total_epochs = num_epochs\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit=10, p=0.5),\n",
    "    A.CoarseDropout(\n",
    "        max_holes=1, max_height=32, max_width=32, min_holes=1, \n",
    "        min_height=16, min_width=16, fill_value=0, p=0.5),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        fname = os.path.basename(file_path)\n",
    "\n",
    "        img = np.load(file_path)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.\n",
    "        img = img.astype(np.float32)\n",
    "\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(img.shape[0], img.shape[1])).sum(axis=0)\n",
    "        else:\n",
    "            mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img, mask=mask)\n",
    "            img = transformed['image']\n",
    "            mask = transformed['mask']\n",
    "        else:\n",
    "            img = torch.tensor(img).unsqueeze(0)\n",
    "            mask = torch.tensor(mask)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "# ì‹œë“œ ê³ ì •\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)                         # íŒŒì´ì¬ random\n",
    "    np.random.seed(seed)                      # numpy\n",
    "    torch.manual_seed(seed)                   # torch CPU\n",
    "    torch.cuda.manual_seed(seed)              # torch GPU\n",
    "    torch.cuda.manual_seed_all(seed)          # multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # ì—°ì‚° ë™ì¼í•˜ê²Œ\n",
    "    torch.backends.cudnn.benchmark = False    # ì—°ì‚° ì†ë„ ìµœì í™” OFF (ê°™ì€ ì—°ì‚° ë³´ì¥)\n",
    "\n",
    "# -------------------- Bounding Box Mask --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    masks = []\n",
    "    for bbox in bbox_list:\n",
    "        mask = np.zeros(image_size, dtype=np.float32)\n",
    "        x_min, y_min, x_max, y_max = bbox\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0\n",
    "        masks.append(mask)\n",
    "    masks = np.stack(masks)\n",
    "    masks = np.expand_dims(masks, axis=1)\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "\n",
    "# -------------------- Bounding Box CSV --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    bbox_dict = {}\n",
    "    for _, row in df.iterrows():\n",
    "        pid = row['pid']\n",
    "        slice_idx = int(re.findall(r'\\d+', str(row['slice']))[0])\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"\n",
    "        bbox = eval(row['bb'])\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)\n",
    "    return bbox_dict\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "\n",
    "def extract_label_from_filename(fname):\n",
    "    try:\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# -------------------- ë¼ë²¨ ì¶”ì¶œ --------------------\n",
    "def extract_label_from_filename(fname): # fname : íŒŒì¼ ì´ë¦„ (ì˜ˆ: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # ì´ ì´ë¦„ì—ì„œ malignancy score(ì•…ì„±ë„ ì ìˆ˜)ë¥¼ ì¶”ì¶œí•´ì„œ ë¼ë²¨ë¡œ ë³€í™˜\n",
    "    try:    # íŒŒì¼ëª…ì´ ì´ìƒí•˜ê±°ë‚˜ ì—ëŸ¬ë‚˜ë©´ exceptë¡œ ë¹ ì ¸ë‚˜ê°€ì„œ None ë°˜í™˜í•¨ (ì•ˆì „ì¥ì¹˜)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # íŒŒì¼ëª…ì—ì„œ _ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ê²ƒë“¤ ì¤‘ì— ë§ˆì§€ë§‰ì—êº¼ë¥¼ ê°€ì ¸ì™€ì„œ .npyë¥¼ \"\" ì´ë ‡ê²Œ ê³µë°±ìœ¼ë¡œ ì²˜ë¦¬í•¨\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- ì´ê²Œ malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # ë¼ë²¨ ê²°ì • ë¡œì§ìœ¼ë¡œ\n",
    "        # score == 3 -> ì¤‘ë¦½ -> None ë°˜í™˜ -> í•™ìŠµì—ì„œ ì œì™¸\n",
    "        # score >= 4 -> ì•”(ì–‘ì„±) -> 1\n",
    "        # score <= 2 -> ì •ìƒ(ìŒì„±) -> 0\n",
    "        # int(score >= 4)ëŠ” íŒŒì´ì¬ì—ì„œ True -> 1\n",
    "        # False -> 0 ì´ë‹ˆê¹ ìë™ìœ¼ë¡œ ë¼ë²¨ì´ ë¨\n",
    "    except:\n",
    "        return None\n",
    "        # í˜¹ì‹œ splitì´ë‚˜ replace, int ë³€í™˜ì´ ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ None ë°˜í™˜í•˜ê³  ë¬´ì‹œ\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    # PyTorchì˜ Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†í•´ì„œ ì»¤ã…¡í…€ ë°ì´í„°ì…‹ ì •ì˜\n",
    "    # ë‚˜ì¤‘ì— DataLoaderë‘ ê°™ì´ ì“°ì´ê¸° ë•Œë¬¸ì— __len__()ì´ë‘ __getitem__()ì„ ê¼­ ë„£ì–´ì¤˜ì•¼í•¨\n",
    "    def __init__(self, paths, labels, transform=None):  # ìƒì„±ì : ì„¸ê°œì˜ ì¸ìë¥¼ ë°›ìŒ\n",
    "        # paths : ì´ë¯¸ì§€ .npy íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "        # labels : ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ (0, 1 or None)\n",
    "        # transform : ì´ë¯¸ì§€ ì¦ê°• ì„¤ì • (train_transform, val_transform ë“±)\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # ë°›ì€ ì¸ìë¥¼ ë©¤ë²„ ë³€ìˆ˜ë¡œ ì €ì¥. ë‚˜ì¤‘ì— gettem()ì—ì„œ ì ‘ê·¼í•¨\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoaderê°€ ì´ê±¸ í˜¸ì¶œí•  ë•Œ indexì— í•´ë‹¹í•˜ëŠ” sample í•˜ë‚˜ë¥¼ ë°˜í™˜\n",
    "        # ì´ë¯¸ì§€, ë¼ë²¨, ë§ˆìŠ¤í¬( = MGAìš© target) 3ê°œë¥¼ ë¦¬í„´í•¨\n",
    "        file_path = self.paths[idx] # íŒŒì¼ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        label = self.labels[idx]    # ë¼ë²¨ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        fname = os.path.basename(file_path) # ì „ì²´ ê²½ë¡œì—ì„œ íŒŒì¼ ì´ë¦„ë§Œ ì¶”ì¶œ -> ë‚˜ì¤‘ì— bbox_dict[fname] ì°¾ì„ë•Œ ì“°ì„\n",
    "\n",
    "        img = np.load(file_path)    # .npy íŒŒì¼ì—ì„œ CT ìŠ¬ë¼ì´ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° -> í‘ë°± CT ì´ë¯¸ì§€, shapeì€ (H, W)\n",
    "        img = np.clip(img, -1000, 400)  # CT ì´ë¯¸ì§€ HU ê°’ì´ ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´ ë…¸ì´ì¦ˆ -> -1000(ê³µê¸°) ~ 400(ì—°ì¡°ì§)ìœ¼ë¡œ í´ë¦¬í•‘í•´ì„œ ë…¸ì´ì¦ˆ ì œê±°\n",
    "        img = (img + 1000) / 1400.  # ì •ê·œí™” : -1000 -> 0, 400 -> 1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë°”ê¿”ì¤Œ -> ëª¨ë¸ì´ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•¨\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        h, w = img.shape\n",
    "        img = np.expand_dims(img, axis=-1)  # (H, W, 1)\n",
    "\n",
    "        # ë§ˆìŠ¤í¬ ìƒì„±\n",
    "        if fname in bbox_dict:\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(h, w)).sum(dim=0).numpy()\n",
    "        else:\n",
    "            mask = np.zeros((h, w), dtype=np.float32)\n",
    "\n",
    "        # transform ì ìš©\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented['image']  # shape: [1, 224, 224]\n",
    "            mask = augmented['mask']  # shape: [224, 224]\n",
    "        else:\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "            mask = torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    # ì „ì²´ ë°ì´í„°ì…‹ ê¸¸ì´ ë°˜í™˜ -> DataLoaderê°€ ì•„ë¼ì•¼ ë°°ì¹˜ ìª¼ê°¤ ìˆ˜ ìˆìŒ.\n",
    "\n",
    "# -------------------- CBAM ì •ì˜ (MGA í¬í•¨) --------------------\n",
    "# 2 Step : Channel Attention(ì–´ë–¤ ì±„ë„ì— ì§‘ì¤‘í• ì§€) * Spatial Attention(ì–´ë””ì— ì§‘ì¤‘í• ì§€) = ìµœì¢… Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # ì…ë ¥ feature mapì˜ ì±„ë„ë³„ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•´ì„œ ê°•ì¡°í•¨\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : ì…ë ¥ ì±„ë„ ìˆ˜\n",
    "        # ratio : ì¤‘ê°„ ì±„ë„ ì¶•ì†Œ ë¹„ìœ¨. ê¸°ë³¸ 1/16ìœ¼ë¡œ bottlenck êµ¬ì„±\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP ì—­í• ì„ í•˜ëŠ” 1x1 conv ë¸”ë¡ -> ì±„ë„ ì••ì¶• -> ë¹„ì„ í˜• -> ë³µì› (sharedëŠ” avg/max ë‘˜ë‹¤ì—ì„œ ê°™ì´ ì”€)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # í‰ê·  í’€ë§ / ìµœëŒ€ í’€ë§ìœ¼ë¡œ ë‘ê°€ì§€ ì „ì—­ ì •ë³´ë¥¼ ì¶”ì¶œ\n",
    "        # ë§ˆì§€ë§‰ sigmoidëŠ” attention weightë¡œ ìŠ¤ì¼€ì¼ë§\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max í’€ë§ ê²½ê³¼ë¥¼ ê°ê° shape MLPì— í†µê³¼ì‹œí‚¤ê³ , ë”í•œ í›„ sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> ì±„ë„ë§ˆë‹¤ ì¤‘ìš”ë„ weightë¥¼ ê³±í•˜ê²Œ ë¨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # ê³µê°„ì ìœ¼ë¡œ ì–´ë””ì— ì§‘ì¤‘í• ì§€ë¥¼ ê²°ì • -> ê° ì±„ë„ ë‚´ë¶€ì—ì„œ ì¤‘ìš”í•œ ìœ„ì¹˜ ì°¾ê¸°\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # ì±„ë„ ì°¨ì›ì€ í‰ê· , ìµœëŒ€ ë‘ ê°œë§Œ ì¨ì„œ concat\n",
    "    # ê·¸ê±¸ 1ì±„ë„ë¡œ ì¤„ì—¬ì£¼ëŠ” conv\n",
    "    # ì»¤ë„ í¬ê¸° k=7ì´ë©´ ë„“ì€ ì˜ì—­ê¹Œì§€ ê°ì§€ ê°€ëŠ¥\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # ì…ë ¥ feature mapì—ì„œ :\n",
    "    # í‰ê· , ìµœëŒ€ê°’ì„ ê° spatial ìœ„ì¹˜ë³„ë¡œ êµ¬í•¨ -> [B, 1, H, W] ë‘ ê°œ\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> ìœ„ì¹˜ë³„ ì¤‘ìš”ë„ map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttentionì„ ë‚´ë¶€ì— ì„ ì–¸\n",
    "    # MGAë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ attention mapì„ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ í¬í•¨\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # ì±„ë„ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ìœ„ì¹˜ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ë‘˜ ë‹¤ ë°˜ì˜ëœ ìµœì¢… feature map ë¦¬í„´\n",
    "\n",
    "# -------------------- ResNet18 + CBAM ëª¨ë¸ ì •ì˜ --------------------\n",
    "# BasicBlockCBAM : ResNetì˜ ê¸°ë³¸ Residual Block í•˜ë‚˜ë¥¼ ì •ì˜\n",
    "# â†’ conv â†’ BN â†’ ReLU â†’ conv â†’ BN â†’ (CBAM optional) â†’ Add â†’ ReLU\n",
    "\n",
    "# ResNet18_CBAM : ResNet18 êµ¬ì¡°ë¡œ ì „ì²´ ë„¤íŠ¸ì›Œí¬ ìŒ“ê¸°\n",
    "# â†’ conv1 â†’ layer1~3 â†’ layer4 â†’ avgpool â†’ fc\n",
    "\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        # ì…ë ¥ ì±„ë„: in_planes, ì¶œë ¥ ì±„ë„: out_planes, 3x3 ì»¤ë„, padding=1ë¡œ í¬ê¸° ìœ ì§€, strideë¡œ í¬ê¸° ì¡°ì ˆ\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)   # ë°°ì¹˜ ì •ê·œí™”\n",
    "        self.relu = nn.ReLU()   # ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        # ë‘ë²ˆì§¸ conv, ì±„ë„ ìˆ˜ ìœ ì§€, í¬ê¸° ìœ ì§€\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)   # ë°°ì¹˜ ì •ê·œí™”\n",
    "\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None  # CBAM ëª¨ë“ˆ ì‚¬ìš© ì—¬ë¶€\n",
    "        self.downsample = downsample    # residual ì—°ê²° ì‹œ ì°¨ì› ë§ì¶”ëŠ” conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # skip connectionìš© ì…ë ¥ ì €ì¥\n",
    "\n",
    "        out = self.conv1(x) # ì²« ë²ˆì§¸ conv\n",
    "        out = self.bn1(out) # ì •ê·œí™”\n",
    "        out = self.relu(out)  # í™œì„±í™”\n",
    "\n",
    "        out = self.conv2(out)   # ë‘ ë²ˆì§¸ conv\n",
    "        out = self.bn2(out) # ì •ê·œí™”\n",
    "\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)    # CBAM ì ìš©\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)   # shortcut ê²½ë¡œ ë³´ì •\n",
    "\n",
    "        out += residual # skip connection\n",
    "        out = self.relu(out)    # ì¶œë ¥ì— ReLU ì ìš©\n",
    "\n",
    "        return out  # ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64 # ì¡°ê¸° ì…ë ¥ ì±„ë„ ìˆ˜ ì„¤ì •\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # ì…ë ¥: [B, 1, 224, 224] -> ì¶œë ¥: [B, 64, 112, 112], í° ì»¤ë„ë¡œ ë„“ì€ ì˜ì—­ ìº¡ì²˜ \n",
    "        self.bn1 = nn.BatchNorm2d(64)   # ì •ê·œí™”\n",
    "        self.relu = nn.ReLU()   # í™œì„±í™”\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # í’€ë§: [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        self.layer1 = self._make_layer(64, blocks=2)  # [B, 64, 56, 56] ìœ ì§€\n",
    "        self.layer2 = self._make_layer(128, blocks=2, stride=2)  # [B, 128, 28, 28] ë‹¤ìš´ìƒ˜í”Œë§\n",
    "        self.layer3 = self._make_layer(256, blocks=2, stride=2)  # [B, 256, 14, 14] ë‹¤ìš´ìƒ˜í”Œë§\n",
    "        self.layer4 = self._make_layer(512, blocks=2, stride=2, use_cbam=False)  # [B, 512, 7, 7], CBAM ë¯¸ì‚¬ìš©\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # [B, 512, 7, 7] -> [B, 512, 1, 1]\n",
    "        self.fc = nn.Linear(512, num_classes)  # [B, 512] -> [B, num_classes]\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        # Planes : í•´ë‹¹ ë ˆì´ì–´ì˜ ì¶œë ¥ ì±„ë„ ìˆ˜\n",
    "        # # blocks : ë¸”ë¡ ìˆ˜\n",
    "        # stride=2ì¸ ê²½ìš° ë‹¤ìš´ìƒ˜í”Œë§ (í•´ìƒë„ ì ˆë°˜)\n",
    "\n",
    "        downsample = None   # ìŠ¤í‚µ ì—°ê²°í•´ì„œ ì…ë ¥/ì¶œë ¥ í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ë§ì¶°ì•¼ í•¨\n",
    "\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                # 1x1 convë¡œ ì±„ë„ ìˆ˜   ë° ê³µê°„ í¬ê¸° ë§ì¶¤\n",
    "                nn.BatchNorm2d(planes))\n",
    "            \n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam=use_cbam)]\n",
    "        # ì²« ë¸”ë¡ì€ ë‹¤ìš´ìƒ˜í”Œë§ ì ìš© ê°€ëŠ¥ì„± ìˆìŒ\n",
    "        self.in_planes = planes # ì´í›„ ë¸”ë¡ì„ ìœ„í•œ ì…ë ¥ ì±„ë„ ì—…ë°ì´íŠ¸\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "            # ë‚˜ë¨¸ì§€ ë¸”ë¡ì€ stride=1ë¡œ ë™ì¼í•œ í•´ìƒë„ ìœ ì§€\n",
    "\n",
    "        return nn.Sequential(*layers)   # ë¸”ë¡ë“¤ì„ Seguentialë¡œ ë¬¶ì–´ ë°˜í™˜\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # ì…ë ¥: [B, 1, 224, 224] -> [B, 64, 112, 112]\n",
    "        x = self.bn1(x)    # ì •ê·œí™”\n",
    "        x = self.relu(x)   # ReLU í™œì„±í™”\n",
    "        x = self.maxpool(x)  # [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        x = self.layer1(x)  # [B, 64, 56, 56]\n",
    "        x = self.layer2(x)  # [B, 128, 28, 28]\n",
    "        x = self.layer3(x)  # [B, 256, 14, 14]\n",
    "        x = self.layer4(x)  # [B, 512, 7, 7]\n",
    "\n",
    "        x = self.avgpool(x)  # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # [B, 512]\n",
    "        x = self.fc(x)  # [B, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------- í•™ìŠµ ë£¨í”„ --------------------\n",
    "# -------------------- run í•¨ìˆ˜ --------------------\n",
    "def run():\n",
    "    seed_everything(42)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    train_dataset = CTDataset(train_files, train_labels, transform=train_transform)\n",
    "    val_dataset = CTDataset(val_files, val_labels, transform=val_transform)\n",
    "    test_dataset = CTDataset(test_files, test_labels, transform=val_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.6653, 0.3347], device=device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    best_acc = 0.0  # ê°€ì¥ ë†’ì€ val accuracyë¥¼ ì €ì¥\n",
    "    save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"r18_cbam_mga_aug_lr4_ep100_weight2.pth\")\n",
    "\n",
    "    # í•™ìŠµ ë£¨í”„ ì‹œì‘\n",
    "    for epoch in range(num_epochs):\n",
    "        # MGA ìŠ¤ì¼€ì¥´ë§: ì´ˆê¸° lambda -> ì ì  ì¦ê°€ì‹œí‚´\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "\n",
    "        model.train()  # í•™ìŠµ ëª¨ë“œë¡œ ë³€ê²½\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # í•œ epoch ë™ì•ˆ ëª¨ë“  train ë°ì´í„°ë¥¼ í•™ìŠµ\n",
    "        for images, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)  # forward pass\n",
    "            ce_loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "            # -------------------- MGA Loss ê³„ì‚° ìœ„ì¹˜ --------------------\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # attention map êº¼ë‚´ì˜¤ê¸°\n",
    "\n",
    "            if attn_map is not None:\n",
    "                attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                attn_loss = F.mse_loss(attn_map, masks)  # maskì™€ì˜ MSE loss\n",
    "                loss = ce_loss + lambda_mga * attn_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Acc: {(correct/total)*100:.4f}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] lambda_mga: {lambda_mga:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()  # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "\n",
    "        # -------------------- ê²€ì¦ --------------------\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iamegs, labels, masks in val_loader:\n",
    "                iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "                outputs = model(iamegs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"âœ… Saved best model!\")\n",
    "\n",
    "    # -------------------- í…ŒìŠ¤íŠ¸ --------------------\n",
    "    print(\"\\nğŸ“Š Test Evaluation:\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # numpy ë°°ì—´ë¡œ ë³€í™˜\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    # ì§€í‘œ ê³„ì‚°\n",
    "    from sklearn.metrics import (\n",
    "        classification_report, roc_auc_score, confusion_matrix,\n",
    "        precision_score, recall_score, balanced_accuracy_score,\n",
    "        matthews_corrcoef, f1_score\n",
    "    )\n",
    "\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    # ğŸ“‹ ì¶œë ¥\n",
    "    print(f\"âœ… Test Accuracy         : {acc*100:.2f}%\")\n",
    "    print(f\"ğŸ¯ AUC                   : {auc:.4f}\")\n",
    "    print(f\"ğŸ“Œ Precision             : {precision:.4f}\")\n",
    "    print(f\"ğŸ“Œ Recall (Sensitivity)  : {recall:.4f}\")\n",
    "    print(f\"ğŸ“Œ Specificity           : {specificity:.4f}\")\n",
    "    print(f\"ğŸ“Œ F1 Score              : {f1:.4f}\")\n",
    "    print(f\"ğŸ“Œ Balanced Accuracy     : {balanced_acc:.4f}\")\n",
    "    print(f\"ğŸ“Œ MCC                   : {mcc:.4f}\")\n",
    "    print(\"\\nğŸ“Œ Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # ğŸ“ CSVë¡œ ì €ì¥\n",
    "    test_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"phase\": \"test\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "\n",
    "    csv_path = \"logs/final_test_metrics.csv\"\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=test_metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(test_metrics)\n",
    "\n",
    "    print(f\"\\nğŸ“ í…ŒìŠ¤íŠ¸ ì§€í‘œ ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "\n",
    "# ì§„ì…ì \n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:09<00:00, 25.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 58.0386, Loss: 0.6966\n",
      "[Epoch 1] lambda_mga: 0.1000\n",
      "Val Acc: 0.4375\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:10<00:00, 23.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 61.7631, Loss: 0.6565\n",
      "[Epoch 2] lambda_mga: 0.1040\n",
      "Val Acc: 0.5600\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:11<00:00, 19.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 63.8800, Loss: 0.6432\n",
      "[Epoch 3] lambda_mga: 0.1080\n",
      "Val Acc: 0.6388\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:11<00:00, 19.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 68.5959, Loss: 0.6116\n",
      "[Epoch 4] lambda_mga: 0.1120\n",
      "Val Acc: 0.6913\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 19.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 69.2926, Loss: 0.5956\n",
      "[Epoch 5] lambda_mga: 0.1160\n",
      "Val Acc: 0.6850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 19.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 70.9807, Loss: 0.5735\n",
      "[Epoch 6] lambda_mga: 0.1200\n",
      "Val Acc: 0.6438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 26.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 72.9368, Loss: 0.5483\n",
      "[Epoch 7] lambda_mga: 0.1240\n",
      "Val Acc: 0.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:08<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 75.0804, Loss: 0.5140\n",
      "[Epoch 8] lambda_mga: 0.1280\n",
      "Val Acc: 0.7512\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:11<00:00, 20.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 76.2862, Loss: 0.4979\n",
      "[Epoch 9] lambda_mga: 0.1320\n",
      "Val Acc: 0.7562\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 19.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 78.2958, Loss: 0.4730\n",
      "[Epoch 10] lambda_mga: 0.1360\n",
      "Val Acc: 0.6587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 11]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:11<00:00, 19.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 79.5820, Loss: 0.4584\n",
      "[Epoch 11] lambda_mga: 0.1400\n",
      "Val Acc: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 12]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 19.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 81.6720, Loss: 0.4181\n",
      "[Epoch 12] lambda_mga: 0.1440\n",
      "Val Acc: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 13]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234/234 [00:12<00:00, 19.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 82.5295, Loss: 0.3966\n",
      "[Epoch 13] lambda_mga: 0.1480\n",
      "Val Acc: 0.7600\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 14]:  19%|â–ˆâ–‰        | 44/234 [00:02<00:07, 25.48it/s]"
     ]
    }
   ],
   "source": [
    "# ë² ìŠ¤íŠ¸ ëª¨ë¸ ì‹œë“œ ê³ ì •\n",
    "\n",
    "# ì „ì²´ì½”ë“œ: ResNet18 + CBAM + MGA Loss + Lambda Scheduling (CE Weight ver)\n",
    "\n",
    "import os, re, numpy as np, torch, gc\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "\n",
    "# -------------------- ë””ë°”ì´ìŠ¤ ì„¤ì • --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • --------------------\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# lambda MGA ìŠ¤ì¼€ì¤„ ì„¤ì •\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "total_epochs = num_epochs\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # numpy or tensor ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜\n",
    "    transforms.Resize((224, 224)),  # ì´ë¯¸ì§€ë¥¼ 224x224ë¡œ resize\n",
    "    transforms.RandomHorizontalFlip(),  # ì´ë¯¸ì§€ë¥¼ 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „\n",
    "    transforms.RandomRotation(10),  # ì´ë¯¸ì§€ë¥¼ -10ë„ ~ +10ë„ ì‚¬ì´ë¡œ ëœë¤ íšŒì „, ì´¬ì˜ ìì„¸ë‚˜ ê¸°ìš¸ì–´ì§ì— ëŒ€í•œ íšŒì „ ê°•ê±´ì„±í™•ë³´\n",
    "    transforms.ToTensor(),  # PILì´ë¯¸ì§€ -> PyTorch Tensorë¡œ ë³€í™˜, (H, W, C) -> (C, H, W), ê°’ë„ 0255 -> 01 ì‚¬ì´ì¦ˆë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
    "    transforms.Normalize([0.5], [0.5]), # í‰ê·  0.5, í‘œì¤€í¸ì°¨ 0.5ë¡œ ì •ê·œí™” -> ê²°ê³¼ì ìœ¼ë¡œ 01 -> 11ë¡œ ë°”ë€œ\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
    "])  # ì „ì²´ ì´ë¯¸ì§€ì˜ ì¼ë¶€ë¶„ ì§€ìš°ê³  0ìœ¼ë¡œ ì±„ì›€ (ê²€ì€ ì‚¬ê°í˜• ìƒê¹€)\n",
    "    # p=0.5 : 50% í™•ë¥ ë¡œ ì´ ì¦ê°• ì ìš©\n",
    "    # scale : ì „ì²´ ì´ë¯¸ì§€ ëŒ€ë¹„ ì‚­ì œ ì˜ì—­ì˜ í¬ê¸° ë¹„ìœ¨\n",
    "    # ratio : ì§€ìš°ëŠ” ì‚¬ê°í˜•ì˜ ê°€ë¡œ:ì„¸ë¡œ ë¹„ìœ¨ ë²”ìœ„\n",
    "    # value=0 : ì§€ìš´ ê³³ì„ ê²€ì€ìƒ‰(0)ìœ¼ë¡œ ë®ìŒ\n",
    "    # í CTì—ì„œ ë³‘ë³€ì´ í•­ìƒ ì¼ì •í•œ ìœ„ì¹˜ì— ë‚˜ì˜¤ì§€ ì•Šìœ¼ë‹ˆê¹Œ ëª¨ë¸ì´ íŠ¹ì • ìœ„ì¹˜ì— ê³¼ì í•©ë˜ëŠ”ê±¸ ë°©ì§€í•¨ (overfitting ì˜ˆë°©)\n",
    "\n",
    "# ê²€ì¦/í…ŒìŠ¤íŠ¸ëŠ” ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ê¹¨ê¸‹í•œ ìƒíƒœì˜ ì´ë¯¸ì§€ë¡œ ì •í™•ë„ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ ê²€ì¦ìš©ì€ ê¹”ë”í•˜ê²Œ\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # PIL ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜\n",
    "    transforms.Resize((224, 224)),  # ì‚¬ì´ì¦ˆ ë§ì¶”ê¸°\n",
    "    transforms.ToTensor(),  # PIL ì´ë¯¸ì§€ -> PyTorch Tensorë¡œ ë³€í™˜\n",
    "    transforms.Normalize([0.5], [0.5])  # ì •ê·œí™”\n",
    "])\n",
    "\n",
    "# ì‹œë“œ ê³ ì •\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)                         # íŒŒì´ì¬ random\n",
    "    np.random.seed(seed)                      # numpy\n",
    "    torch.manual_seed(seed)                   # torch CPU\n",
    "    torch.cuda.manual_seed(seed)              # torch GPU\n",
    "    torch.cuda.manual_seed_all(seed)          # multi-GPU\n",
    "    torch.backends.cudnn.deterministic = True # ì—°ì‚° ë™ì¼í•˜ê²Œ\n",
    "    torch.backends.cudnn.benchmark = False    # ì—°ì‚° ì†ë„ ìµœì í™” OFF (ê°™ì€ ì—°ì‚° ë³´ì¥)\n",
    "\n",
    "# -------------------- Bounding Boxë¥¼ Binary Maskë¡œ --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    # bbox_list : í•œ ì´ë¯¸ì§€ì— ë“¤ì–´ìˆëŠ” bounding box ë¦¬ìŠ¤íŠ¸\n",
    "    # image_size : ì¶œë ¥í•  ë§ˆìŠ¤í¬ í¬ê¸°. ë³´í†µ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ (height, width) -> ë””í´íŠ¸ëŠ” 224x224\n",
    "    # bboxë“¤ì„ binary maskë¡œ ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜\n",
    "    masks = []  # ì—¬ëŸ¬ ê°œì˜ bboxê°€ ë“¤ì–´ì˜¤ë‹ˆê¹Œ, ê°ê°ì˜ ë§ˆìŠ¤í¬ë¥¼ í•˜ë‚˜ì”© ë¦¬ìŠ¤íŠ¸ì— ìŒ“ê¸° ìœ„í•œ ë¹ˆ ë¦¬ìŠ¤íŠ¸\n",
    "    for bbox in bbox_list:  # bbox_listë¥¼ í•˜ë‚˜ì”© ëŒë©´ì„œ ì²˜ë¦¬ -> [x_min, y_min, x_max, y_max]ë„¤ ì¢Œí‘œë¡œ êµ¬ì„±ëœ í•˜ë‚˜ì˜ ì‚¬ê°í˜• ì˜ì—­ \n",
    "        mask = np.zeros(image_size, dtype=np.float32)   # 224x224ì§œë¦¬ 0ìœ¼ë¡œ ê½‰ ì°¬ 2D ë°°ì—´ì„ í•˜ë‚˜ ìƒì„±\n",
    "        # ë°°ê²½ì´ í° ì¢…ì´ë¥¼ ë§Œë“œëŠ” ëŠë‚Œìœ¼ë¡œ ë§Œë“¤ê³ , ì‚¬ê° ì˜ì—­ë§Œ 1ë¡œ ë§ì¹ í• ê±°ì„\n",
    "        x_min, y_min, x_max, y_max = bbox   # ê° bboxì˜ ë„¤ ì¢Œí‘œê°’ì„ ê°ê° ë³€ìˆ˜ë¡œ ì–¸íŒ©. -> ë§ˆìŠ¤í¬ì˜ í•´ë‹¹ ì˜ì—­ì— ì‚¬ê°í˜•ì„ ì¹ í•˜ê¸° ìœ„í•´ì„œ\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0    # y_min, y_max, x_min, x_maxê¹Œì§€ì˜ ë²”ìœ„ì— 1.0ì„ ì±„ì›Œ ë„£ìŒ\n",
    "        # -> ë§ˆìŠ¤í¬ì—ì„œ bboxì— í•´ë‹¹í•˜ëŠ” ì‚¬ê°í˜• ì˜ì—­ë§Œ 1(foreground)ë¡œ í‘œì‹œë¨. ë‚˜ë¨¸ì§„ ì—¬ì „íˆ 0(background)\n",
    "        masks.append(mask)  # ì§€ê¸ˆ ë§Œë“  ë§ˆìŠ¤í¬(2D ë°°ì—´)ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ -> [mask1, mask2, ...]ì´ë ‡ê²Œ ìŒ“ì„\n",
    "\n",
    "    masks = np.stack(masks) # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ 3D ë°°ì—´ë¡œ í•©ì¹¨ -> shape : [N, H, W] -> Nì€ bbox ê°œìˆ˜\n",
    "    masks = np.expand_dims(masks, axis=1)   # í…ì„œ shapeì„ [N, 1, H, W]ë¡œ ë°”ê¿ˆ\n",
    "    # PyTorch ëª¨ë¸ì—ì„œ ê¸°ëŒ€í•˜ëŠ” (batch x channel x height x width) í¬ë§· ë§ì¶”ê¸°\n",
    "\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "    # numpy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜í•´ì„œ ë¦¬í„´\n",
    "\n",
    "    # í•œ bbox â†’ í•˜ë‚˜ì˜ ë§ˆìŠ¤í¬ â†’ ì—¬ëŸ¬ ê°œë©´ ìŒ“ì•„ì„œ batch í˜•íƒœë¡œ\n",
    "# -------------------- Bounding Box CSV ë¡œë“œ --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    # csv_path : bounding box ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” CSV íŒŒì¼ ê²½ë¡œ\n",
    "    # ë°˜í™˜ê°’ : {filename:[bbox1, bbox2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬\n",
    "    df = pd.read_csv(csv_path)  # CSVíŒŒì¼ì„ pandas DataFrameìœ¼ë¡œ ì½ì–´ì˜´\n",
    "    bbox_dict = {}\n",
    "    # key : ìŠ¬ë¼ì´ìŠ¤ íŒŒì¼ ì´ë¦„ (ex. \"LIDC-IDRI-1012_slice0004.npy\")\n",
    "    # value : í•´ë‹¹ ìŠ¬ë¼ì´ìŠ¤ì— ì¡´ì¬í•˜ëŠ” bboxë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "    for _, row in df.iterrows():    # DataFrameì˜ ëª¨ë“  í–‰(row)ë¥¼ í•˜ë‚˜ì”© ìˆœíšŒ\n",
    "        # rowëŠ” í•œ ì¤„(=í•œ bbox)ì˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆìŒ\n",
    "\n",
    "        pid = row['pid']    # í™˜ì ID (ì˜ˆ: \"LIDC-IDRI-1012\") -> ì´ë¯¸ì§€ ì´ë¦„ êµ¬ì„± ìš”ì†Œ\n",
    "        slice_str = row['slice']    # ìŠ¬ë¼ì´ìŠ¤ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” ë¬¸ìì—´ (ì˜ˆ: \"slice_0039\")\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])  # re.findall()ë¡œ ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ë½‘ì•„ëƒ„\n",
    "        # \"slice_0039\" -> ['0039'] -> [0] -> 39 (ìŠ¬ë¼ì´ìŠ¤ ë²ˆí˜¸ë¥¼ ì •ìˆ˜ë¡œ ì¶”ì¶œí•¨)\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"   # íŒŒì¼ëª… êµ¬ì„± (ì˜ˆ: \"LIDC-IDRI-1012_slice0039.npy\")\n",
    "        # {:04d}ëŠ” 4ìë¦¬ ì •ìˆ˜ë¡œ ë§Œë“¤ê³  ë¹ˆìë¦¬ëŠ” 0ìœ¼ë¡œ ì±„ì›Œì¤Œ (39 -> 0039)\n",
    "        bbox = eval(row['bb'])  # row['bb']ëŠ” ë¬¸ìì—´ í˜•íƒœì˜ bbox (ì˜ˆ: \"[20, 30, 80, 100]\")\n",
    "        # eval()ì„ ì¨ì„œ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ê¿”ì¤Œ\n",
    "        # ì£¼ì˜ : ë³´ì•ˆ ìƒ ìœ„í—˜í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ì§€ë§Œ, ì—¬ê¸´ ë‚´ë¶€ ë°ì´í„°ë¼ ì‚¬ìš©ì¤‘\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)    # fnameì´ë¼ëŠ” keyê°€ ë”•ì…”ë„ˆë¦¬ì— ì—†ìœ¼ë©´ []ë¡œ ì´ˆê¸°í™”í•˜ê³ ,\n",
    "        # ê±°ê¸°ì— bboxë¥¼ append -> ìŠ¬ë¼ì´ìŠ¤ í•˜ë‚˜ì— bbox ì—¬ëŸ¬ê°œ ìˆì–´ë„ ì „ë¶€ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ì•„ì¤Œ\n",
    "    return bbox_dict    # ìµœì¢…ì ìœ¼ë¡œ {filename: [bbox1, bbox2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "# ì‹¤ì œë¡œ csv_pathì— ìˆëŠ” ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™€ì„œ bbox_dictì— ì €ì¥í•¨\n",
    "# ì´ê±¸ ë‚˜ì£¼ì— Dataset í´ë˜ìŠ¤ì—ì„œ fname ê¸°ì¤€ì„ êº¼ë‚´ì“°ê²Œ ë¨\n",
    "\n",
    "# -------------------- ë¼ë²¨ ì¶”ì¶œ --------------------\n",
    "def extract_label_from_filename(fname): # fname : íŒŒì¼ ì´ë¦„ (ì˜ˆ: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # ì´ ì´ë¦„ì—ì„œ malignancy score(ì•…ì„±ë„ ì ìˆ˜)ë¥¼ ì¶”ì¶œí•´ì„œ ë¼ë²¨ë¡œ ë³€í™˜\n",
    "    try:    # íŒŒì¼ëª…ì´ ì´ìƒí•˜ê±°ë‚˜ ì—ëŸ¬ë‚˜ë©´ exceptë¡œ ë¹ ì ¸ë‚˜ê°€ì„œ None ë°˜í™˜í•¨ (ì•ˆì „ì¥ì¹˜)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # íŒŒì¼ëª…ì—ì„œ _ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ê²ƒë“¤ ì¤‘ì— ë§ˆì§€ë§‰ì—êº¼ë¥¼ ê°€ì ¸ì™€ì„œ .npyë¥¼ \"\" ì´ë ‡ê²Œ ê³µë°±ìœ¼ë¡œ ì²˜ë¦¬í•¨\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- ì´ê²Œ malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # ë¼ë²¨ ê²°ì • ë¡œì§ìœ¼ë¡œ\n",
    "        # score == 3 -> ì¤‘ë¦½ -> None ë°˜í™˜ -> í•™ìŠµì—ì„œ ì œì™¸\n",
    "        # score >= 4 -> ì•”(ì–‘ì„±) -> 1\n",
    "        # score <= 2 -> ì •ìƒ(ìŒì„±) -> 0\n",
    "        # int(score >= 4)ëŠ” íŒŒì´ì¬ì—ì„œ True -> 1\n",
    "        # False -> 0 ì´ë‹ˆê¹ ìë™ìœ¼ë¡œ ë¼ë²¨ì´ ë¨\n",
    "    except:\n",
    "        return None\n",
    "        # í˜¹ì‹œ splitì´ë‚˜ replace, int ë³€í™˜ì´ ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ None ë°˜í™˜í•˜ê³  ë¬´ì‹œ\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    # PyTorchì˜ Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†í•´ì„œ ì»¤ã…¡í…€ ë°ì´í„°ì…‹ ì •ì˜\n",
    "    # ë‚˜ì¤‘ì— DataLoaderë‘ ê°™ì´ ì“°ì´ê¸° ë•Œë¬¸ì— __len__()ì´ë‘ __getitem__()ì„ ê¼­ ë„£ì–´ì¤˜ì•¼í•¨\n",
    "    def __init__(self, paths, labels, transform=None):  # ìƒì„±ì : ì„¸ê°œì˜ ì¸ìë¥¼ ë°›ìŒ\n",
    "        # paths : ì´ë¯¸ì§€ .npy íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "        # labels : ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ (0, 1 or None)\n",
    "        # transform : ì´ë¯¸ì§€ ì¦ê°• ì„¤ì • (train_transform, val_transform ë“±)\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # ë°›ì€ ì¸ìë¥¼ ë©¤ë²„ ë³€ìˆ˜ë¡œ ì €ì¥. ë‚˜ì¤‘ì— gettem()ì—ì„œ ì ‘ê·¼í•¨\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoaderê°€ ì´ê±¸ í˜¸ì¶œí•  ë•Œ indexì— í•´ë‹¹í•˜ëŠ” sample í•˜ë‚˜ë¥¼ ë°˜í™˜\n",
    "        # ì´ë¯¸ì§€, ë¼ë²¨, ë§ˆìŠ¤í¬( = MGAìš© target) 3ê°œë¥¼ ë¦¬í„´í•¨\n",
    "        file_path = self.paths[idx] # íŒŒì¼ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        label = self.labels[idx]    # ë¼ë²¨ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        fname = os.path.basename(file_path) # ì „ì²´ ê²½ë¡œì—ì„œ íŒŒì¼ ì´ë¦„ë§Œ ì¶”ì¶œ -> ë‚˜ì¤‘ì— bbox_dict[fname] ì°¾ì„ë•Œ ì“°ì„\n",
    "\n",
    "        img = np.load(file_path)    # .npy íŒŒì¼ì—ì„œ CT ìŠ¬ë¼ì´ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° -> í‘ë°± CT ì´ë¯¸ì§€, shapeì€ (H, W)\n",
    "        img = np.clip(img, -1000, 400)  # CT ì´ë¯¸ì§€ HU ê°’ì´ ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´ ë…¸ì´ì¦ˆ -> -1000(ê³µê¸°) ~ 400(ì—°ì¡°ì§)ìœ¼ë¡œ í´ë¦¬í•‘í•´ì„œ ë…¸ì´ì¦ˆ ì œê±°\n",
    "        img = (img + 1000) / 1400.  # ì •ê·œí™” : -1000 -> 0, 400 -> 1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë°”ê¿”ì¤Œ -> ëª¨ë¸ì´ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•¨\n",
    "        img = np.expand_dims(img, axis=-1)  # CTëŠ” ì±„ë„ì´ 1ê°œë‹ˆê¹ (H, W) -> (H, w, 1)ë¡œ ë°”ê¿”ì¤Œ\n",
    "        # ë‚˜ì¤‘ì— PyTorchì—ì„œ (C, H, W)ë¡œ ë°”ê¾¸ê¸° ìœ„í•¨\n",
    "\n",
    "        if self.transform:  # ë°ì´í„° ì¦ê°•(transform)ì´ ìˆë‹¤ë©´ ì ìš©\n",
    "            img = self.transform(img)   \n",
    "        else:   # ì—†ìœ¼ë©´ numpy -> tensor ë³€í™˜í•˜ê³  (H, W, C) -> (C, H, W)ë¡œ ìˆœì„œ ë°”ê¿ˆ\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "\n",
    "        if fname in bbox_dict:  # ì´ ì´ë¯¸ì§€ì— bboxê°€ ì¡´ì¬í•˜ë©´ -> ë§ˆìŠ¤í¬ ìƒì„±\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(224, 224))\n",
    "            # image_sizeëŠ” transformê³¼ ë™ì¼í•˜ê²Œ 224x224\n",
    "        else:   # bboxê°€ ì—†ë‹¤ë©´ ì „ë¶€ 0ìœ¼ë¡œ ì±„ì›Œì§„ ë§ˆìŠ¤í¬ ìƒì„± -> MGA Loss ê³„ì‚° ì‹œ ì°¸ê³ ìš©ìœ¼ë¡œ ì“°ì¼ ìˆ˜ ìˆìŒ\n",
    "            mask = torch.zeros((1, 224, 224), dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask.squeeze(0)\n",
    "        # ë°˜í™˜ê°’ 3ê°œ :\n",
    "        # img : shape[1, 224, 224]\n",
    "        # label : int(0 or 1)\n",
    "        # mask : [224, 224] <- squeezeë¡œ ì±„ë„ 1ê°œ ì œê±°\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    # ì „ì²´ ë°ì´í„°ì…‹ ê¸¸ì´ ë°˜í™˜ -> DataLoaderê°€ ì•„ë¼ì•¼ ë°°ì¹˜ ìª¼ê°¤ ìˆ˜ ìˆìŒ.\n",
    "\n",
    "# -------------------- CBAM ì •ì˜ (MGA í¬í•¨) --------------------\n",
    "# 2 Step : Channel Attention(ì–´ë–¤ ì±„ë„ì— ì§‘ì¤‘í• ì§€) * Spatial Attention(ì–´ë””ì— ì§‘ì¤‘í• ì§€) = ìµœì¢… Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # ì…ë ¥ feature mapì˜ ì±„ë„ë³„ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•´ì„œ ê°•ì¡°í•¨\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : ì…ë ¥ ì±„ë„ ìˆ˜\n",
    "        # ratio : ì¤‘ê°„ ì±„ë„ ì¶•ì†Œ ë¹„ìœ¨. ê¸°ë³¸ 1/16ìœ¼ë¡œ bottlenck êµ¬ì„±\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP ì—­í• ì„ í•˜ëŠ” 1x1 conv ë¸”ë¡ -> ì±„ë„ ì••ì¶• -> ë¹„ì„ í˜• -> ë³µì› (sharedëŠ” avg/max ë‘˜ë‹¤ì—ì„œ ê°™ì´ ì”€)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # í‰ê·  í’€ë§ / ìµœëŒ€ í’€ë§ìœ¼ë¡œ ë‘ê°€ì§€ ì „ì—­ ì •ë³´ë¥¼ ì¶”ì¶œ\n",
    "        # ë§ˆì§€ë§‰ sigmoidëŠ” attention weightë¡œ ìŠ¤ì¼€ì¼ë§\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max í’€ë§ ê²½ê³¼ë¥¼ ê°ê° shape MLPì— í†µê³¼ì‹œí‚¤ê³ , ë”í•œ í›„ sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> ì±„ë„ë§ˆë‹¤ ì¤‘ìš”ë„ weightë¥¼ ê³±í•˜ê²Œ ë¨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # ê³µê°„ì ìœ¼ë¡œ ì–´ë””ì— ì§‘ì¤‘í• ì§€ë¥¼ ê²°ì • -> ê° ì±„ë„ ë‚´ë¶€ì—ì„œ ì¤‘ìš”í•œ ìœ„ì¹˜ ì°¾ê¸°\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # ì±„ë„ ì°¨ì›ì€ í‰ê· , ìµœëŒ€ ë‘ ê°œë§Œ ì¨ì„œ concat\n",
    "    # ê·¸ê±¸ 1ì±„ë„ë¡œ ì¤„ì—¬ì£¼ëŠ” conv\n",
    "    # ì»¤ë„ í¬ê¸° k=7ì´ë©´ ë„“ì€ ì˜ì—­ê¹Œì§€ ê°ì§€ ê°€ëŠ¥\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # ì…ë ¥ feature mapì—ì„œ :\n",
    "    # í‰ê· , ìµœëŒ€ê°’ì„ ê° spatial ìœ„ì¹˜ë³„ë¡œ êµ¬í•¨ -> [B, 1, H, W] ë‘ ê°œ\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> ìœ„ì¹˜ë³„ ì¤‘ìš”ë„ map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttentionì„ ë‚´ë¶€ì— ì„ ì–¸\n",
    "    # MGAë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ attention mapì„ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ í¬í•¨\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # ì±„ë„ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ìœ„ì¹˜ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ë‘˜ ë‹¤ ë°˜ì˜ëœ ìµœì¢… feature map ë¦¬í„´\n",
    "\n",
    "# -------------------- ResNet18 + CBAM ëª¨ë¸ ì •ì˜ --------------------\n",
    "# BasicBlockCBAM : ResNetì˜ ê¸°ë³¸ Residual Block í•˜ë‚˜ë¥¼ ì •ì˜\n",
    "# â†’ conv â†’ BN â†’ ReLU â†’ conv â†’ BN â†’ (CBAM optional) â†’ Add â†’ ReLU\n",
    "\n",
    "# ResNet18_CBAM : ResNet18 êµ¬ì¡°ë¡œ ì „ì²´ ë„¤íŠ¸ì›Œí¬ ìŒ“ê¸°\n",
    "# â†’ conv1 â†’ layer1~3 â†’ layer4 â†’ avgpool â†’ fc\n",
    "\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        # ì…ë ¥ ì±„ë„: in_planes, ì¶œë ¥ ì±„ë„: out_planes, 3x3 ì»¤ë„, padding=1ë¡œ í¬ê¸° ìœ ì§€, strideë¡œ í¬ê¸° ì¡°ì ˆ\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)   # ë°°ì¹˜ ì •ê·œí™”\n",
    "        self.relu = nn.ReLU()   # ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        # ë‘ë²ˆì§¸ conv, ì±„ë„ ìˆ˜ ìœ ì§€, í¬ê¸° ìœ ì§€\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)   # ë°°ì¹˜ ì •ê·œí™”\n",
    "\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None  # CBAM ëª¨ë“ˆ ì‚¬ìš© ì—¬ë¶€\n",
    "        self.downsample = downsample    # residual ì—°ê²° ì‹œ ì°¨ì› ë§ì¶”ëŠ” conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # skip connectionìš© ì…ë ¥ ì €ì¥\n",
    "\n",
    "        out = self.conv1(x) # ì²« ë²ˆì§¸ conv\n",
    "        out = self.bn1(out) # ì •ê·œí™”\n",
    "        out = self.relu(out)  # í™œì„±í™”\n",
    "\n",
    "        out = self.conv2(out)   # ë‘ ë²ˆì§¸ conv\n",
    "        out = self.bn2(out) # ì •ê·œí™”\n",
    "\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)    # CBAM ì ìš©\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)   # shortcut ê²½ë¡œ ë³´ì •\n",
    "\n",
    "        out += residual # skip connection\n",
    "        out = self.relu(out)    # ì¶œë ¥ì— ReLU ì ìš©\n",
    "\n",
    "        return out  # ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64 # ì¡°ê¸° ì…ë ¥ ì±„ë„ ìˆ˜ ì„¤ì •\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # ì…ë ¥: [B, 1, 224, 224] -> ì¶œë ¥: [B, 64, 112, 112], í° ì»¤ë„ë¡œ ë„“ì€ ì˜ì—­ ìº¡ì²˜ \n",
    "        self.bn1 = nn.BatchNorm2d(64)   # ì •ê·œí™”\n",
    "        self.relu = nn.ReLU()   # í™œì„±í™”\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # í’€ë§: [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        self.layer1 = self._make_layer(64, blocks=2)  # [B, 64, 56, 56] ìœ ì§€\n",
    "        self.layer2 = self._make_layer(128, blocks=2, stride=2)  # [B, 128, 28, 28] ë‹¤ìš´ìƒ˜í”Œë§\n",
    "        self.layer3 = self._make_layer(256, blocks=2, stride=2)  # [B, 256, 14, 14] ë‹¤ìš´ìƒ˜í”Œë§\n",
    "        self.layer4 = self._make_layer(512, blocks=2, stride=2, use_cbam=False)  # [B, 512, 7, 7], CBAM ë¯¸ì‚¬ìš©\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # [B, 512, 7, 7] -> [B, 512, 1, 1]\n",
    "        self.fc = nn.Linear(512, num_classes)  # [B, 512] -> [B, num_classes]\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        # Planes : í•´ë‹¹ ë ˆì´ì–´ì˜ ì¶œë ¥ ì±„ë„ ìˆ˜\n",
    "        # # blocks : ë¸”ë¡ ìˆ˜\n",
    "        # stride=2ì¸ ê²½ìš° ë‹¤ìš´ìƒ˜í”Œë§ (í•´ìƒë„ ì ˆë°˜)\n",
    "\n",
    "        downsample = None   # ìŠ¤í‚µ ì—°ê²°í•´ì„œ ì…ë ¥/ì¶œë ¥ í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ë§ì¶°ì•¼ í•¨\n",
    "\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                # 1x1 convë¡œ ì±„ë„ ìˆ˜   ë° ê³µê°„ í¬ê¸° ë§ì¶¤\n",
    "                nn.BatchNorm2d(planes))\n",
    "            \n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam=use_cbam)]\n",
    "        # ì²« ë¸”ë¡ì€ ë‹¤ìš´ìƒ˜í”Œë§ ì ìš© ê°€ëŠ¥ì„± ìˆìŒ\n",
    "        self.in_planes = planes # ì´í›„ ë¸”ë¡ì„ ìœ„í•œ ì…ë ¥ ì±„ë„ ì—…ë°ì´íŠ¸\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "            # ë‚˜ë¨¸ì§€ ë¸”ë¡ì€ stride=1ë¡œ ë™ì¼í•œ í•´ìƒë„ ìœ ì§€\n",
    "\n",
    "        return nn.Sequential(*layers)   # ë¸”ë¡ë“¤ì„ Seguentialë¡œ ë¬¶ì–´ ë°˜í™˜\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # ì…ë ¥: [B, 1, 224, 224] -> [B, 64, 112, 112]\n",
    "        x = self.bn1(x)    # ì •ê·œí™”\n",
    "        x = self.relu(x)   # ReLU í™œì„±í™”\n",
    "        x = self.maxpool(x)  # [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        x = self.layer1(x)  # [B, 64, 56, 56]\n",
    "        x = self.layer2(x)  # [B, 128, 28, 28]\n",
    "        x = self.layer3(x)  # [B, 256, 14, 14]\n",
    "        x = self.layer4(x)  # [B, 512, 7, 7]\n",
    "\n",
    "        x = self.avgpool(x)  # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # [B, 512]\n",
    "        x = self.fc(x)  # [B, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------- í•™ìŠµ ë£¨í”„ --------------------\n",
    "def run():\n",
    "    seed_everything(42)\n",
    "    # ëª¨ë“  CT ìŠ¬ë¼ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸° (LIDC-IDRI í™˜ì í´ë” ì•ˆì˜ .npy íŒŒì¼ë“¤)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "\n",
    "    # íŒŒì¼ ê²½ë¡œì™€ í•´ë‹¹ íŒŒì¼ì˜ ë¼ë²¨ì„ íŠœí”Œë¡œ ì €ì¥\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    # ë¼ë²¨ì´ Noneì´ ì•„ë‹Œ ë°ì´í„°ë§Œ í•„í„°ë§ (ì¤‘ë¦½ ì œì™¸)\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "\n",
    "    # íŒŒì¼, ë¼ë²¨ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„°ë¥¼ train(70%), val(15%), test(15%)ë¡œ ë¶„í• \n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(\n",
    "    files, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(\n",
    "    temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    train_dataset = CTDataset(train_files, train_labels, transform=train_transform)\n",
    "    val_dataset = CTDataset(val_files, val_labels, transform=val_transform)\n",
    "    test_dataset = CTDataset(test_files, test_labels, transform=val_transform)\n",
    "\n",
    "    # ë°ì´í„° ë¡œë”\n",
    "    train_loader = DataLoader(train_dataset,  batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.6653, 0.3347], device=device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    best_acc = 0.0  # ê°€ì¥ ë†’ì€ val accuracyë¥¼ ì €ì¥\n",
    "    save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"r18_cbam_mga_aug_lr4_ep100_weight_seedfix.pth\")\n",
    "\n",
    "    # í•™ìŠµ ë£¨í”„ ì‹œì‘\n",
    "    for epoch in range(num_epochs):\n",
    "        # MGA ìŠ¤ì¼€ì¥´ë§: ì´ˆê¸° lambda -> ì ì  ì¦ê°€ì‹œí‚´\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "\n",
    "        model.train()  # í•™ìŠµ ëª¨ë“œë¡œ ë³€ê²½\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # í•œ epoch ë™ì•ˆ ëª¨ë“  train ë°ì´í„°ë¥¼ í•™ìŠµ\n",
    "        for images, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)  # forward pass\n",
    "            ce_loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "            # -------------------- MGA Loss ê³„ì‚° ìœ„ì¹˜ --------------------\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # attention map êº¼ë‚´ì˜¤ê¸°\n",
    "\n",
    "            if attn_map is not None:\n",
    "                attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                attn_loss = F.mse_loss(attn_map, masks)  # maskì™€ì˜ MSE loss\n",
    "                loss = ce_loss + lambda_mga * attn_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Acc: {(correct/total)*100:.4f}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] lambda_mga: {lambda_mga:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()  # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "\n",
    "        # -------------------- ê²€ì¦ --------------------\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iamegs, labels, masks in val_loader:\n",
    "                iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "                outputs = model(iamegs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"âœ… Saved best model!\")\n",
    "\n",
    "    # -------------------- í…ŒìŠ¤íŠ¸ --------------------\n",
    "    print(\"\\nğŸ“Š Test Evaluation:\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # numpy ë°°ì—´ë¡œ ë³€í™˜\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    # ì§€í‘œ ê³„ì‚°\n",
    "    from sklearn.metrics import (\n",
    "        classification_report, roc_auc_score, confusion_matrix,\n",
    "        precision_score, recall_score, balanced_accuracy_score,\n",
    "        matthews_corrcoef, f1_score\n",
    "    )\n",
    "\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    # ğŸ“‹ ì¶œë ¥\n",
    "    print(f\"âœ… Test Accuracy         : {acc*100:.2f}%\")\n",
    "    print(f\"ğŸ¯ AUC                   : {auc:.4f}\")\n",
    "    print(f\"ğŸ“Œ Precision             : {precision:.4f}\")\n",
    "    print(f\"ğŸ“Œ Recall (Sensitivity)  : {recall:.4f}\")\n",
    "    print(f\"ğŸ“Œ Specificity           : {specificity:.4f}\")\n",
    "    print(f\"ğŸ“Œ F1 Score              : {f1:.4f}\")\n",
    "    print(f\"ğŸ“Œ Balanced Accuracy     : {balanced_acc:.4f}\")\n",
    "    print(f\"ğŸ“Œ MCC                   : {mcc:.4f}\")\n",
    "    print(\"\\nğŸ“Œ Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # ğŸ“ CSVë¡œ ì €ì¥\n",
    "    test_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"phase\": \"test\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "\n",
    "    csv_path = \"logs/final_test_metrics.csv\"\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=test_metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(test_metrics)\n",
    "\n",
    "    print(f\"\\nğŸ“ í…ŒìŠ¤íŠ¸ ì§€í‘œ ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "\n",
    "# ì§„ì…ì \n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 59.5391, Loss: 0.7025\n",
      "[Epoch 1] lambda_mga: 0.1000\n",
      "Val Acc: 0.6112\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 2]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 61.5488, Loss: 0.6686\n",
      "[Epoch 2] lambda_mga: 0.1040\n",
      "Val Acc: 0.6850\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]:  21%|â–ˆâ–ˆ        | 97/467 [00:03<00:12, 29.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 3]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 64.6302, Loss: 0.6406\n",
      "[Epoch 3] lambda_mga: 0.1080\n",
      "Val Acc: 0.5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 4]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 67.0954, Loss: 0.6272\n",
      "[Epoch 4] lambda_mga: 0.1120\n",
      "Val Acc: 0.7300\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 5]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 35.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 66.9882, Loss: 0.6162\n",
      "[Epoch 5] lambda_mga: 0.1160\n",
      "Val Acc: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 6]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 70.0965, Loss: 0.5933\n",
      "[Epoch 6] lambda_mga: 0.1200\n",
      "Val Acc: 0.7125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 7]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 71.1415, Loss: 0.5739\n",
      "[Epoch 7] lambda_mga: 0.1240\n",
      "Val Acc: 0.6800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 8]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 73.1243, Loss: 0.5526\n",
      "[Epoch 8] lambda_mga: 0.1280\n",
      "Val Acc: 0.7288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 9]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 75.5091, Loss: 0.5167\n",
      "[Epoch 9] lambda_mga: 0.1320\n",
      "Val Acc: 0.7063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 10]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 75.1876, Loss: 0.5112\n",
      "[Epoch 10] lambda_mga: 0.1360\n",
      "Val Acc: 0.7388\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 11]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 37.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 77.8403, Loss: 0.4868\n",
      "[Epoch 11] lambda_mga: 0.1400\n",
      "Val Acc: 0.7450\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 12]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 80.1179, Loss: 0.4569\n",
      "[Epoch 12] lambda_mga: 0.1440\n",
      "Val Acc: 0.6675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 13]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 79.4212, Loss: 0.4462\n",
      "[Epoch 13] lambda_mga: 0.1480\n",
      "Val Acc: 0.7612\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 14]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 81.5380, Loss: 0.4130\n",
      "[Epoch 14] lambda_mga: 0.1520\n",
      "Val Acc: 0.7975\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 15]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:16<00:00, 28.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 82.2079, Loss: 0.4060\n",
      "[Epoch 15] lambda_mga: 0.1560\n",
      "Val Acc: 0.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 16]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 84.4587, Loss: 0.3728\n",
      "[Epoch 16] lambda_mga: 0.1600\n",
      "Val Acc: 0.8000\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 17]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 39.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 84.9678, Loss: 0.3623\n",
      "[Epoch 17] lambda_mga: 0.1640\n",
      "Val Acc: 0.8175\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 18]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:10<00:00, 42.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 85.6913, Loss: 0.3337\n",
      "[Epoch 18] lambda_mga: 0.1680\n",
      "Val Acc: 0.8175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 19]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 41.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 86.7899, Loss: 0.3204\n",
      "[Epoch 19] lambda_mga: 0.1720\n",
      "Val Acc: 0.8187\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 20]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 42.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 87.4062, Loss: 0.3087\n",
      "[Epoch 20] lambda_mga: 0.1760\n",
      "Val Acc: 0.8150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 21]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 42.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 87.4598, Loss: 0.3059\n",
      "[Epoch 21] lambda_mga: 0.1800\n",
      "Val Acc: 0.8075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 22]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:10<00:00, 42.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 88.8264, Loss: 0.2772\n",
      "[Epoch 22] lambda_mga: 0.1840\n",
      "Val Acc: 0.8438\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 23]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:09<00:00, 48.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 88.9871, Loss: 0.2755\n",
      "[Epoch 23] lambda_mga: 0.1880\n",
      "Val Acc: 0.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 24]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:10<00:00, 46.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 90.1661, Loss: 0.2538\n",
      "[Epoch 24] lambda_mga: 0.1920\n",
      "Val Acc: 0.8413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 25]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 33.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 90.1929, Loss: 0.2444\n",
      "[Epoch 25] lambda_mga: 0.1960\n",
      "Val Acc: 0.8600\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 26]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 32.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.3451, Loss: 0.2288\n",
      "[Epoch 26] lambda_mga: 0.2000\n",
      "Val Acc: 0.7887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 27]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.4523, Loss: 0.2264\n",
      "[Epoch 27] lambda_mga: 0.2040\n",
      "Val Acc: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 28]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.0150, Loss: 0.2190\n",
      "[Epoch 28] lambda_mga: 0.2080\n",
      "Val Acc: 0.8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 29]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 37.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 91.9346, Loss: 0.2188\n",
      "[Epoch 29] lambda_mga: 0.2120\n",
      "Val Acc: 0.8163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 30]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.6313, Loss: 0.2034\n",
      "[Epoch 30] lambda_mga: 0.2160\n",
      "Val Acc: 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 31]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 31.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.7117, Loss: 0.1908\n",
      "[Epoch 31] lambda_mga: 0.2200\n",
      "Val Acc: 0.8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 32]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.4169, Loss: 0.1969\n",
      "[Epoch 32] lambda_mga: 0.2240\n",
      "Val Acc: 0.8425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 33]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 92.3365, Loss: 0.1936\n",
      "[Epoch 33] lambda_mga: 0.2280\n",
      "Val Acc: 0.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 34]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 37.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.0514, Loss: 0.1696\n",
      "[Epoch 34] lambda_mga: 0.2320\n",
      "Val Acc: 0.8575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 35]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 39.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.8907, Loss: 0.1695\n",
      "[Epoch 35] lambda_mga: 0.2360\n",
      "Val Acc: 0.8538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 36]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.3548, Loss: 0.1728\n",
      "[Epoch 36] lambda_mga: 0.2400\n",
      "Val Acc: 0.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 37]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.8103, Loss: 0.1754\n",
      "[Epoch 37] lambda_mga: 0.2440\n",
      "Val Acc: 0.8650\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 38]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 93.6495, Loss: 0.1636\n",
      "[Epoch 38] lambda_mga: 0.2480\n",
      "Val Acc: 0.8400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 39]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.6677, Loss: 0.1429\n",
      "[Epoch 39] lambda_mga: 0.2520\n",
      "Val Acc: 0.8812\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 40]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 38.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.4266, Loss: 0.1472\n",
      "[Epoch 40] lambda_mga: 0.2560\n",
      "Val Acc: 0.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 41]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.5606, Loss: 0.1499\n",
      "[Epoch 41] lambda_mga: 0.2600\n",
      "Val Acc: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 42]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.8821, Loss: 0.1390\n",
      "[Epoch 42] lambda_mga: 0.2640\n",
      "Val Acc: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 43]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.3194, Loss: 0.1600\n",
      "[Epoch 43] lambda_mga: 0.2680\n",
      "Val Acc: 0.8425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 44]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 32.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.9893, Loss: 0.1437\n",
      "[Epoch 44] lambda_mga: 0.2720\n",
      "Val Acc: 0.8738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 45]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 37.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.7213, Loss: 0.1396\n",
      "[Epoch 45] lambda_mga: 0.2760\n",
      "Val Acc: 0.8525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 46]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.0429, Loss: 0.1374\n",
      "[Epoch 46] lambda_mga: 0.2800\n",
      "Val Acc: 0.8725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 47]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 32.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 94.7749, Loss: 0.1450\n",
      "[Epoch 47] lambda_mga: 0.2840\n",
      "Val Acc: 0.8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 48]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0343, Loss: 0.1147\n",
      "[Epoch 48] lambda_mga: 0.2880\n",
      "Val Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 49]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.1233, Loss: 0.1282\n",
      "[Epoch 49] lambda_mga: 0.2920\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 50]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 38.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0879, Loss: 0.1168\n",
      "[Epoch 50] lambda_mga: 0.2960\n",
      "Val Acc: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 51]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 33.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.4716, Loss: 0.1240\n",
      "[Epoch 51] lambda_mga: 0.3000\n",
      "Val Acc: 0.8612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 52]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.3376, Loss: 0.1267\n",
      "[Epoch 52] lambda_mga: 0.3040\n",
      "Val Acc: 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 53]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.6592, Loss: 0.1202\n",
      "[Epoch 53] lambda_mga: 0.3080\n",
      "Val Acc: 0.8925\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 54]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 95.9539, Loss: 0.1161\n",
      "[Epoch 54] lambda_mga: 0.3120\n",
      "Val Acc: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 55]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 37.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0611, Loss: 0.1120\n",
      "[Epoch 55] lambda_mga: 0.3160\n",
      "Val Acc: 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 56]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 35.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.3558, Loss: 0.1092\n",
      "[Epoch 56] lambda_mga: 0.3200\n",
      "Val Acc: 0.8838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 57]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 32.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.1951, Loss: 0.1038\n",
      "[Epoch 57] lambda_mga: 0.3240\n",
      "Val Acc: 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 58]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 36.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.5702, Loss: 0.0962\n",
      "[Epoch 58] lambda_mga: 0.3280\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 59]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.0611, Loss: 0.1142\n",
      "[Epoch 59] lambda_mga: 0.3320\n",
      "Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 60]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 33.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7042, Loss: 0.0969\n",
      "[Epoch 60] lambda_mga: 0.3360\n",
      "Val Acc: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 61]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 39.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.7042, Loss: 0.0970\n",
      "[Epoch 61] lambda_mga: 0.3400\n",
      "Val Acc: 0.8938\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 62]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.8114, Loss: 0.0932\n",
      "[Epoch 62] lambda_mga: 0.3440\n",
      "Val Acc: 0.8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 63]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.6506, Loss: 0.0988\n",
      "[Epoch 63] lambda_mga: 0.3480\n",
      "Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 64]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.6506, Loss: 0.0936\n",
      "[Epoch 64] lambda_mga: 0.3520\n",
      "Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 65]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 32.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.1329, Loss: 0.0823\n",
      "[Epoch 65] lambda_mga: 0.3560\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 66]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 38.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.8382, Loss: 0.0973\n",
      "[Epoch 66] lambda_mga: 0.3600\n",
      "Val Acc: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 67]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.4898, Loss: 0.0929\n",
      "[Epoch 67] lambda_mga: 0.3640\n",
      "Val Acc: 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 68]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.8114, Loss: 0.0841\n",
      "[Epoch 68] lambda_mga: 0.3680\n",
      "Val Acc: 0.8675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 69]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 32.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.8382, Loss: 0.0935\n",
      "[Epoch 69] lambda_mga: 0.3720\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 70]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9185, Loss: 0.0912\n",
      "[Epoch 70] lambda_mga: 0.3760\n",
      "Val Acc: 0.8625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 71]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9453, Loss: 0.0882\n",
      "[Epoch 71] lambda_mga: 0.3800\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 72]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 38.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.5434, Loss: 0.0996\n",
      "[Epoch 72] lambda_mga: 0.3840\n",
      "Val Acc: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 73]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.2669, Loss: 0.0798\n",
      "[Epoch 73] lambda_mga: 0.3880\n",
      "Val Acc: 0.8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 74]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4277, Loss: 0.0790\n",
      "[Epoch 74] lambda_mga: 0.3920\n",
      "Val Acc: 0.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 75]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6152, Loss: 0.0778\n",
      "[Epoch 75] lambda_mga: 0.3960\n",
      "Val Acc: 0.8712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 76]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.8650, Loss: 0.0825\n",
      "[Epoch 76] lambda_mga: 0.4000\n",
      "Val Acc: 0.8475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 77]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:12<00:00, 37.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.6506, Loss: 0.0920\n",
      "[Epoch 77] lambda_mga: 0.4040\n",
      "Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 78]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6956, Loss: 0.0643\n",
      "[Epoch 78] lambda_mga: 0.4080\n",
      "Val Acc: 0.8113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 79]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6420, Loss: 0.0706\n",
      "[Epoch 79] lambda_mga: 0.4120\n",
      "Val Acc: 0.8938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 80]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 32.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4277, Loss: 0.0696\n",
      "[Epoch 80] lambda_mga: 0.4160\n",
      "Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 81]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 33.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4009, Loss: 0.0731\n",
      "[Epoch 81] lambda_mga: 0.4200\n",
      "Val Acc: 0.8938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 82]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 40.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6152, Loss: 0.0712\n",
      "[Epoch 82] lambda_mga: 0.4240\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 83]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 33.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4009, Loss: 0.0741\n",
      "[Epoch 83] lambda_mga: 0.4280\n",
      "Val Acc: 0.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 84]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.1061, Loss: 0.0803\n",
      "[Epoch 84] lambda_mga: 0.4320\n",
      "Val Acc: 0.8725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 85]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.2401, Loss: 0.0794\n",
      "[Epoch 85] lambda_mga: 0.4360\n",
      "Val Acc: 0.8775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 86]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:13<00:00, 34.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6152, Loss: 0.0731\n",
      "[Epoch 86] lambda_mga: 0.4400\n",
      "Val Acc: 0.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 87]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 40.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.3473, Loss: 0.0760\n",
      "[Epoch 87] lambda_mga: 0.4440\n",
      "Val Acc: 0.8762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 88]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 96.9453, Loss: 0.0814\n",
      "[Epoch 88] lambda_mga: 0.4480\n",
      "Val Acc: 0.8962\n",
      "âœ… Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 89]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 31.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.2315, Loss: 0.0525\n",
      "[Epoch 89] lambda_mga: 0.4520\n",
      "Val Acc: 0.8888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 90]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.0975, Loss: 0.0498\n",
      "[Epoch 90] lambda_mga: 0.4560\n",
      "Val Acc: 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 91]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 41.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.4009, Loss: 0.0757\n",
      "[Epoch 91] lambda_mga: 0.4600\n",
      "Val Acc: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 92]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7224, Loss: 0.0675\n",
      "[Epoch 92] lambda_mga: 0.4640\n",
      "Val Acc: 0.8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 93]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 40.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.0975, Loss: 0.0535\n",
      "[Epoch 93] lambda_mga: 0.4680\n",
      "Val Acc: 0.8962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 94]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.6152, Loss: 0.0683\n",
      "[Epoch 94] lambda_mga: 0.4720\n",
      "Val Acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 95]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:14<00:00, 31.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.8832, Loss: 0.0539\n",
      "[Epoch 95] lambda_mga: 0.4760\n",
      "Val Acc: 0.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 96]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 41.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.3473, Loss: 0.0727\n",
      "[Epoch 96] lambda_mga: 0.4800\n",
      "Val Acc: 0.8788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 97]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 29.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.0707, Loss: 0.0547\n",
      "[Epoch 97] lambda_mga: 0.4840\n",
      "Val Acc: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 98]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.7492, Loss: 0.0615\n",
      "[Epoch 98] lambda_mga: 0.4880\n",
      "Val Acc: 0.8700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 99]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:15<00:00, 30.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 97.9368, Loss: 0.0599\n",
      "[Epoch 99] lambda_mga: 0.4920\n",
      "Val Acc: 0.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Epoch 100]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:11<00:00, 41.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Acc: 98.1511, Loss: 0.0582\n",
      "[Epoch 100] lambda_mga: 0.4960\n",
      "Val Acc: 0.8725\n",
      "\n",
      "ğŸ“Š Test Evaluation:\n",
      "âœ… Test Accuracy         : 90.62%\n",
      "ğŸ¯ AUC                   : 0.9408\n",
      "ğŸ“Œ Precision             : 0.9261\n",
      "ğŸ“Œ Recall (Sensitivity)  : 0.9314\n",
      "ğŸ“Œ Specificity           : 0.8582\n",
      "ğŸ“Œ F1 Score              : 0.9288\n",
      "ğŸ“Œ Balanced Accuracy     : 0.8948\n",
      "ğŸ“Œ MCC                   : 0.7917\n",
      "\n",
      "ğŸ“Œ Confusion Matrix:\n",
      "[[236  39]\n",
      " [ 36 489]]\n",
      "\n",
      "ğŸ“ í…ŒìŠ¤íŠ¸ ì§€í‘œ ì €ì¥ ì™„ë£Œ: logs/final_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# ğŸ‘ğŸ‘ğŸ‘ğŸ‘ âœ… Test Accuracy         : 90.62%\n",
    "# ğŸ¯ AUC                   : 0.9408\n",
    "# ğŸ“Œ Precision             : 0.9261\n",
    "# ğŸ“Œ Recall (Sensitivity)  : 0.9314\n",
    "# ğŸ“Œ Specificity           : 0.8582\n",
    "# ğŸ“Œ F1 Score              : 0.9288\n",
    "# ğŸ“Œ Balanced Accuracy     : 0.8948\n",
    "# ğŸ“Œ MCC                   : 0.7917\n",
    "\n",
    "# ğŸ“Œ Confusion Matrix:\n",
    "# [[236  39]\n",
    "#  [ 36 489]]\n",
    "# r18_cbam_mga_aug_lr4_ep100_weight.pth\n",
    "# ì „ì²´ì½”ë“œ: ResNet18 + CBAM + MGA Loss (CE Weight ver)\n",
    "\n",
    "import os, re, numpy as np, torch, gc\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# -------------------- ë””ë°”ì´ìŠ¤ ì„¤ì • --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • --------------------\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# lambda MGA ìŠ¤ì¼€ì¤„ ì„¤ì •\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "total_epochs = num_epochs\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # numpy or tensor ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜\n",
    "    transforms.Resize((224, 224)),  # ì´ë¯¸ì§€ë¥¼ 224x224ë¡œ resize\n",
    "    transforms.RandomHorizontalFlip(),  # ì´ë¯¸ì§€ë¥¼ 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „\n",
    "    transforms.RandomRotation(10),  # ì´ë¯¸ì§€ë¥¼ -10ë„ ~ +10ë„ ì‚¬ì´ë¡œ ëœë¤ íšŒì „, ì´¬ì˜ ìì„¸ë‚˜ ê¸°ìš¸ì–´ì§ì— ëŒ€í•œ íšŒì „ ê°•ê±´ì„±í™•ë³´\n",
    "    transforms.ToTensor(),  # PILì´ë¯¸ì§€ -> PyTorch Tensorë¡œ ë³€í™˜, (H, W, C) -> (C, H, W), ê°’ë„ 0255 -> 01 ì‚¬ì´ì¦ˆë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
    "    transforms.Normalize([0.5], [0.5]), # í‰ê·  0.5, í‘œì¤€í¸ì°¨ 0.5ë¡œ ì •ê·œí™” -> ê²°ê³¼ì ìœ¼ë¡œ 01 -> 11ë¡œ ë°”ë€œ\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
    "])  # ì „ì²´ ì´ë¯¸ì§€ì˜ ì¼ë¶€ë¶„ ì§€ìš°ê³  0ìœ¼ë¡œ ì±„ì›€ (ê²€ì€ ì‚¬ê°í˜• ìƒê¹€)\n",
    "    # p=0.5 : 50% í™•ë¥ ë¡œ ì´ ì¦ê°• ì ìš©\n",
    "    # scale : ì „ì²´ ì´ë¯¸ì§€ ëŒ€ë¹„ ì‚­ì œ ì˜ì—­ì˜ í¬ê¸° ë¹„ìœ¨\n",
    "    # ratio : ì§€ìš°ëŠ” ì‚¬ê°í˜•ì˜ ê°€ë¡œ:ì„¸ë¡œ ë¹„ìœ¨ ë²”ìœ„\n",
    "    # value=0 : ì§€ìš´ ê³³ì„ ê²€ì€ìƒ‰(0)ìœ¼ë¡œ ë®ìŒ\n",
    "    # í CTì—ì„œ ë³‘ë³€ì´ í•­ìƒ ì¼ì •í•œ ìœ„ì¹˜ì— ë‚˜ì˜¤ì§€ ì•Šìœ¼ë‹ˆê¹Œ ëª¨ë¸ì´ íŠ¹ì • ìœ„ì¹˜ì— ê³¼ì í•©ë˜ëŠ”ê±¸ ë°©ì§€í•¨ (overfitting ì˜ˆë°©)\n",
    "\n",
    "# ê²€ì¦/í…ŒìŠ¤íŠ¸ëŠ” ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ê¹¨ê¸‹í•œ ìƒíƒœì˜ ì´ë¯¸ì§€ë¡œ ì •í™•ë„ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ ê²€ì¦ìš©ì€ ê¹”ë”í•˜ê²Œ\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # PIL ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜\n",
    "    transforms.Resize((224, 224)),  # ì‚¬ì´ì¦ˆ ë§ì¶”ê¸°\n",
    "    transforms.ToTensor(),  # PIL ì´ë¯¸ì§€ -> PyTorch Tensorë¡œ ë³€í™˜\n",
    "    transforms.Normalize([0.5], [0.5])  # ì •ê·œí™”\n",
    "])\n",
    "\n",
    "# -------------------- Bounding Boxë¥¼ Binary Maskë¡œ --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    # bbox_list : í•œ ì´ë¯¸ì§€ì— ë“¤ì–´ìˆëŠ” bounding box ë¦¬ìŠ¤íŠ¸\n",
    "    # image_size : ì¶œë ¥í•  ë§ˆìŠ¤í¬ í¬ê¸°. ë³´í†µ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ (height, width) -> ë””í´íŠ¸ëŠ” 224x224\n",
    "    # bboxë“¤ì„ binary maskë¡œ ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜\n",
    "    masks = []  # ì—¬ëŸ¬ ê°œì˜ bboxê°€ ë“¤ì–´ì˜¤ë‹ˆê¹Œ, ê°ê°ì˜ ë§ˆìŠ¤í¬ë¥¼ í•˜ë‚˜ì”© ë¦¬ìŠ¤íŠ¸ì— ìŒ“ê¸° ìœ„í•œ ë¹ˆ ë¦¬ìŠ¤íŠ¸\n",
    "    for bbox in bbox_list:  # bbox_listë¥¼ í•˜ë‚˜ì”© ëŒë©´ì„œ ì²˜ë¦¬ -> [x_min, y_min, x_max, y_max]ë„¤ ì¢Œí‘œë¡œ êµ¬ì„±ëœ í•˜ë‚˜ì˜ ì‚¬ê°í˜• ì˜ì—­ \n",
    "        mask = np.zeros(image_size, dtype=np.float32)   # 224x224ì§œë¦¬ 0ìœ¼ë¡œ ê½‰ ì°¬ 2D ë°°ì—´ì„ í•˜ë‚˜ ìƒì„±\n",
    "        # ë°°ê²½ì´ í° ì¢…ì´ë¥¼ ë§Œë“œëŠ” ëŠë‚Œìœ¼ë¡œ ë§Œë“¤ê³ , ì‚¬ê° ì˜ì—­ë§Œ 1ë¡œ ë§ì¹ í• ê±°ì„\n",
    "        x_min, y_min, x_max, y_max = bbox   # ê° bboxì˜ ë„¤ ì¢Œí‘œê°’ì„ ê°ê° ë³€ìˆ˜ë¡œ ì–¸íŒ©. -> ë§ˆìŠ¤í¬ì˜ í•´ë‹¹ ì˜ì—­ì— ì‚¬ê°í˜•ì„ ì¹ í•˜ê¸° ìœ„í•´ì„œ\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0    # y_min, y_max, x_min, x_maxê¹Œì§€ì˜ ë²”ìœ„ì— 1.0ì„ ì±„ì›Œ ë„£ìŒ\n",
    "        # -> ë§ˆìŠ¤í¬ì—ì„œ bboxì— í•´ë‹¹í•˜ëŠ” ì‚¬ê°í˜• ì˜ì—­ë§Œ 1(foreground)ë¡œ í‘œì‹œë¨. ë‚˜ë¨¸ì§„ ì—¬ì „íˆ 0(background)\n",
    "        masks.append(mask)  # ì§€ê¸ˆ ë§Œë“  ë§ˆìŠ¤í¬(2D ë°°ì—´)ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ -> [mask1, mask2, ...]ì´ë ‡ê²Œ ìŒ“ì„\n",
    "\n",
    "    masks = np.stack(masks) # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ 3D ë°°ì—´ë¡œ í•©ì¹¨ -> shape : [N, H, W] -> Nì€ bbox ê°œìˆ˜\n",
    "    masks = np.expand_dims(masks, axis=1)   # í…ì„œ shapeì„ [N, 1, H, W]ë¡œ ë°”ê¿ˆ\n",
    "    # PyTorch ëª¨ë¸ì—ì„œ ê¸°ëŒ€í•˜ëŠ” (batch x channel x height x width) í¬ë§· ë§ì¶”ê¸°\n",
    "\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "    # numpy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜í•´ì„œ ë¦¬í„´\n",
    "\n",
    "    # í•œ bbox â†’ í•˜ë‚˜ì˜ ë§ˆìŠ¤í¬ â†’ ì—¬ëŸ¬ ê°œë©´ ìŒ“ì•„ì„œ batch í˜•íƒœë¡œ\n",
    "# -------------------- Bounding Box CSV ë¡œë“œ --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    # csv_path : bounding box ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” CSV íŒŒì¼ ê²½ë¡œ\n",
    "    # ë°˜í™˜ê°’ : {filename:[bbox1, bbox2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬\n",
    "    df = pd.read_csv(csv_path)  # CSVíŒŒì¼ì„ pandas DataFrameìœ¼ë¡œ ì½ì–´ì˜´\n",
    "    bbox_dict = {}\n",
    "    # key : ìŠ¬ë¼ì´ìŠ¤ íŒŒì¼ ì´ë¦„ (ex. \"LIDC-IDRI-1012_slice0004.npy\")\n",
    "    # value : í•´ë‹¹ ìŠ¬ë¼ì´ìŠ¤ì— ì¡´ì¬í•˜ëŠ” bboxë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "    for _, row in df.iterrows():    # DataFrameì˜ ëª¨ë“  í–‰(row)ë¥¼ í•˜ë‚˜ì”© ìˆœíšŒ\n",
    "        # rowëŠ” í•œ ì¤„(=í•œ bbox)ì˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆìŒ\n",
    "\n",
    "        pid = row['pid']    # í™˜ì ID (ì˜ˆ: \"LIDC-IDRI-1012\") -> ì´ë¯¸ì§€ ì´ë¦„ êµ¬ì„± ìš”ì†Œ\n",
    "        slice_str = row['slice']    # ìŠ¬ë¼ì´ìŠ¤ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” ë¬¸ìì—´ (ì˜ˆ: \"slice_0039\")\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])  # re.findall()ë¡œ ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ë½‘ì•„ëƒ„\n",
    "        # \"slice_0039\" -> ['0039'] -> [0] -> 39 (ìŠ¬ë¼ì´ìŠ¤ ë²ˆí˜¸ë¥¼ ì •ìˆ˜ë¡œ ì¶”ì¶œí•¨)\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"   # íŒŒì¼ëª… êµ¬ì„± (ì˜ˆ: \"LIDC-IDRI-1012_slice0039.npy\")\n",
    "        # {:04d}ëŠ” 4ìë¦¬ ì •ìˆ˜ë¡œ ë§Œë“¤ê³  ë¹ˆìë¦¬ëŠ” 0ìœ¼ë¡œ ì±„ì›Œì¤Œ (39 -> 0039)\n",
    "        bbox = eval(row['bb'])  # row['bb']ëŠ” ë¬¸ìì—´ í˜•íƒœì˜ bbox (ì˜ˆ: \"[20, 30, 80, 100]\")\n",
    "        # eval()ì„ ì¨ì„œ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ê¿”ì¤Œ\n",
    "        # ì£¼ì˜ : ë³´ì•ˆ ìƒ ìœ„í—˜í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ì§€ë§Œ, ì—¬ê¸´ ë‚´ë¶€ ë°ì´í„°ë¼ ì‚¬ìš©ì¤‘\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)    # fnameì´ë¼ëŠ” keyê°€ ë”•ì…”ë„ˆë¦¬ì— ì—†ìœ¼ë©´ []ë¡œ ì´ˆê¸°í™”í•˜ê³ ,\n",
    "        # ê±°ê¸°ì— bboxë¥¼ append -> ìŠ¬ë¼ì´ìŠ¤ í•˜ë‚˜ì— bbox ì—¬ëŸ¬ê°œ ìˆì–´ë„ ì „ë¶€ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ì•„ì¤Œ\n",
    "    return bbox_dict    # ìµœì¢…ì ìœ¼ë¡œ {filename: [bbox1, bbox2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "# ì‹¤ì œë¡œ csv_pathì— ìˆëŠ” ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™€ì„œ bbox_dictì— ì €ì¥í•¨\n",
    "# ì´ê±¸ ë‚˜ì£¼ì— Dataset í´ë˜ìŠ¤ì—ì„œ fname ê¸°ì¤€ì„ êº¼ë‚´ì“°ê²Œ ë¨\n",
    "\n",
    "# -------------------- ë¼ë²¨ ì¶”ì¶œ --------------------\n",
    "def extract_label_from_filename(fname): # fname : íŒŒì¼ ì´ë¦„ (ì˜ˆ: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # ì´ ì´ë¦„ì—ì„œ malignancy score(ì•…ì„±ë„ ì ìˆ˜)ë¥¼ ì¶”ì¶œí•´ì„œ ë¼ë²¨ë¡œ ë³€í™˜\n",
    "    try:    # íŒŒì¼ëª…ì´ ì´ìƒí•˜ê±°ë‚˜ ì—ëŸ¬ë‚˜ë©´ exceptë¡œ ë¹ ì ¸ë‚˜ê°€ì„œ None ë°˜í™˜í•¨ (ì•ˆì „ì¥ì¹˜)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # íŒŒì¼ëª…ì—ì„œ _ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ê²ƒë“¤ ì¤‘ì— ë§ˆì§€ë§‰ì—êº¼ë¥¼ ê°€ì ¸ì™€ì„œ .npyë¥¼ \"\" ì´ë ‡ê²Œ ê³µë°±ìœ¼ë¡œ ì²˜ë¦¬í•¨\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- ì´ê²Œ malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # ë¼ë²¨ ê²°ì • ë¡œì§ìœ¼ë¡œ\n",
    "        # score == 3 -> ì¤‘ë¦½ -> None ë°˜í™˜ -> í•™ìŠµì—ì„œ ì œì™¸\n",
    "        # score >= 4 -> ì•”(ì–‘ì„±) -> 1\n",
    "        # score <= 2 -> ì •ìƒ(ìŒì„±) -> 0\n",
    "        # int(score >= 4)ëŠ” íŒŒì´ì¬ì—ì„œ True -> 1\n",
    "        # False -> 0 ì´ë‹ˆê¹ ìë™ìœ¼ë¡œ ë¼ë²¨ì´ ë¨\n",
    "    except:\n",
    "        return None\n",
    "        # í˜¹ì‹œ splitì´ë‚˜ replace, int ë³€í™˜ì´ ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ None ë°˜í™˜í•˜ê³  ë¬´ì‹œ\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    # PyTorchì˜ Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†í•´ì„œ ì»¤ã…¡í…€ ë°ì´í„°ì…‹ ì •ì˜\n",
    "    # ë‚˜ì¤‘ì— DataLoaderë‘ ê°™ì´ ì“°ì´ê¸° ë•Œë¬¸ì— __len__()ì´ë‘ __getitem__()ì„ ê¼­ ë„£ì–´ì¤˜ì•¼í•¨\n",
    "    def __init__(self, paths, labels, transform=None):  # ìƒì„±ì : ì„¸ê°œì˜ ì¸ìë¥¼ ë°›ìŒ\n",
    "        # paths : ì´ë¯¸ì§€ .npy íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "        # labels : ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ (0, 1 or None)\n",
    "        # transform : ì´ë¯¸ì§€ ì¦ê°• ì„¤ì • (train_transform, val_transform ë“±)\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # ë°›ì€ ì¸ìë¥¼ ë©¤ë²„ ë³€ìˆ˜ë¡œ ì €ì¥. ë‚˜ì¤‘ì— gettem()ì—ì„œ ì ‘ê·¼í•¨\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoaderê°€ ì´ê±¸ í˜¸ì¶œí•  ë•Œ indexì— í•´ë‹¹í•˜ëŠ” sample í•˜ë‚˜ë¥¼ ë°˜í™˜\n",
    "        # ì´ë¯¸ì§€, ë¼ë²¨, ë§ˆìŠ¤í¬( = MGAìš© target) 3ê°œë¥¼ ë¦¬í„´í•¨\n",
    "        file_path = self.paths[idx] # íŒŒì¼ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        label = self.labels[idx]    # ë¼ë²¨ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        fname = os.path.basename(file_path) # ì „ì²´ ê²½ë¡œì—ì„œ íŒŒì¼ ì´ë¦„ë§Œ ì¶”ì¶œ -> ë‚˜ì¤‘ì— bbox_dict[fname] ì°¾ì„ë•Œ ì“°ì„\n",
    "\n",
    "        img = np.load(file_path)    # .npy íŒŒì¼ì—ì„œ CT ìŠ¬ë¼ì´ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° -> í‘ë°± CT ì´ë¯¸ì§€, shapeì€ (H, W)\n",
    "        img = np.clip(img, -1000, 400)  # CT ì´ë¯¸ì§€ HU ê°’ì´ ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´ ë…¸ì´ì¦ˆ -> -1000(ê³µê¸°) ~ 400(ì—°ì¡°ì§)ìœ¼ë¡œ í´ë¦¬í•‘í•´ì„œ ë…¸ì´ì¦ˆ ì œê±°\n",
    "        img = (img + 1000) / 1400.  # ì •ê·œí™” : -1000 -> 0, 400 -> 1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë°”ê¿”ì¤Œ -> ëª¨ë¸ì´ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•¨\n",
    "        img = np.expand_dims(img, axis=-1)  # CTëŠ” ì±„ë„ì´ 1ê°œë‹ˆê¹ (H, W) -> (H, w, 1)ë¡œ ë°”ê¿”ì¤Œ\n",
    "        # ë‚˜ì¤‘ì— PyTorchì—ì„œ (C, H, W)ë¡œ ë°”ê¾¸ê¸° ìœ„í•¨\n",
    "\n",
    "        if self.transform:  # ë°ì´í„° ì¦ê°•(transform)ì´ ìˆë‹¤ë©´ ì ìš©\n",
    "            img = self.transform(img)   \n",
    "        else:   # ì—†ìœ¼ë©´ numpy -> tensor ë³€í™˜í•˜ê³  (H, W, C) -> (C, H, W)ë¡œ ìˆœì„œ ë°”ê¿ˆ\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "\n",
    "        if fname in bbox_dict:  # ì´ ì´ë¯¸ì§€ì— bboxê°€ ì¡´ì¬í•˜ë©´ -> ë§ˆìŠ¤í¬ ìƒì„±\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(224, 224))\n",
    "            # image_sizeëŠ” transformê³¼ ë™ì¼í•˜ê²Œ 224x224\n",
    "        else:   # bboxê°€ ì—†ë‹¤ë©´ ì „ë¶€ 0ìœ¼ë¡œ ì±„ì›Œì§„ ë§ˆìŠ¤í¬ ìƒì„± -> MGA Loss ê³„ì‚° ì‹œ ì°¸ê³ ìš©ìœ¼ë¡œ ì“°ì¼ ìˆ˜ ìˆìŒ\n",
    "            mask = torch.zeros((1, 224, 224), dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask.squeeze(0)\n",
    "        # ë°˜í™˜ê°’ 3ê°œ :\n",
    "        # img : shape[1, 224, 224]\n",
    "        # label : int(0 or 1)\n",
    "        # mask : [224, 224] <- squeezeë¡œ ì±„ë„ 1ê°œ ì œê±°\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    # ì „ì²´ ë°ì´í„°ì…‹ ê¸¸ì´ ë°˜í™˜ -> DataLoaderê°€ ì•„ë¼ì•¼ ë°°ì¹˜ ìª¼ê°¤ ìˆ˜ ìˆìŒ.\n",
    "\n",
    "# -------------------- CBAM ì •ì˜ (MGA í¬í•¨) --------------------\n",
    "# 2 Step : Channel Attention(ì–´ë–¤ ì±„ë„ì— ì§‘ì¤‘í• ì§€) * Spatial Attention(ì–´ë””ì— ì§‘ì¤‘í• ì§€) = ìµœì¢… Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # ì…ë ¥ feature mapì˜ ì±„ë„ë³„ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•´ì„œ ê°•ì¡°í•¨\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : ì…ë ¥ ì±„ë„ ìˆ˜\n",
    "        # ratio : ì¤‘ê°„ ì±„ë„ ì¶•ì†Œ ë¹„ìœ¨. ê¸°ë³¸ 1/16ìœ¼ë¡œ bottlenck êµ¬ì„±\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP ì—­í• ì„ í•˜ëŠ” 1x1 conv ë¸”ë¡ -> ì±„ë„ ì••ì¶• -> ë¹„ì„ í˜• -> ë³µì› (sharedëŠ” avg/max ë‘˜ë‹¤ì—ì„œ ê°™ì´ ì”€)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # í‰ê·  í’€ë§ / ìµœëŒ€ í’€ë§ìœ¼ë¡œ ë‘ê°€ì§€ ì „ì—­ ì •ë³´ë¥¼ ì¶”ì¶œ\n",
    "        # ë§ˆì§€ë§‰ sigmoidëŠ” attention weightë¡œ ìŠ¤ì¼€ì¼ë§\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max í’€ë§ ê²½ê³¼ë¥¼ ê°ê° shape MLPì— í†µê³¼ì‹œí‚¤ê³ , ë”í•œ í›„ sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> ì±„ë„ë§ˆë‹¤ ì¤‘ìš”ë„ weightë¥¼ ê³±í•˜ê²Œ ë¨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # ê³µê°„ì ìœ¼ë¡œ ì–´ë””ì— ì§‘ì¤‘í• ì§€ë¥¼ ê²°ì • -> ê° ì±„ë„ ë‚´ë¶€ì—ì„œ ì¤‘ìš”í•œ ìœ„ì¹˜ ì°¾ê¸°\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # ì±„ë„ ì°¨ì›ì€ í‰ê· , ìµœëŒ€ ë‘ ê°œë§Œ ì¨ì„œ concat\n",
    "    # ê·¸ê±¸ 1ì±„ë„ë¡œ ì¤„ì—¬ì£¼ëŠ” conv\n",
    "    # ì»¤ë„ í¬ê¸° k=7ì´ë©´ ë„“ì€ ì˜ì—­ê¹Œì§€ ê°ì§€ ê°€ëŠ¥\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # ì…ë ¥ feature mapì—ì„œ :\n",
    "    # í‰ê· , ìµœëŒ€ê°’ì„ ê° spatial ìœ„ì¹˜ë³„ë¡œ êµ¬í•¨ -> [B, 1, H, W] ë‘ ê°œ\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> ìœ„ì¹˜ë³„ ì¤‘ìš”ë„ map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttentionì„ ë‚´ë¶€ì— ì„ ì–¸\n",
    "    # MGAë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ attention mapì„ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ í¬í•¨\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # ì±„ë„ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ìœ„ì¹˜ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ë‘˜ ë‹¤ ë°˜ì˜ëœ ìµœì¢… feature map ë¦¬í„´\n",
    "\n",
    "# -------------------- ResNet18 + CBAM ëª¨ë¸ ì •ì˜ --------------------\n",
    "# BasicBlockCBAM : ResNetì˜ ê¸°ë³¸ Residual Block í•˜ë‚˜ë¥¼ ì •ì˜\n",
    "# â†’ conv â†’ BN â†’ ReLU â†’ conv â†’ BN â†’ (CBAM optional) â†’ Add â†’ ReLU\n",
    "\n",
    "# ResNet18_CBAM : ResNet18 êµ¬ì¡°ë¡œ ì „ì²´ ë„¤íŠ¸ì›Œí¬ ìŒ“ê¸°\n",
    "# â†’ conv1 â†’ layer1~3 â†’ layer4 â†’ avgpool â†’ fc\n",
    "\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        # ì…ë ¥ ì±„ë„: in_planes, ì¶œë ¥ ì±„ë„: out_planes, 3x3 ì»¤ë„, padding=1ë¡œ í¬ê¸° ìœ ì§€, strideë¡œ í¬ê¸° ì¡°ì ˆ\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)   # ë°°ì¹˜ ì •ê·œí™”\n",
    "        self.relu = nn.ReLU()   # ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        # ë‘ë²ˆì§¸ conv, ì±„ë„ ìˆ˜ ìœ ì§€, í¬ê¸° ìœ ì§€\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)   # ë°°ì¹˜ ì •ê·œí™”\n",
    "\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None  # CBAM ëª¨ë“ˆ ì‚¬ìš© ì—¬ë¶€\n",
    "        self.downsample = downsample    # residual ì—°ê²° ì‹œ ì°¨ì› ë§ì¶”ëŠ” conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # skip connectionìš© ì…ë ¥ ì €ì¥\n",
    "\n",
    "        out = self.conv1(x) # ì²« ë²ˆì§¸ conv\n",
    "        out = self.bn1(out) # ì •ê·œí™”\n",
    "        out = self.relu(out)  # í™œì„±í™”\n",
    "\n",
    "        out = self.conv2(out)   # ë‘ ë²ˆì§¸ conv\n",
    "        out = self.bn2(out) # ì •ê·œí™”\n",
    "\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)    # CBAM ì ìš©\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)   # shortcut ê²½ë¡œ ë³´ì •\n",
    "\n",
    "        out += residual # skip connection\n",
    "        out = self.relu(out)    # ì¶œë ¥ì— ReLU ì ìš©\n",
    "\n",
    "        return out  # ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64 # ì¡°ê¸° ì…ë ¥ ì±„ë„ ìˆ˜ ì„¤ì •\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # ì…ë ¥: [B, 1, 224, 224] -> ì¶œë ¥: [B, 64, 112, 112], í° ì»¤ë„ë¡œ ë„“ì€ ì˜ì—­ ìº¡ì²˜ \n",
    "        self.bn1 = nn.BatchNorm2d(64)   # ì •ê·œí™”\n",
    "        self.relu = nn.ReLU()   # í™œì„±í™”\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # í’€ë§: [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        self.layer1 = self._make_layer(64, blocks=2)  # [B, 64, 56, 56] ìœ ì§€\n",
    "        self.layer2 = self._make_layer(128, blocks=2, stride=2)  # [B, 128, 28, 28] ë‹¤ìš´ìƒ˜í”Œë§\n",
    "        self.layer3 = self._make_layer(256, blocks=2, stride=2)  # [B, 256, 14, 14] ë‹¤ìš´ìƒ˜í”Œë§\n",
    "        self.layer4 = self._make_layer(512, blocks=2, stride=2, use_cbam=False)  # [B, 512, 7, 7], CBAM ë¯¸ì‚¬ìš©\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # [B, 512, 7, 7] -> [B, 512, 1, 1]\n",
    "        self.fc = nn.Linear(512, num_classes)  # [B, 512] -> [B, num_classes]\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        # Planes : í•´ë‹¹ ë ˆì´ì–´ì˜ ì¶œë ¥ ì±„ë„ ìˆ˜\n",
    "        # # blocks : ë¸”ë¡ ìˆ˜\n",
    "        # stride=2ì¸ ê²½ìš° ë‹¤ìš´ìƒ˜í”Œë§ (í•´ìƒë„ ì ˆë°˜)\n",
    "\n",
    "        downsample = None   # ìŠ¤í‚µ ì—°ê²°í•´ì„œ ì…ë ¥/ì¶œë ¥ í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ë§ì¶°ì•¼ í•¨\n",
    "\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                # 1x1 convë¡œ ì±„ë„ ìˆ˜   ë° ê³µê°„ í¬ê¸° ë§ì¶¤\n",
    "                nn.BatchNorm2d(planes))\n",
    "            \n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam=use_cbam)]\n",
    "        # ì²« ë¸”ë¡ì€ ë‹¤ìš´ìƒ˜í”Œë§ ì ìš© ê°€ëŠ¥ì„± ìˆìŒ\n",
    "        self.in_planes = planes # ì´í›„ ë¸”ë¡ì„ ìœ„í•œ ì…ë ¥ ì±„ë„ ì—…ë°ì´íŠ¸\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "            # ë‚˜ë¨¸ì§€ ë¸”ë¡ì€ stride=1ë¡œ ë™ì¼í•œ í•´ìƒë„ ìœ ì§€\n",
    "\n",
    "        return nn.Sequential(*layers)   # ë¸”ë¡ë“¤ì„ Seguentialë¡œ ë¬¶ì–´ ë°˜í™˜\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # ì…ë ¥: [B, 1, 224, 224] -> [B, 64, 112, 112]\n",
    "        x = self.bn1(x)    # ì •ê·œí™”\n",
    "        x = self.relu(x)   # ReLU í™œì„±í™”\n",
    "        x = self.maxpool(x)  # [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        x = self.layer1(x)  # [B, 64, 56, 56]\n",
    "        x = self.layer2(x)  # [B, 128, 28, 28]\n",
    "        x = self.layer3(x)  # [B, 256, 14, 14]\n",
    "        x = self.layer4(x)  # [B, 512, 7, 7]\n",
    "\n",
    "        x = self.avgpool(x)  # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # [B, 512]\n",
    "        x = self.fc(x)  # [B, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------- í•™ìŠµ ë£¨í”„ --------------------\n",
    "def run():\n",
    "    # ëª¨ë“  CT ìŠ¬ë¼ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸° (LIDC-IDRI í™˜ì í´ë” ì•ˆì˜ .npy íŒŒì¼ë“¤)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "\n",
    "    # íŒŒì¼ ê²½ë¡œì™€ í•´ë‹¹ íŒŒì¼ì˜ ë¼ë²¨ì„ íŠœí”Œë¡œ ì €ì¥\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    # ë¼ë²¨ì´ Noneì´ ì•„ë‹Œ ë°ì´í„°ë§Œ í•„í„°ë§ (ì¤‘ë¦½ ì œì™¸)\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "\n",
    "    # íŒŒì¼, ë¼ë²¨ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„°ë¥¼ train(70%), val(15%), test(15%)ë¡œ ë¶„í• \n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    train_dataset = CTDataset(train_files, train_labels, transform=train_transform)\n",
    "    val_dataset = CTDataset(val_files, val_labels, transform=val_transform)\n",
    "    test_dataset = CTDataset(test_files, test_labels, transform=val_transform)\n",
    "\n",
    "    # ë°ì´í„° ë¡œë”\n",
    "    train_loader = DataLoader(train_dataset,  batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.6653, 0.3347], device=device))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    best_acc = 0.0  # ê°€ì¥ ë†’ì€ val accuracyë¥¼ ì €ì¥\n",
    "    save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"r18_cbam_mga_aug_lr4_ep100_weight.pth\")\n",
    "\n",
    "    # í•™ìŠµ ë£¨í”„ ì‹œì‘\n",
    "    for epoch in range(num_epochs):\n",
    "        # MGA ìŠ¤ì¼€ì¥´ë§: ì´ˆê¸° lambda -> ì ì  ì¦ê°€ì‹œí‚´\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "\n",
    "        model.train()  # í•™ìŠµ ëª¨ë“œë¡œ ë³€ê²½\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # í•œ epoch ë™ì•ˆ ëª¨ë“  train ë°ì´í„°ë¥¼ í•™ìŠµ\n",
    "        for images, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)  # forward pass\n",
    "            ce_loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "            # -------------------- MGA Loss ê³„ì‚° ìœ„ì¹˜ --------------------\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # attention map êº¼ë‚´ì˜¤ê¸°\n",
    "\n",
    "            if attn_map is not None:\n",
    "                attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                attn_loss = F.mse_loss(attn_map, masks)  # maskì™€ì˜ MSE loss\n",
    "                loss = ce_loss + lambda_mga * attn_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Acc: {(correct/total)*100:.4f}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] lambda_mga: {lambda_mga:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()  # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "\n",
    "        # -------------------- ê²€ì¦ --------------------\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iamegs, labels, masks in val_loader:\n",
    "                iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "                outputs = model(iamegs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"âœ… Saved best model!\")\n",
    "\n",
    "    # -------------------- í…ŒìŠ¤íŠ¸ --------------------\n",
    "    print(\"\\nğŸ“Š Test Evaluation:\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # numpy ë°°ì—´ë¡œ ë³€í™˜\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_probs = np.array(y_probs)\n",
    "\n",
    "    # ì§€í‘œ ê³„ì‚°\n",
    "    from sklearn.metrics import (\n",
    "        classification_report, roc_auc_score, confusion_matrix,\n",
    "        precision_score, recall_score, balanced_accuracy_score,\n",
    "        matthews_corrcoef, f1_score\n",
    "    )\n",
    "\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    auc = roc_auc_score(y_true, y_probs)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel() if cm.shape == (2, 2) else (0, 0, 0, 0)\n",
    "    specificity = tn / (tn + fp + 1e-6)\n",
    "    balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    # ğŸ“‹ ì¶œë ¥\n",
    "    print(f\"âœ… Test Accuracy         : {acc*100:.2f}%\")\n",
    "    print(f\"ğŸ¯ AUC                   : {auc:.4f}\")\n",
    "    print(f\"ğŸ“Œ Precision             : {precision:.4f}\")\n",
    "    print(f\"ğŸ“Œ Recall (Sensitivity)  : {recall:.4f}\")\n",
    "    print(f\"ğŸ“Œ Specificity           : {specificity:.4f}\")\n",
    "    print(f\"ğŸ“Œ F1 Score              : {f1:.4f}\")\n",
    "    print(f\"ğŸ“Œ Balanced Accuracy     : {balanced_acc:.4f}\")\n",
    "    print(f\"ğŸ“Œ MCC                   : {mcc:.4f}\")\n",
    "    print(\"\\nğŸ“Œ Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # ğŸ“ CSVë¡œ ì €ì¥\n",
    "    test_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model\": \"ResNet18_CBAM_MGA\",\n",
    "        \"phase\": \"test\",\n",
    "        \"accuracy\": round(acc, 4),\n",
    "        \"auc\": round(auc, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "        \"specificity\": round(specificity, 4),\n",
    "        \"f1_score\": round(f1, 4),\n",
    "        \"balanced_acc\": round(balanced_acc, 4),\n",
    "        \"mcc\": round(mcc, 4),\n",
    "        \"tn\": int(tn), \"fp\": int(fp), \"fn\": int(fn), \"tp\": int(tp)\n",
    "    }\n",
    "\n",
    "    csv_path = \"logs/final_test_metrics.csv\"\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    file_exists = os.path.exists(csv_path)\n",
    "\n",
    "    with open(csv_path, 'a', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=test_metrics.keys())\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerow(test_metrics)\n",
    "\n",
    "    print(f\"\\nğŸ“ í…ŒìŠ¤íŠ¸ ì§€í‘œ ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "\n",
    "# ì§„ì…ì \n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë¼ë²¨ ë¶„í¬\n",
      "Class 0: 1784ê°œ\n",
      "Class 1: 3548ê°œ\n",
      "Class None: 2517ê°œ\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ğŸ“‚ ì „ì²´ ìŠ¬ë¼ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "\n",
    "# ğŸ·ï¸ íŒŒì¼ ì´ë¦„ì—ì„œ ë¼ë²¨ ì¶”ì¶œ í•¨ìˆ˜\n",
    "def extract_label_from_filename(fname):\n",
    "    try:\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        if score == 3:\n",
    "            return None  # ì¤‘ë¦½ì€ ì œì™¸\n",
    "        return int(score >= 4)  # 0 or 1\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# ğŸ“Š ë¼ë²¨ ì¹´ìš´íŠ¸\n",
    "label_counts = {\"0\": 0, \"1\": 0, \"None\": 0}\n",
    "for f in all_files:\n",
    "    label = extract_label_from_filename(f)\n",
    "    if label is None:\n",
    "        label_counts[\"None\"] += 1\n",
    "    else:\n",
    "        label_counts[str(label)] += 1\n",
    "\n",
    "# ì¶œë ¥\n",
    "print(\"âœ… ë¼ë²¨ ë¶„í¬\")\n",
    "for k, v in label_counts.items():\n",
    "    print(f\"Class {k}: {v}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ‘ğŸ‘ğŸ‘ ì „ì²´ì½”ë“œ: ResNet18 + CBAM + MGA Loss + Lambda Scheduling (ê¸°ë³¸) \n",
    "# + ë°ì´í„° ì¦ê°• (Resize 224 / RandomHorizontalFlip / RandomRotation 10 / RandomErasing)\n",
    "\n",
    "import os, re, numpy as np, torch, gc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------- ë””ë°”ì´ìŠ¤ ì„¤ì • --------------------\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------- í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • --------------------\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "bbox_csv_path = \"/home/iujeong/lung_cancer/csv/allbb_noPoly.csv\"\n",
    "\n",
    "batch_size = 16\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# lambda MGA ìŠ¤ì¼€ì¤„ ì„¤ì •\n",
    "initial_lambda = 0.1\n",
    "final_lambda = 0.5\n",
    "total_epochs = num_epochs\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # numpy or tensor ì´ë¯¸ì§€ë¥¼ PIL ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜\n",
    "    transforms.Resize((224, 224)),  # ì´ë¯¸ì§€ë¥¼ 224x224ë¡œ resize\n",
    "    transforms.RandomHorizontalFlip(),  # ì´ë¯¸ì§€ë¥¼ 50% í™•ë¥ ë¡œ ì¢Œìš° ë°˜ì „\n",
    "    transforms.RandomRotation(10),  # ì´ë¯¸ì§€ë¥¼ -10ë„ ~ +10ë„ ì‚¬ì´ë¡œ ëœë¤ íšŒì „, ì´¬ì˜ ìì„¸ë‚˜ ê¸°ìš¸ì–´ì§ì— ëŒ€í•œ íšŒì „ ê°•ê±´ì„±í™•ë³´\n",
    "    transforms.ToTensor(),  # PILì´ë¯¸ì§€ -> PyTorch Tensorë¡œ ë³€í™˜, (H, W, C) -> (C, H, W), ê°’ë„ 0255 -> 01 ì‚¬ì´ì¦ˆë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •\n",
    "    transforms.Normalize([0.5], [0.5]), # í‰ê·  0.5, í‘œì¤€í¸ì°¨ 0.5ë¡œ ì •ê·œí™” -> ê²°ê³¼ì ìœ¼ë¡œ 01 -> 11ë¡œ ë°”ë€œ\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0)\n",
    "])  # ì „ì²´ ì´ë¯¸ì§€ì˜ ì¼ë¶€ë¶„ ì§€ìš°ê³  0ìœ¼ë¡œ ì±„ì›€ (ê²€ì€ ì‚¬ê°í˜• ìƒê¹€)\n",
    "    # p=0.5 : 50% í™•ë¥ ë¡œ ì´ ì¦ê°• ì ìš©\n",
    "    # scale : ì „ì²´ ì´ë¯¸ì§€ ëŒ€ë¹„ ì‚­ì œ ì˜ì—­ì˜ í¬ê¸° ë¹„ìœ¨\n",
    "    # ratio : ì§€ìš°ëŠ” ì‚¬ê°í˜•ì˜ ê°€ë¡œ:ì„¸ë¡œ ë¹„ìœ¨ ë²”ìœ„\n",
    "    # value=0 : ì§€ìš´ ê³³ì„ ê²€ì€ìƒ‰(0)ìœ¼ë¡œ ë®ìŒ\n",
    "    # í CTì—ì„œ ë³‘ë³€ì´ í•­ìƒ ì¼ì •í•œ ìœ„ì¹˜ì— ë‚˜ì˜¤ì§€ ì•Šìœ¼ë‹ˆê¹Œ ëª¨ë¸ì´ íŠ¹ì • ìœ„ì¹˜ì— ê³¼ì í•©ë˜ëŠ”ê±¸ ë°©ì§€í•¨ (overfitting ì˜ˆë°©)\n",
    "\n",
    "# ê²€ì¦/í…ŒìŠ¤íŠ¸ëŠ” ëª¨ë¸ì´ í•™ìŠµí•˜ì§€ ì•Šì€ ê¹¨ê¸‹í•œ ìƒíƒœì˜ ì´ë¯¸ì§€ë¡œ ì •í™•ë„ë¥¼ í™•ì¸í•˜ê¸° ìœ„í•´ì„œ ê²€ì¦ìš©ì€ ê¹”ë”í•˜ê²Œ\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),    # PIL ì´ë¯¸ì§€ ê°ì²´ë¡œ ë³€í™˜\n",
    "    transforms.Resize((224, 224)),  # ì‚¬ì´ì¦ˆ ë§ì¶”ê¸°\n",
    "    transforms.ToTensor(),  # PIL ì´ë¯¸ì§€ -> PyTorch Tensorë¡œ ë³€í™˜\n",
    "    transforms.Normalize([0.5], [0.5])  # ì •ê·œí™”\n",
    "])\n",
    "\n",
    "# -------------------- Bounding Boxë¥¼ Binary Maskë¡œ --------------------\n",
    "def create_binary_mask_from_bbox(bbox_list, image_size=(224, 224)):\n",
    "    # bbox_list : í•œ ì´ë¯¸ì§€ì— ë“¤ì–´ìˆëŠ” bounding box ë¦¬ìŠ¤íŠ¸\n",
    "    # image_size : ì¶œë ¥í•  ë§ˆìŠ¤í¬ í¬ê¸°. ë³´í†µ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ (height, width) -> ë””í´íŠ¸ëŠ” 224x224\n",
    "    # bboxë“¤ì„ binary maskë¡œ ë°”ê¿”ì£¼ëŠ” í•¨ìˆ˜\n",
    "    masks = []  # ì—¬ëŸ¬ ê°œì˜ bboxê°€ ë“¤ì–´ì˜¤ë‹ˆê¹Œ, ê°ê°ì˜ ë§ˆìŠ¤í¬ë¥¼ í•˜ë‚˜ì”© ë¦¬ìŠ¤íŠ¸ì— ìŒ“ê¸° ìœ„í•œ ë¹ˆ ë¦¬ìŠ¤íŠ¸\n",
    "    for bbox in bbox_list:  # bbox_listë¥¼ í•˜ë‚˜ì”© ëŒë©´ì„œ ì²˜ë¦¬ -> [x_min, y_min, x_max, y_max]ë„¤ ì¢Œí‘œë¡œ êµ¬ì„±ëœ í•˜ë‚˜ì˜ ì‚¬ê°í˜• ì˜ì—­ \n",
    "        mask = np.zeros(image_size, dtype=np.float32)   # 224x224ì§œë¦¬ 0ìœ¼ë¡œ ê½‰ ì°¬ 2D ë°°ì—´ì„ í•˜ë‚˜ ìƒì„±\n",
    "        # ë°°ê²½ì´ í° ì¢…ì´ë¥¼ ë§Œë“œëŠ” ëŠë‚Œìœ¼ë¡œ ë§Œë“¤ê³ , ì‚¬ê° ì˜ì—­ë§Œ 1ë¡œ ë§ì¹ í• ê±°ì„\n",
    "        x_min, y_min, x_max, y_max = bbox   # ê° bboxì˜ ë„¤ ì¢Œí‘œê°’ì„ ê°ê° ë³€ìˆ˜ë¡œ ì–¸íŒ©. -> ë§ˆìŠ¤í¬ì˜ í•´ë‹¹ ì˜ì—­ì— ì‚¬ê°í˜•ì„ ì¹ í•˜ê¸° ìœ„í•´ì„œ\n",
    "        mask[y_min:y_max, x_min:x_max] = 1.0    # y_min, y_max, x_min, x_maxê¹Œì§€ì˜ ë²”ìœ„ì— 1.0ì„ ì±„ì›Œ ë„£ìŒ\n",
    "        # -> ë§ˆìŠ¤í¬ì—ì„œ bboxì— í•´ë‹¹í•˜ëŠ” ì‚¬ê°í˜• ì˜ì—­ë§Œ 1(foreground)ë¡œ í‘œì‹œë¨. ë‚˜ë¨¸ì§„ ì—¬ì „íˆ 0(background)\n",
    "        masks.append(mask)  # ì§€ê¸ˆ ë§Œë“  ë§ˆìŠ¤í¬(2D ë°°ì—´)ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€ -> [mask1, mask2, ...]ì´ë ‡ê²Œ ìŒ“ì„\n",
    "\n",
    "    masks = np.stack(masks) # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ 3D ë°°ì—´ë¡œ í•©ì¹¨ -> shape : [N, H, W] -> Nì€ bbox ê°œìˆ˜\n",
    "    masks = np.expand_dims(masks, axis=1)   # í…ì„œ shapeì„ [N, 1, H, W]ë¡œ ë°”ê¿ˆ\n",
    "    # PyTorch ëª¨ë¸ì—ì„œ ê¸°ëŒ€í•˜ëŠ” (batch x channel x height x width) í¬ë§· ë§ì¶”ê¸°\n",
    "\n",
    "    return torch.tensor(masks, dtype=torch.float32)\n",
    "    # numpy ë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜í•´ì„œ ë¦¬í„´\n",
    "\n",
    "    # í•œ bbox â†’ í•˜ë‚˜ì˜ ë§ˆìŠ¤í¬ â†’ ì—¬ëŸ¬ ê°œë©´ ìŒ“ì•„ì„œ batch í˜•íƒœë¡œ\n",
    "# -------------------- Bounding Box CSV ë¡œë“œ --------------------\n",
    "def load_bbox_dict(csv_path):\n",
    "    # csv_path : bounding box ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” CSV íŒŒì¼ ê²½ë¡œ\n",
    "    # ë°˜í™˜ê°’ : {filename:[bbox1, bbox2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬\n",
    "    df = pd.read_csv(csv_path)  # CSVíŒŒì¼ì„ pandas DataFrameìœ¼ë¡œ ì½ì–´ì˜´\n",
    "    bbox_dict = {}\n",
    "    # key : ìŠ¬ë¼ì´ìŠ¤ íŒŒì¼ ì´ë¦„ (ex. \"LIDC-IDRI-1012_slice0004.npy\")\n",
    "    # value : í•´ë‹¹ ìŠ¬ë¼ì´ìŠ¤ì— ì¡´ì¬í•˜ëŠ” bboxë“¤ì˜ ë¦¬ìŠ¤íŠ¸\n",
    "    for _, row in df.iterrows():    # DataFrameì˜ ëª¨ë“  í–‰(row)ë¥¼ í•˜ë‚˜ì”© ìˆœíšŒ\n",
    "        # rowëŠ” í•œ ì¤„(=í•œ bbox)ì˜ ì •ë³´ë¥¼ ë‹´ê³  ìˆìŒ\n",
    "\n",
    "        pid = row['pid']    # í™˜ì ID (ì˜ˆ: \"LIDC-IDRI-1012\") -> ì´ë¯¸ì§€ ì´ë¦„ êµ¬ì„± ìš”ì†Œ\n",
    "        slice_str = row['slice']    # ìŠ¬ë¼ì´ìŠ¤ ì •ë³´ê°€ ë“¤ì–´ìˆëŠ” ë¬¸ìì—´ (ì˜ˆ: \"slice_0039\")\n",
    "        slice_idx = int(re.findall(r'\\d+', str(slice_str))[0])  # re.findall()ë¡œ ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ë½‘ì•„ëƒ„\n",
    "        # \"slice_0039\" -> ['0039'] -> [0] -> 39 (ìŠ¬ë¼ì´ìŠ¤ ë²ˆí˜¸ë¥¼ ì •ìˆ˜ë¡œ ì¶”ì¶œí•¨)\n",
    "        fname = f\"{pid}_slice{slice_idx:04d}.npy\"   # íŒŒì¼ëª… êµ¬ì„± (ì˜ˆ: \"LIDC-IDRI-1012_slice0039.npy\")\n",
    "        # {:04d}ëŠ” 4ìë¦¬ ì •ìˆ˜ë¡œ ë§Œë“¤ê³  ë¹ˆìë¦¬ëŠ” 0ìœ¼ë¡œ ì±„ì›Œì¤Œ (39 -> 0039)\n",
    "        bbox = eval(row['bb'])  # row['bb']ëŠ” ë¬¸ìì—´ í˜•íƒœì˜ bbox (ì˜ˆ: \"[20, 30, 80, 100]\")\n",
    "        # eval()ì„ ì¨ì„œ ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ê¿”ì¤Œ\n",
    "        # ì£¼ì˜ : ë³´ì•ˆ ìƒ ìœ„í—˜í•  ìˆ˜ ìˆëŠ” í•¨ìˆ˜ì§€ë§Œ, ì—¬ê¸´ ë‚´ë¶€ ë°ì´í„°ë¼ ì‚¬ìš©ì¤‘\n",
    "        bbox_dict.setdefault(fname, []).append(bbox)    # fnameì´ë¼ëŠ” keyê°€ ë”•ì…”ë„ˆë¦¬ì— ì—†ìœ¼ë©´ []ë¡œ ì´ˆê¸°í™”í•˜ê³ ,\n",
    "        # ê±°ê¸°ì— bboxë¥¼ append -> ìŠ¬ë¼ì´ìŠ¤ í•˜ë‚˜ì— bbox ì—¬ëŸ¬ê°œ ìˆì–´ë„ ì „ë¶€ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ì•„ì¤Œ\n",
    "    return bbox_dict    # ìµœì¢…ì ìœ¼ë¡œ {filename: [bbox1, bbox2, ...]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜\n",
    "\n",
    "bbox_dict = load_bbox_dict(bbox_csv_path)\n",
    "# ì‹¤ì œë¡œ csv_pathì— ìˆëŠ” ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™€ì„œ bbox_dictì— ì €ì¥í•¨\n",
    "# ì´ê±¸ ë‚˜ì£¼ì— Dataset í´ë˜ìŠ¤ì—ì„œ fname ê¸°ì¤€ì„ êº¼ë‚´ì“°ê²Œ ë¨\n",
    "\n",
    "# -------------------- ë¼ë²¨ ì¶”ì¶œ --------------------\n",
    "def extract_label_from_filename(fname): # fname : íŒŒì¼ ì´ë¦„ (ì˜ˆ: \"LIDC-IDRI-1012_slice0039_5.npy\")\n",
    "    # ì´ ì´ë¦„ì—ì„œ malignancy score(ì•…ì„±ë„ ì ìˆ˜)ë¥¼ ì¶”ì¶œí•´ì„œ ë¼ë²¨ë¡œ ë³€í™˜\n",
    "    try:    # íŒŒì¼ëª…ì´ ì´ìƒí•˜ê±°ë‚˜ ì—ëŸ¬ë‚˜ë©´ exceptë¡œ ë¹ ì ¸ë‚˜ê°€ì„œ None ë°˜í™˜í•¨ (ì•ˆì „ì¥ì¹˜)\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        # íŒŒì¼ëª…ì—ì„œ _ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ê²ƒë“¤ ì¤‘ì— ë§ˆì§€ë§‰ì—êº¼ë¥¼ ê°€ì ¸ì™€ì„œ .npyë¥¼ \"\" ì´ë ‡ê²Œ ê³µë°±ìœ¼ë¡œ ì²˜ë¦¬í•¨\n",
    "        # fname.split(\"_\") -> ['LIDC-IDRI-1012', 'slice0039', '5.npy]\n",
    "        # [-1] -> '5.npy'\n",
    "        # .replace(\".npy\", \"\") -> '5'\n",
    "        # int(...) -> 5 <- ì´ê²Œ malignancy score\n",
    "        return None if score == 3 else int(score >= 4)\n",
    "        # ë¼ë²¨ ê²°ì • ë¡œì§ìœ¼ë¡œ\n",
    "        # score == 3 -> ì¤‘ë¦½ -> None ë°˜í™˜ -> í•™ìŠµì—ì„œ ì œì™¸\n",
    "        # score >= 4 -> ì•”(ì–‘ì„±) -> 1\n",
    "        # score <= 2 -> ì •ìƒ(ìŒì„±) -> 0\n",
    "        # int(score >= 4)ëŠ” íŒŒì´ì¬ì—ì„œ True -> 1\n",
    "        # False -> 0 ì´ë‹ˆê¹ ìë™ìœ¼ë¡œ ë¼ë²¨ì´ ë¨\n",
    "    except:\n",
    "        return None\n",
    "        # í˜¹ì‹œ splitì´ë‚˜ replace, int ë³€í™˜ì´ ì‹¤íŒ¨í•˜ë©´ ê·¸ëƒ¥ None ë°˜í™˜í•˜ê³  ë¬´ì‹œ\n",
    "\n",
    "# -------------------- Dataset --------------------\n",
    "class CTDataset(Dataset):\n",
    "    # PyTorchì˜ Dataset í´ë˜ìŠ¤ë¥¼ ìƒì†í•´ì„œ ì»¤ã…¡í…€ ë°ì´í„°ì…‹ ì •ì˜\n",
    "    # ë‚˜ì¤‘ì— DataLoaderë‘ ê°™ì´ ì“°ì´ê¸° ë•Œë¬¸ì— __len__()ì´ë‘ __getitem__()ì„ ê¼­ ë„£ì–´ì¤˜ì•¼í•¨\n",
    "    def __init__(self, paths, labels, transform=None):  # ìƒì„±ì : ì„¸ê°œì˜ ì¸ìë¥¼ ë°›ìŒ\n",
    "        # paths : ì´ë¯¸ì§€ .npy íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸\n",
    "        # labels : ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸ (0, 1 or None)\n",
    "        # transform : ì´ë¯¸ì§€ ì¦ê°• ì„¤ì • (train_transform, val_transform ë“±)\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        # ë°›ì€ ì¸ìë¥¼ ë©¤ë²„ ë³€ìˆ˜ë¡œ ì €ì¥. ë‚˜ì¤‘ì— gettem()ì—ì„œ ì ‘ê·¼í•¨\n",
    "\n",
    "    def __getitem__(self, idx): # DataLoaderê°€ ì´ê±¸ í˜¸ì¶œí•  ë•Œ indexì— í•´ë‹¹í•˜ëŠ” sample í•˜ë‚˜ë¥¼ ë°˜í™˜\n",
    "        # ì´ë¯¸ì§€, ë¼ë²¨, ë§ˆìŠ¤í¬( = MGAìš© target) 3ê°œë¥¼ ë¦¬í„´í•¨\n",
    "        file_path = self.paths[idx] # íŒŒì¼ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        label = self.labels[idx]    # ë¼ë²¨ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        fname = os.path.basename(file_path) # ì „ì²´ ê²½ë¡œì—ì„œ íŒŒì¼ ì´ë¦„ë§Œ ì¶”ì¶œ -> ë‚˜ì¤‘ì— bbox_dict[fname] ì°¾ì„ë•Œ ì“°ì„\n",
    "\n",
    "        img = np.load(file_path)    # .npy íŒŒì¼ì—ì„œ CT ìŠ¬ë¼ì´ìŠ¤ ë¶ˆëŸ¬ì˜¤ê¸° -> í‘ë°± CT ì´ë¯¸ì§€, shapeì€ (H, W)\n",
    "        img = np.clip(img, -1000, 400)  # CT ì´ë¯¸ì§€ HU ê°’ì´ ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´ ë…¸ì´ì¦ˆ -> -1000(ê³µê¸°) ~ 400(ì—°ì¡°ì§)ìœ¼ë¡œ í´ë¦¬í•‘í•´ì„œ ë…¸ì´ì¦ˆ ì œê±°\n",
    "        img = (img + 1000) / 1400.  # ì •ê·œí™” : -1000 -> 0, 400 -> 1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë°”ê¿”ì¤Œ -> ëª¨ë¸ì´ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ í•¨\n",
    "        img = np.expand_dims(img, axis=-1)  # CTëŠ” ì±„ë„ì´ 1ê°œë‹ˆê¹ (H, W) -> (H, w, 1)ë¡œ ë°”ê¿”ì¤Œ\n",
    "        # ë‚˜ì¤‘ì— PyTorchì—ì„œ (C, H, W)ë¡œ ë°”ê¾¸ê¸° ìœ„í•¨\n",
    "\n",
    "        if self.transform:  # ë°ì´í„° ì¦ê°•(transform)ì´ ìˆë‹¤ë©´ ì ìš©\n",
    "            img = self.transform(img)   \n",
    "        else:   # ì—†ìœ¼ë©´ numpy -> tensor ë³€í™˜í•˜ê³  (H, W, C) -> (C, H, W)ë¡œ ìˆœì„œ ë°”ê¿ˆ\n",
    "            img = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32)\n",
    "\n",
    "        if fname in bbox_dict:  # ì´ ì´ë¯¸ì§€ì— bboxê°€ ì¡´ì¬í•˜ë©´ -> ë§ˆìŠ¤í¬ ìƒì„±\n",
    "            mask = create_binary_mask_from_bbox(bbox_dict[fname], image_size=(224, 224))\n",
    "            # image_sizeëŠ” transformê³¼ ë™ì¼í•˜ê²Œ 224x224\n",
    "        else:   # bboxê°€ ì—†ë‹¤ë©´ ì „ë¶€ 0ìœ¼ë¡œ ì±„ì›Œì§„ ë§ˆìŠ¤í¬ ìƒì„± -> MGA Loss ê³„ì‚° ì‹œ ì°¸ê³ ìš©ìœ¼ë¡œ ì“°ì¼ ìˆ˜ ìˆìŒ\n",
    "            mask = torch.zeros((1, 224, 224), dtype=torch.float32)\n",
    "\n",
    "        return img, torch.tensor(label).long(), mask.squeeze(0)\n",
    "        # ë°˜í™˜ê°’ 3ê°œ :\n",
    "        # img : shape[1, 224, 224]\n",
    "        # label : int(0 or 1)\n",
    "        # mask : [224, 224] <- squeezeë¡œ ì±„ë„ 1ê°œ ì œê±°\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    # ì „ì²´ ë°ì´í„°ì…‹ ê¸¸ì´ ë°˜í™˜ -> DataLoaderê°€ ì•„ë¼ì•¼ ë°°ì¹˜ ìª¼ê°¤ ìˆ˜ ìˆìŒ.\n",
    "\n",
    "# -------------------- CBAM ì •ì˜ (MGA í¬í•¨) --------------------\n",
    "# 2 Step : Channel Attention(ì–´ë–¤ ì±„ë„ì— ì§‘ì¤‘í• ì§€) * Spatial Attention(ì–´ë””ì— ì§‘ì¤‘í• ì§€) = ìµœì¢… Attention\n",
    "\n",
    "class ChannelAttention(nn.Module):  # ì…ë ¥ feature mapì˜ ì±„ë„ë³„ ì¤‘ìš”ë„ë¥¼ ê³„ì‚°í•´ì„œ ê°•ì¡°í•¨\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        # planes : ì…ë ¥ ì±„ë„ ìˆ˜\n",
    "        # ratio : ì¤‘ê°„ ì±„ë„ ì¶•ì†Œ ë¹„ìœ¨. ê¸°ë³¸ 1/16ìœ¼ë¡œ bottlenck êµ¬ì„±\n",
    "        super().__init__()\n",
    "\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        # MLP ì—­í• ì„ í•˜ëŠ” 1x1 conv ë¸”ë¡ -> ì±„ë„ ì••ì¶• -> ë¹„ì„ í˜• -> ë³µì› (sharedëŠ” avg/max ë‘˜ë‹¤ì—ì„œ ê°™ì´ ì”€)\n",
    "\n",
    "        self.avg, self.max, self.sigmoid = nn.AdaptiveAvgPool2d(1), nn.AdaptiveMaxPool2d(1), nn.Sigmoid()\n",
    "        # í‰ê·  í’€ë§ / ìµœëŒ€ í’€ë§ìœ¼ë¡œ ë‘ê°€ì§€ ì „ì—­ ì •ë³´ë¥¼ ì¶”ì¶œ\n",
    "        # ë§ˆì§€ë§‰ sigmoidëŠ” attention weightë¡œ ìŠ¤ì¼€ì¼ë§\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "    # avg & max í’€ë§ ê²½ê³¼ë¥¼ ê°ê° shape MLPì— í†µê³¼ì‹œí‚¤ê³ , ë”í•œ í›„ sigmoid\n",
    "    # -> shape : [B, C, 1, 1]\n",
    "    # -> ì±„ë„ë§ˆë‹¤ ì¤‘ìš”ë„ weightë¥¼ ê³±í•˜ê²Œ ë¨\n",
    "\n",
    "class SpatialAttention(nn.Module):  # ê³µê°„ì ìœ¼ë¡œ ì–´ë””ì— ì§‘ì¤‘í• ì§€ë¥¼ ê²°ì • -> ê° ì±„ë„ ë‚´ë¶€ì—ì„œ ì¤‘ìš”í•œ ìœ„ì¹˜ ì°¾ê¸°\n",
    "\n",
    "    def __init__(self, k=7):    \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    # ì±„ë„ ì°¨ì›ì€ í‰ê· , ìµœëŒ€ ë‘ ê°œë§Œ ì¨ì„œ concat\n",
    "    # ê·¸ê±¸ 1ì±„ë„ë¡œ ì¤„ì—¬ì£¼ëŠ” conv\n",
    "    # ì»¤ë„ í¬ê¸° k=7ì´ë©´ ë„“ì€ ì˜ì—­ê¹Œì§€ ê°ì§€ ê°€ëŠ¥\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg, _max = torch.mean(x, dim=1, keepdim=True), torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "    # ì…ë ¥ feature mapì—ì„œ :\n",
    "    # í‰ê· , ìµœëŒ€ê°’ì„ ê° spatial ìœ„ì¹˜ë³„ë¡œ êµ¬í•¨ -> [B, 1, H, W] ë‘ ê°œ\n",
    "    # concat -> [B, 2, H, w]\n",
    "    # conv + sigmoid -> ìœ„ì¹˜ë³„ ì¤‘ìš”ë„ map\n",
    "\n",
    "class CBAM(nn.Module):  \n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "    # ChannelAttention, SpatialAttentionì„ ë‚´ë¶€ì— ì„ ì–¸\n",
    "    # MGAë¥¼ ìœ„í•´ ë§ˆì§€ë§‰ attention mapì„ ì €ì¥í•˜ëŠ” ë³€ìˆ˜ í¬í•¨\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "    # ì±„ë„ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ìœ„ì¹˜ ì¤‘ìš”ë„ -> ê³±í•¨\n",
    "    # ë‘˜ ë‹¤ ë°˜ì˜ëœ ìµœì¢… feature map ë¦¬í„´\n",
    "\n",
    "# -------------------- ResNet18 + CBAM ëª¨ë¸ ì •ì˜ --------------------\n",
    "# BasicBlockCBAM : ResNetì˜ ê¸°ë³¸ Residual Block í•˜ë‚˜ë¥¼ ì •ì˜\n",
    "# â†’ conv â†’ BN â†’ ReLU â†’ conv â†’ BN â†’ (CBAM optional) â†’ Add â†’ ReLU\n",
    "\n",
    "# ResNet18_CBAM : ResNet18 êµ¬ì¡°ë¡œ ì „ì²´ ë„¤íŠ¸ì›Œí¬ ìŒ“ê¸°\n",
    "# â†’ conv1 â†’ layer1~3 â†’ layer4 â†’ avgpool â†’ fc\n",
    "\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        # ì…ë ¥ ì±„ë„: in_planes, ì¶œë ¥ ì±„ë„: out_planes, 3x3 ì»¤ë„, padding=1ë¡œ í¬ê¸° ìœ ì§€, strideë¡œ í¬ê¸° ì¡°ì ˆ\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)   # ë°°ì¹˜ ì •ê·œí™”\n",
    "        self.relu = nn.ReLU()   # ë¹„ì„ í˜• í™œì„±í™” í•¨ìˆ˜\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        # ë‘ë²ˆì§¸ conv, ì±„ë„ ìˆ˜ ìœ ì§€, í¬ê¸° ìœ ì§€\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)   # ë°°ì¹˜ ì •ê·œí™”\n",
    "\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None  # CBAM ëª¨ë“ˆ ì‚¬ìš© ì—¬ë¶€\n",
    "        self.downsample = downsample    # residual ì—°ê²° ì‹œ ì°¨ì› ë§ì¶”ëŠ” conv\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x    # skip connectionìš© ì…ë ¥ ì €ì¥\n",
    "\n",
    "        out = self.conv1(x) # ì²« ë²ˆì§¸ conv\n",
    "        out = self.bn1(out) # ì •ê·œí™”\n",
    "        out = self.relu(out)  # í™œì„±í™”\n",
    "\n",
    "        out = self.conv2(out)   # ë‘ ë²ˆì§¸ conv\n",
    "        out = self.bn2(out) # ì •ê·œí™”\n",
    "\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)    # CBAM ì ìš©\n",
    "\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)   # shortcut ê²½ë¡œ ë³´ì •\n",
    "\n",
    "        out += residual # skip connection\n",
    "        out = self.relu(out)    # ì¶œë ¥ì— ReLU ì ìš©\n",
    "\n",
    "        return out  # ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64 # ì¡°ê¸° ì…ë ¥ ì±„ë„ ìˆ˜ ì„¤ì •\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # ì…ë ¥: [B, 1, 224, 224] -> ì¶œë ¥: [B, 64, 112, 112], í° ì»¤ë„ë¡œ ë„“ì€ ì˜ì—­ ìº¡ì²˜ \n",
    "        self.bn1 = nn.BatchNorm2d(64)   # ì •ê·œí™”\n",
    "        self.relu = nn.ReLU()   # í™œì„±í™”\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # í’€ë§: [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        self.layer1 = self._make_layer(64, blocks=2)  # [B, 64, 56, 56] ìœ ì§€\n",
    "        self.layer2 = self._make_layer(128, blocks=2, stride=2)  # [B, 128, 28, 28] ë‹¤ìš´ìƒ˜í”Œë§\n",
    "        self.layer3 = self._make_layer(256, blocks=2, stride=2)  # [B, 256, 14, 14] ë‹¤ìš´ìƒ˜í”Œë§\n",
    "        self.layer4 = self._make_layer(512, blocks=2, stride=2, use_cbam=False)  # [B, 512, 7, 7], CBAM ë¯¸ì‚¬ìš©\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # [B, 512, 7, 7] -> [B, 512, 1, 1]\n",
    "        self.fc = nn.Linear(512, num_classes)  # [B, 512] -> [B, num_classes]\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        # Planes : í•´ë‹¹ ë ˆì´ì–´ì˜ ì¶œë ¥ ì±„ë„ ìˆ˜\n",
    "        # # blocks : ë¸”ë¡ ìˆ˜\n",
    "        # stride=2ì¸ ê²½ìš° ë‹¤ìš´ìƒ˜í”Œë§ (í•´ìƒë„ ì ˆë°˜)\n",
    "\n",
    "        downsample = None   # ìŠ¤í‚µ ì—°ê²°í•´ì„œ ì…ë ¥/ì¶œë ¥ í¬ê¸°ê°€ ë‹¤ë¥´ë©´ ë§ì¶°ì•¼ í•¨\n",
    "\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                # 1x1 convë¡œ ì±„ë„ ìˆ˜   ë° ê³µê°„ í¬ê¸° ë§ì¶¤\n",
    "                nn.BatchNorm2d(planes))\n",
    "            \n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam=use_cbam)]\n",
    "        # ì²« ë¸”ë¡ì€ ë‹¤ìš´ìƒ˜í”Œë§ ì ìš© ê°€ëŠ¥ì„± ìˆìŒ\n",
    "        self.in_planes = planes # ì´í›„ ë¸”ë¡ì„ ìœ„í•œ ì…ë ¥ ì±„ë„ ì—…ë°ì´íŠ¸\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "            # ë‚˜ë¨¸ì§€ ë¸”ë¡ì€ stride=1ë¡œ ë™ì¼í•œ í•´ìƒë„ ìœ ì§€\n",
    "\n",
    "        return nn.Sequential(*layers)   # ë¸”ë¡ë“¤ì„ Seguentialë¡œ ë¬¶ì–´ ë°˜í™˜\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  # ì…ë ¥: [B, 1, 224, 224] -> [B, 64, 112, 112]\n",
    "        x = self.bn1(x)    # ì •ê·œí™”\n",
    "        x = self.relu(x)   # ReLU í™œì„±í™”\n",
    "        x = self.maxpool(x)  # [B, 64, 112, 112] -> [B, 64, 56, 56]\n",
    "\n",
    "        x = self.layer1(x)  # [B, 64, 56, 56]\n",
    "        x = self.layer2(x)  # [B, 128, 28, 28]\n",
    "        x = self.layer3(x)  # [B, 256, 14, 14]\n",
    "        x = self.layer4(x)  # [B, 512, 7, 7]\n",
    "\n",
    "        x = self.avgpool(x)  # [B, 512, 1, 1]\n",
    "        x = torch.flatten(x, 1)  # [B, 512]\n",
    "        x = self.fc(x)  # [B, num_classes]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# -------------------- í•™ìŠµ ë£¨í”„ --------------------\n",
    "def run():\n",
    "    # ëª¨ë“  CT ìŠ¬ë¼ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ ë¶ˆëŸ¬ì˜¤ê¸° (LIDC-IDRI í™˜ì í´ë” ì•ˆì˜ .npy íŒŒì¼ë“¤)\n",
    "    all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "\n",
    "    # íŒŒì¼ ê²½ë¡œì™€ í•´ë‹¹ íŒŒì¼ì˜ ë¼ë²¨ì„ íŠœí”Œë¡œ ì €ì¥\n",
    "    file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "    # ë¼ë²¨ì´ Noneì´ ì•„ë‹Œ ë°ì´í„°ë§Œ í•„í„°ë§ (ì¤‘ë¦½ ì œì™¸)\n",
    "    file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "\n",
    "    # íŒŒì¼, ë¼ë²¨ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬\n",
    "    files, labels = zip(*file_label_pairs)\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„°ë¥¼ train(70%), val(15%), test(15%)ë¡œ ë¶„í• \n",
    "    train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "    val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    train_dataset = CTDataset(train_files, train_labels, transform=train_transform)\n",
    "    val_dataset = CTDataset(val_files, val_labels, transform=val_transform)\n",
    "    test_dataset = CTDataset(test_files, test_labels, transform=val_transform)\n",
    "\n",
    "    # ë°ì´í„° ë¡œë”\n",
    "    train_loader = DataLoader(train_dataset,  batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
    "    model = ResNet18_CBAM().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    best_acc = 0.0  # ê°€ì¥ ë†’ì€ val accuracyë¥¼ ì €ì¥\n",
    "    save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"r18_cbam_mga_aug_lr4_ep100_1t.pth\")\n",
    "\n",
    "    # í•™ìŠµ ë£¨í”„ ì‹œì‘\n",
    "    for epoch in range(num_epochs):\n",
    "        # MGA ìŠ¤ì¼€ì¥´ë§: ì´ˆê¸° lambda -> ì ì  ì¦ê°€ì‹œí‚´\n",
    "        lambda_mga = initial_lambda + (final_lambda - initial_lambda) * (epoch / total_epochs)\n",
    "\n",
    "        model.train()  # í•™ìŠµ ëª¨ë“œë¡œ ë³€ê²½\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # í•œ epoch ë™ì•ˆ ëª¨ë“  train ë°ì´í„°ë¥¼ í•™ìŠµ\n",
    "        for images, labels, masks in tqdm(train_loader, desc=f\"[Epoch {epoch+1}]\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)  # forward pass\n",
    "            ce_loss = criterion(outputs, labels)  # cross entropy loss\n",
    "\n",
    "            # -------------------- MGA Loss ê³„ì‚° ìœ„ì¹˜ --------------------\n",
    "            attn_map = model.layer3[1].cbam.last_attention  # attention map êº¼ë‚´ì˜¤ê¸°\n",
    "\n",
    "            if attn_map is not None:\n",
    "                attn_map = F.interpolate(attn_map, size=(224, 224), mode='bilinear', align_corners=False).squeeze(1)\n",
    "                attn_loss = F.mse_loss(attn_map, masks)  # maskì™€ì˜ MSE loss\n",
    "                loss = ce_loss + lambda_mga * attn_loss\n",
    "            else:\n",
    "                loss = ce_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = outputs.max(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Train Acc: {(correct/total)*100:.4f}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "        print(f\"[Epoch {epoch+1}] lambda_mga: {lambda_mga:.4f}\")\n",
    "\n",
    "        torch.cuda.empty_cache(); gc.collect()  # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "\n",
    "        # -------------------- ê²€ì¦ --------------------\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for iamegs, labels, masks in val_loader:\n",
    "                iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "                outputs = model(iamegs)\n",
    "                _, preds = outputs.max(1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "        print(f\"Val Acc: {val_acc:.4f}\")\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(\"âœ… Saved best model!\")\n",
    "\n",
    "    # -------------------- í…ŒìŠ¤íŠ¸ --------------------\n",
    "    print(\"\\nğŸ“Š Test Evaluation:\")\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model.eval()\n",
    "    y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for iamegs, labels, masks in test_loader:\n",
    "            iamegs, labels, masks = iamegs.to(device), labels.to(device), masks.to(device)\n",
    "            outputs = model(iamegs)\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1]\n",
    "            preds = outputs.argmax(1)\n",
    "            y_probs.extend(probs.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "    # ìµœì¢… í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶œë ¥\n",
    "    print(f\"âœ… Test Accuracy: {(np.array(y_pred) == np.array(y_true)).mean() * 100:.2f}%\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "    print(f\"AUC: {roc_auc_score(y_true, y_probs):.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# ì§„ì…ì \n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
