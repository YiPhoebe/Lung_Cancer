{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-Cam\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from torchvision.models import (\n",
    "    resnet34 as resnet34_fn,\n",
    "    densenet121 as densenet121_fn,\n",
    "    efficientnet_b0 as efficientnet_b0_fn,\n",
    "    ResNet34_Weights,\n",
    "    DenseNet121_Weights,\n",
    "    EfficientNet_B0_Weights\n",
    ")\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_models():\n",
    "    m1 = resnet34_fn(weights=ResNet34_Weights.IMAGENET1K_V1)\n",
    "    m1.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    m1.fc = nn.Linear(m1.fc.in_features, 1)\n",
    "    m1.load_state_dict(torch.load(\"best_model_resnet34.pth\"))\n",
    "    m1.to(DEVICE).eval()\n",
    "\n",
    "    m2 = densenet121_fn(weights=DenseNet121_Weights.IMAGENET1K_V1)\n",
    "    m2.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    m2.classifier = nn.Linear(m2.classifier.in_features, 1)\n",
    "    m2.load_state_dict(torch.load(\"best_model_densenet121.pth\"))\n",
    "    m2.to(DEVICE).eval()\n",
    "\n",
    "    m3 = efficientnet_b0_fn(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "    m3.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "    m3.classifier[1] = nn.Linear(m3.classifier[1].in_features, 1)\n",
    "    m3.load_state_dict(torch.load(\"best_model_efficientnet_b0.pth\"))\n",
    "    m3.to(DEVICE).eval()\n",
    "\n",
    "    return m1, m2, m3\n",
    "\n",
    "resnet34_model, densenet_model, effnet_model = load_models()\n",
    "\n",
    "def apply_gradcam(model, image_tensor, target_layer):\n",
    "    model.eval()\n",
    "    image_tensor = image_tensor.unsqueeze(0).to(DEVICE).requires_grad_()\n",
    "    activations, gradients = [], []\n",
    "\n",
    "    def forward_hook(module, input, output): activations.append(output)\n",
    "    def backward_hook(module, grad_in, grad_out): gradients.append(grad_out[0])\n",
    "\n",
    "    f_hook = target_layer.register_forward_hook(forward_hook)\n",
    "    b_hook = target_layer.register_backward_hook(backward_hook)\n",
    "\n",
    "    output = model(image_tensor)\n",
    "    output.backward()\n",
    "\n",
    "    grads = gradients[0]\n",
    "    acts = activations[0]\n",
    "    pooled_grads = torch.mean(grads, dim=(2, 3), keepdim=True)\n",
    "    weighted_acts = pooled_grads * acts\n",
    "    cam = torch.sum(weighted_acts, dim=1).squeeze().cpu().detach().numpy()\n",
    "\n",
    "    cam = np.maximum(cam, 0)\n",
    "    cam = cam / (cam.max() + 1e-8)\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "\n",
    "    f_hook.remove(); b_hook.remove()\n",
    "    return cam\n",
    "\n",
    "def show_all_gradcams(npy_path):\n",
    "    img = np.load(npy_path).astype(np.float32)\n",
    "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "    img_tensor = torch.tensor(img).unsqueeze(0)\n",
    "    img_tensor = F.interpolate(img_tensor.unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "    cam_r = apply_gradcam(resnet34_model, img_tensor, resnet34_model.layer4)\n",
    "    cam_d = apply_gradcam(densenet_model, img_tensor, densenet_model.features.denseblock4)\n",
    "    cam_e = apply_gradcam(effnet_model, img_tensor, effnet_model.features[-1])\n",
    "\n",
    "    original = img_tensor.squeeze().cpu().numpy()\n",
    "    original = np.repeat(original[:, :, None], 3, axis=2)\n",
    "\n",
    "    def overlay(cam):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255\n",
    "        heatmap = heatmap[..., ::-1]\n",
    "        return np.clip(0.4 * heatmap + original, 0, 1)\n",
    "\n",
    "    overlays = [original, overlay(cam_r), overlay(cam_d), overlay(cam_e)]\n",
    "    titles = [\"Original\", \"ResNet34\", \"DenseNet121\", \"EffNet-B0\"]\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    for ax, img, title in zip(axes, overlays, titles):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# üéØ Ïó¨Í∏∞Ïóê 6Ïû• ÎÑ£Ïñ¥ÏÑú Ïã§Ìñâ\n",
    "paths = [\n",
    "    \"/data1/lidc-idri/slices/LIDC-IDRI-0194/slice_078_5.npy\",\n",
    "    \"/data1/lidc-idri/slices/LIDC-IDRI-0332/slice_066_5.npy\",\n",
    "    \"/data1/lidc-idri/slices/LIDC-IDRI-0081/slice_083_5.npy\",\n",
    "    \"/data1/lidc-idri/slices/LIDC-IDRI-0118/slice_028_1.npy\",\n",
    "    \"/data1/lidc-idri/slices/LIDC-IDRI-0426/slice_047_1.npy\",\n",
    "    \"/data1/lidc-idri/slices/LIDC-IDRI-0379/slice_063_2.npy\"\n",
    "]\n",
    "\n",
    "for path in paths:\n",
    "    print(f\"üìå {path}\")\n",
    "    show_all_gradcams(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±\n",
    "# Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨ Î≥ÄÍ≤Ω\n",
    "save_dir = \"./gradcam_outputs\"  # ÌòÑÏû¨ ÏûëÏóÖ ÎîîÎ†âÌÜ†Î¶¨Ïóê Ï†ÄÏû•\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Grad-CAM ÏãúÍ∞ÅÌôî + Ï†ÄÏû• Ìï®Ïàò\n",
    "def save_all_gradcams(npy_path, save_path):\n",
    "    img = np.load(npy_path).astype(np.float32)\n",
    "    img = (img - img.min()) / (img.max() - img.min() + 1e-8)\n",
    "    img_tensor = torch.tensor(img).unsqueeze(0)\n",
    "    img_tensor = F.interpolate(img_tensor.unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "    cam_r = apply_gradcam(resnet34_model, img_tensor, resnet34_model.layer4)\n",
    "    cam_d = apply_gradcam(densenet_model, img_tensor, densenet_model.features.denseblock4)\n",
    "    cam_e = apply_gradcam(effnet_model, img_tensor, effnet_model.features[-1])\n",
    "\n",
    "    original = img_tensor.squeeze().cpu().numpy()\n",
    "    original = np.repeat(original[:, :, None], 3, axis=2)\n",
    "\n",
    "    def overlay(cam):\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
    "        heatmap = np.float32(heatmap) / 255\n",
    "        heatmap = heatmap[..., ::-1]\n",
    "        return np.clip(0.4 * heatmap + original, 0, 1)\n",
    "\n",
    "    overlays = [original, overlay(cam_r), overlay(cam_d), overlay(cam_e)]\n",
    "    titles = [\"Original\", \"ResNet34\", \"DenseNet121\", \"EffNet-B0\"]\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    for ax, img, title in zip(axes, overlays, titles):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(save_path)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Ï†ÄÏû• ÎåÄÏÉÅ ÌååÏùº Í≤ΩÎ°ú\n",
    "gradcam_paths = [\n",
    "    \"/data1/lidc-idri/slices/LIDC-IDRI-0194/slice_078_5.npy\",\n",
    "    \"/data1/lidc-idri/slices/LIDC-IDRI-0332/slice_066_5.npy\",\n",
    "    \"/data1/lidc-idri/slices/LIDC-IDRI-0081/slice_083_5.npy\",\n",
    "    \"/data1/lidc-idri/slices/LIDC-IDRI-0118/slice_028_1.npy\",\n",
    "    \"/data1/lidc-idri/slices/LIDC-IDRI-0426/slice_047_1.npy\",\n",
    "    \"/data1/lidc-idri/slices/LIDC-IDRI-0379/slice_063_2.npy\"\n",
    "]\n",
    "\n",
    "# Ï†ÄÏû• Î£®ÌîÑ\n",
    "for idx, path in enumerate(gradcam_paths):\n",
    "    label = \"malignant\" if idx < 3 else \"benign\"\n",
    "    save_path = os.path.join(save_dir, f\"gradcam_{label}_{idx%3+1}.png\")\n",
    "    save_all_gradcams(path, save_path)\n",
    "\n",
    "# Ï†ÄÏû• ÌôïÏù∏\n",
    "print(\"‚úÖ Ï†ÄÏû• ÏôÑÎ£å!\")\n",
    "print(\"\\nüìÇ Ï†ÄÏû•Îêú ÌååÏùº:\")\n",
    "for f in os.listdir(save_dir):\n",
    "    print(\"‚Ä¢\", f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
