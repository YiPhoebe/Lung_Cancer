{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n",
      "✅ 총 7849개의 파일이 발견되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "추론 중: 100%|██████████| 7849/7849 [09:14<00:00, 14.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CSV 저장 완료! (7849개 항목)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------- 디바이스 설정 --------------------\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# -------------------- CBAM 정의 --------------------\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, planes, ratio=16):\n",
    "        super().__init__()\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Conv2d(planes, planes // ratio, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(planes // ratio, planes, 1, bias=False))\n",
    "        self.avg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max = nn.AdaptiveMaxPool2d(1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.shared(self.avg(x)) + self.shared(self.max(x)))\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, k=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=k, padding=k // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg = torch.mean(x, dim=1, keepdim=True)\n",
    "        _max = torch.max(x, dim=1, keepdim=True)[0]\n",
    "        return self.sigmoid(self.conv(torch.cat([avg, _max], dim=1)))\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, planes):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "        self.last_attention = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        ca_out = self.ca(x) * x\n",
    "        sa_out = self.sa(ca_out)\n",
    "        self.last_attention = sa_out\n",
    "        return sa_out * ca_out\n",
    "\n",
    "# -------------------- ResNet18 + CBAM 정의 --------------------\n",
    "class BasicBlockCBAM(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None, use_cbam=True):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_planes, out_planes, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
    "        self.cbam = CBAM(out_planes) if use_cbam else None\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if self.cbam:\n",
    "            out = self.cbam(out)\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "        return self.relu(out + identity)\n",
    "\n",
    "class ResNet18_CBAM(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.in_planes = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(64, 2)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2, use_cbam=False)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, planes, blocks, stride=1, use_cbam=True):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_planes, planes, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(planes))\n",
    "        layers = [BasicBlockCBAM(self.in_planes, planes, stride, downsample, use_cbam)]\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockCBAM(self.in_planes, planes, use_cbam=use_cbam))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.maxpool(self.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.layer4(self.layer3(self.layer2(self.layer1(x))))\n",
    "        x = self.avgpool(x)\n",
    "        return self.fc(torch.flatten(x, 1))\n",
    "\n",
    "# -------------------- 모델 준비 --------------------\n",
    "model_path = \"/home/iujeong/lung_cancer/pth/r18_cbam_mga_aug_lr4_ep100_weight.pth\"\n",
    "model = ResNet18_CBAM(num_classes=2).to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# -------------------- Transform --------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# -------------------- 데이터 준비 --------------------\n",
    "slice_dir = \"/data1/lidc-idri/slices\"\n",
    "npy_files = sorted(glob(os.path.join(slice_dir, \"**\", \"*.npy\"), recursive=True))\n",
    "print(f\"✅ 총 {len(npy_files)}개의 파일이 발견되었습니다.\")\n",
    "\n",
    "# -------------------- 배치 추론 --------------------\n",
    "results = []\n",
    "batch_images = []\n",
    "batch_paths = []\n",
    "\n",
    "for idx, f in enumerate(tqdm(npy_files, desc=\"추론 중\")):\n",
    "    try:\n",
    "        img = np.load(f)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.0\n",
    "        img = np.expand_dims(img, axis=-1).astype(np.float32)\n",
    "        img = transform(img)\n",
    "        batch_images.append(img)\n",
    "        batch_paths.append(f)\n",
    "\n",
    "        if len(batch_images) == batch_size or idx == len(npy_files) - 1:\n",
    "            batch_tensor = torch.stack(batch_images).to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(batch_tensor)\n",
    "                probs = F.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "            for path, prob in zip(batch_paths, probs):\n",
    "                file_id = os.path.relpath(path, slice_dir).replace(\"/\", \"_\").replace(\".npy\", \"\")\n",
    "                results.append({\"id\": file_id, \"cancer\": float(prob)})\n",
    "            batch_images = []\n",
    "            batch_paths = []\n",
    "    except Exception as e:\n",
    "        print(f\"[!] 오류 발생: {f} → {e}\")\n",
    "\n",
    "# -------------------- CSV 저장 --------------------\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"submission.csv\", index=False)\n",
    "print(f\"✅ CSV 저장 완료! ({len(results)}개 항목)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
