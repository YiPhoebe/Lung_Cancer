{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import gc\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "slice_root = \"/data1/lidc-idri/slices\"\n",
    "batch_size = 16\n",
    "num_epoch = 1\n",
    "learning_rate = 1e-4\n",
    "\n",
    "# 레이블 추출\n",
    "def labels_filename(fname):\n",
    "    try:\n",
    "        score = int(fname.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        return None  if score == 3 else int(score >= 4)\n",
    "    \n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "# 데이터셋 전처리\n",
    "class LIDCDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        file_path = self.file_paths[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        img = np.load(file_path).astype(np.float32)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img_tensor = torch.tensor(img)\n",
    "\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img_tensor)\n",
    "\n",
    "        return img_tensor, torch.tensor(label).float()\n",
    "\n",
    "\n",
    "# 데이터 증강\n",
    "augmentation_configs = {\n",
    "    'baseline': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.CenterCrop(180),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "\n",
    "    'flip_rotate': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.CenterCrop(180),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "\n",
    "    'blur': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.CenterCrop(180),\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "\n",
    "    'total': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.CenterCrop(180),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "}\n",
    "\n",
    "# 데이터 불러오기\n",
    "def get_model(name):\n",
    "    if name == \"resnet18\":\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "    elif name == \"resnet34\":\n",
    "        model = models.resnet34(pretrained=True)\n",
    "        model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        model.fc = nn.Linear(model.fc.in_features, 1)\n",
    "\n",
    "    elif name == \"densenet121\":\n",
    "        model = models.densenet121(pretrained=True)\n",
    "        model.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
    "\n",
    "    elif name == \"efficientnet_b0\":\n",
    "        model = models.efficientnet_b0(pretrained=True)\n",
    "        model.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model name\")\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "# 데이터 로더\n",
    "all_files = glob(os.path.join(slice_root, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "\n",
    "file_label_pairs = [(f, labels_filename(f)) for f in all_files]\n",
    "file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "files, labels = zip(*file_label_pairs)\n",
    "\n",
    "train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "results = defaultdict(dict)\n",
    "model_names = [\"resnet18\", \"resnet34\", \"densenet121\", \"efficientnet_b0\"]\n",
    "\n",
    "for model_name in model_names:\n",
    "    for aug_name, transform in augmentation_configs.items():\n",
    "        print(f\"\\n Running: {model_name} + {aug_name}\")\n",
    "\n",
    "        train_dataset = LIDCDataset(train_files, train_labels, transform)\n",
    "        val_dataset = LIDCDataset(val_files, val_labels, transform)\n",
    "        test_dataset = LIDCDataset(test_files, test_labels, transform)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "        model = get_model(model_name)\n",
    "\n",
    "# loss, optimizer 설정\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# 반복문\n",
    "        best_val_acc = 0.0\n",
    "\n",
    "        # --- 저장 경로 및 변수 초기화 ---\n",
    "        save_dir = os.path.join(os.path.dirname(os.getcwd()), \"pth\")\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        best_val_acc = 0.0\n",
    "\n",
    "        for epoch in range(num_epoch):\n",
    "            model.train()\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            epoch_loss = 0\n",
    "\n",
    "            for images, labels in train_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.unsqueeze(1).to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                predicted = (torch.sigmoid(outputs) > 0.5).long()\n",
    "                correct += (predicted == labels.long()).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "            train_acc = correct / total\n",
    "            print(f\"[{model_name} + {aug_name}] Epoch: {epoch+1}/{num_epoch} Train Acc: {train_acc * 100:.4f}%\")\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            val_correct = 0\n",
    "            val_total = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for images, labels in val_loader:\n",
    "                    images = images.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = model(images)\n",
    "\n",
    "                    predicted = (torch.sigmoid(outputs) > 0.5).squeeze().long()\n",
    "                    val_correct += (predicted == labels.long()).sum().item()\n",
    "                    val_total += labels.size(0)\n",
    "\n",
    "            val_acc = val_correct / val_total\n",
    "            print(f\"[{model_name} + {aug_name}] Epoch {epoch+1}/{num_epoch} Val Acc {val_acc * 100:.4f}%\")\n",
    "\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(model.state_dict(), os.path.join(save_dir, f\"best_aug_{model_name}_{aug_name}.pth\"))\n",
    "\n",
    "\n",
    "        model.load_state_dict(torch.load(os.path.join(save_dir, f\"best_aug_{model_name}_{aug_name}.pth\")))\n",
    "        model.eval()\n",
    "\n",
    "        y_true, y_pred, y_probs = [], [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                probs = torch.sigmoid(outputs).squeeze()\n",
    "                preds = (probs > 0.5).long()\n",
    "\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(preds.cpu().numpy())\n",
    "                y_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "        acc = (np.array(y_true) == np.array(y_pred)).mean()\n",
    "        auc = roc_auc_score(y_true, y_probs)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        results[model_name][aug_name] = {\"acc\": acc, \"auc\": auc, \"cm\": cm}\n",
    "        print(f\"✅ Test Acc: {acc:.4f}, AUC: {auc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
