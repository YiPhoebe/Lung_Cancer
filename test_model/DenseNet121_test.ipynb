{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Densenet121\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- ÏÑ§Ï†ï ---\n",
    "SLICE_ROOT = \"/data1/lidc-idri/slices\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 100\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- ÌååÏùº Î¶¨Ïä§Ìä∏ Î∞è ÎùºÎ≤® ÏÉùÏÑ± ---\n",
    "def extract_label_from_filename(filename):\n",
    "    try:\n",
    "        score = int(filename.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        if score == 3:\n",
    "            return None\n",
    "        return 1 if score >= 4 else 0\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "all_files = glob(os.path.join(SLICE_ROOT, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "\n",
    "files, labels = zip(*file_label_pairs)\n",
    "train_files, val_files, train_labels, val_labels = train_test_split(\n",
    "    files, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Transform ---\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# --- Dataset Ï†ïÏùò ---\n",
    "class LIDCDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        img = np.load(file_path).astype(np.float32)\n",
    "        img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-8)\n",
    "        img = np.expand_dims(img, axis=0)  # (1, H, W)\n",
    "        img_tensor = torch.tensor(img)\n",
    "\n",
    "        # Resize to (1, 224, 224)\n",
    "        img_tensor = F.interpolate(img_tensor.unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img_tensor)\n",
    "\n",
    "        return img_tensor, torch.tensor(label).float()\n",
    "\n",
    "# --- DataLoader ---\n",
    "train_dataset = LIDCDataset(train_files, train_labels, transform=train_transform)\n",
    "val_dataset = LIDCDataset(val_files, val_labels, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# --- Î™®Îç∏ Ï†ïÏùò ---\n",
    "model = densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1)\n",
    "model.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 1)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# --- ÌïôÏäµ Î£®ÌîÑ ---\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.unsqueeze(1).to(DEVICE)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # --- Í≤ÄÏ¶ù ---\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).squeeze().long()\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "            correct += (preds == labels.long()).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    acc = correct / total\n",
    "    print(f\"Validation Accuracy: {acc:.4f}\")\n",
    "\n",
    "    if acc > best_val_acc:\n",
    "        best_val_acc = acc\n",
    "        torch.save(model.state_dict(), \"best_model_densenet121.pth\")\n",
    "        print(\"‚úÖ Best model saved!\")\n",
    "\n",
    "# --- Î¶¨Ìè¨Ìä∏ Ï∂úÎ†• ---\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
