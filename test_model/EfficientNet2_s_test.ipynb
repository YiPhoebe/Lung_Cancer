{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import timm  # pip install timm\n",
    "\n",
    "# --- 설정 ---\n",
    "SLICE_ROOT = \"/data1/lidc-idri/slices\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 10\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- 라벨 추출 함수 ---\n",
    "def extract_label_from_filename(filename):\n",
    "    try:\n",
    "        score = int(filename.split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "        if score == 3:\n",
    "            return None\n",
    "        return 1 if score >= 4 else 0\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# --- 3-way split ---\n",
    "all_files = glob(os.path.join(SLICE_ROOT, \"LIDC-IDRI-*\", \"*.npy\"))\n",
    "file_label_pairs = [(f, extract_label_from_filename(f)) for f in all_files]\n",
    "file_label_pairs = [(f, l) for f, l in file_label_pairs if l is not None]\n",
    "files, labels = zip(*file_label_pairs)\n",
    "\n",
    "train_files, temp_files, train_labels, temp_labels = train_test_split(files, labels, test_size=0.3, random_state=42)\n",
    "val_files, test_files, val_labels, test_labels = train_test_split(temp_files, temp_labels, test_size=0.5, random_state=42)\n",
    "\n",
    "# --- Dataset ---\n",
    "class LIDCDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = np.load(self.file_paths[idx]).astype(np.float32)\n",
    "        img = np.clip(img, -1000, 400)\n",
    "        img = (img + 1000) / 1400.0\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = np.expand_dims(img, 0)\n",
    "        img_tensor = torch.tensor(img)\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img_tensor)\n",
    "        label = torch.tensor(self.labels[idx]).float()\n",
    "        return img_tensor, label, self.file_paths[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "# --- Transform ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# --- DataLoader ---\n",
    "train_loader = DataLoader(LIDCDataset(train_files, train_labels, transform=transform), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(LIDCDataset(val_files, val_labels, transform=transform), batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(LIDCDataset(test_files, test_labels, transform=transform), batch_size=BATCH_SIZE)\n",
    "\n",
    "# --- 모델 정의 ---\n",
    "model = timm.create_model(\"efficientnetv2_s\", pretrained=False, in_chans=1, num_classes=1)\n",
    "model.to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "save_path = os.path.join(os.path.dirname(os.getcwd()), \"pth\", \"best_model_effnetv2s.pth\")\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "# --- 학습 ---\n",
    "best_val_acc = 0.0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, labels, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{NUM_EPOCHS}\"):\n",
    "        images, labels = images.to(DEVICE), labels.unsqueeze(1).to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"[Epoch {epoch+1}] Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # --- 검증 ---\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images).squeeze()\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > 0.5).long()\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "            correct += (preds == labels.long()).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_acc = correct / total\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(\"✅ Best model saved!\")\n",
    "\n",
    "# --- 테스트 ---\n",
    "print(\"\\n📊 Test Set Evaluation (Best Model 기준):\")\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "model.eval()\n",
    "y_true, y_pred, y_probs = [], [], []\n",
    "with torch.no_grad():\n",
    "    for images, labels, _ in test_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(images).squeeze()\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).long()\n",
    "        y_probs.extend(probs.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "\n",
    "test_acc = (np.array(y_pred) == np.array(y_true)).mean() * 100\n",
    "print(f\"✅ Test Accuracy: {test_acc:.2f}%\")\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "try:\n",
    "    auc_score = roc_auc_score(y_true, y_probs)\n",
    "    print(f\"AUC: {auc_score:.4f}\")\n",
    "except ValueError:\n",
    "    print(\"AUC 계산 실패: 클래스가 모두 있어야 합니다.\")\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
