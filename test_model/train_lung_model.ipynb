{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏûÑÏãú Îç∞Ïù¥ÌÑ∞ Ï†ÑÏö© ÏΩîÎìú ÌÖåÏä§Ìä∏ Î™®Îìú: ÏÑ±Îä• ÏûêÎèô ÏßÑÎã® Ìè¨Ìï®\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lung_nodule_dataset import LungNoduleSliceDataset\n",
    "\n",
    "# ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 3\n",
    "\n",
    "# Ïª§Ïä§ÌÖÄ Î™®Îç∏\n",
    "class LungCancerClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        self.base_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Sequential(nn.Linear(num_features, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è ÎùºÎ≤® ÌôïÏù∏\n",
    "csv_path = \"/data2/lijin/lidc-prep/nodule_matched.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df['binary_label'] = df['malignancy'].astype(int)\n",
    "print(\"‚úÖ Ï†ÑÏ≤¥ ÎùºÎ≤® Î∂ÑÌè¨:\")\n",
    "print(df['binary_label'].value_counts())\n",
    "\n",
    "# Stratified split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['binary_label'], random_state=42)\n",
    "print(\"‚úÖ Î∂ÑÌï† ÌõÑ ÎùºÎ≤® Î∂ÑÌè¨:\")\n",
    "print(\"Train:\", train_df['binary_label'].value_counts())\n",
    "print(\"Test:\", test_df['binary_label'].value_counts())\n",
    "\n",
    "# Ï¶ùÍ∞ï\n",
    "a_train = A.Compose([A.HorizontalFlip(p=0.7), A.RandomBrightnessContrast(p=0.5), A.Rotate(limit=15, p=0.5)])\n",
    "a_test = A.Compose([])\n",
    "\n",
    "# Dataset\n",
    "train_dataset = LungNoduleSliceDataset(df=train_df, image_root=\"/data2/lijin/lidc-prep/LIDC-IDRI-slices\", transform=a_train)\n",
    "test_dataset = LungNoduleSliceDataset(df=test_df, image_root=\"/data2/lijin/lidc-prep/LIDC-IDRI-slices\", transform=a_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Î™®Îç∏ ÏÑ∏ÌåÖ\n",
    "model = LungCancerClassifier().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# ÌõàÎ†® + ÌèâÍ∞Ä Î£®ÌîÑ\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Train Loss: {total_loss / len(train_loader):.4f}, Accuracy: {(correct/total)*100:.2f}%\")\n",
    "\n",
    "    # ÌèâÍ∞Ä\n",
    "    model.eval()\n",
    "    all_preds, all_probs, all_labels = [], [], []\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device).float()\n",
    "            labels = labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            probs = outputs.cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "\n",
    "            all_preds.extend(preds.flatten())\n",
    "            all_probs.extend(probs.flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    # ÏÑ±Îä• ÏßÄÌëú Ï∂úÎ†•\n",
    "    try:\n",
    "        f1 = f1_score(all_labels, all_preds)\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "        print(f\"‚úÖ [Epoch {epoch+1}] Test Loss: {test_loss / len(test_loader):.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "    except ValueError as e:\n",
    "        print(\"‚ö†Ô∏è  ÏßÄÌëú Í≥ÑÏÇ∞ Ïã§Ìå®:\", str(e))\n",
    "\n",
    "    print(\"üìä ÎùºÎ≤® Î∂ÑÌè¨:\", np.unique(all_labels, return_counts=True))\n",
    "    print(\"üìà ÏòàÏ∏° Î∂ÑÌè¨:\", np.unique(all_preds, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Î™®Îç∏ Ïã§Ìóò Ïä§ÌÅ¨Î¶ΩÌä∏ (EfficientNet-B0 / DenseNet121 / ResNet34 / ResNet50)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lung_nodule_dataset import LungNoduleSliceDataset\n",
    "\n",
    "# ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 3\n",
    "\n",
    "# Î™®Îç∏ Î°úÎî© Ìï®Ïàò\n",
    "def get_model(name):\n",
    "    if name == 'resnet34':\n",
    "        base = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "        base.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_ftrs = base.fc.in_features\n",
    "        base.fc = nn.Sequential(nn.Linear(num_ftrs, 1), nn.Sigmoid())\n",
    "\n",
    "    elif name == 'resnet50':\n",
    "        base = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        base.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_ftrs = base.fc.in_features\n",
    "        base.fc = nn.Sequential(nn.Linear(num_ftrs, 1), nn.Sigmoid())\n",
    "\n",
    "    elif name == 'densenet121':\n",
    "        base = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "        base.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_ftrs = base.classifier.in_features\n",
    "        base.classifier = nn.Sequential(nn.Linear(num_ftrs, 1), nn.Sigmoid())\n",
    "\n",
    "    elif name == 'efficientnet_b0':\n",
    "        base = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        base.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        num_ftrs = base.classifier[1].in_features\n",
    "        base.classifier = nn.Sequential(nn.Linear(num_ftrs, 1), nn.Sigmoid())\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {name}\")\n",
    "    \n",
    "    return base\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î°úÎî© Î∞è Ï†ÑÏ≤òÎ¶¨\n",
    "csv_path = \"/data2/lijin/lidc-prep/nodule_matched.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df['binary_label'] = df['malignancy'].astype(int)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['binary_label'], random_state=42)\n",
    "\n",
    "a_train = A.Compose([A.HorizontalFlip(p=0.7), A.RandomBrightnessContrast(p=0.5), A.Rotate(limit=15, p=0.5)])\n",
    "a_test = A.Compose([])\n",
    "\n",
    "train_dataset = LungNoduleSliceDataset(df=train_df, image_root=\"/data2/lijin/lidc-prep/LIDC-IDRI-slices\", transform=a_train)\n",
    "test_dataset = LungNoduleSliceDataset(df=test_df, image_root=\"/data2/lijin/lidc-prep/LIDC-IDRI-slices\", transform=a_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# ÏÑ±Îä• Í∏∞Î°ù\n",
    "df_results = []\n",
    "\n",
    "# Î™®Îç∏Î≥Ñ Ïã§Ìóò Î∞òÎ≥µ\n",
    "model_names = ['resnet34', 'resnet50', 'densenet121', 'efficientnet_b0']\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"\\nüöÄ ÏãúÏûë: {model_name}\")\n",
    "    model = get_model(model_name).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device).float()\n",
    "            labels = labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {total_loss / len(train_loader):.4f}, Accuracy: {(correct/total)*100:.2f}%\")\n",
    "\n",
    "    # ÌÖåÏä§Ìä∏ ÌèâÍ∞Ä\n",
    "    model.eval()\n",
    "    all_preds, all_probs, all_labels = [], [], []\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device).float()\n",
    "            labels = labels.to(device).float().unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            probs = outputs.cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            all_preds.extend(preds.flatten())\n",
    "            all_probs.extend(probs.flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    print(f\"‚úÖ {model_name}: Test Loss: {avg_test_loss:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "    df_results.append({\"model\": model_name, \"f1\": f1, \"auc\": auc, \"test_loss\": avg_test_loss})\n",
    "\n",
    "# Í≤∞Í≥º Ï∂úÎ†•\n",
    "print(\"\\nüìä Î™®Îç∏Î≥Ñ Í≤∞Í≥º ÎπÑÍµê:\")\n",
    "df_results = pd.DataFrame(df_results)\n",
    "print(df_results.sort_values(by=\"f1\", ascending=False).reset_index(drop=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
