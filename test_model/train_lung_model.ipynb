{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임시 데이터 전용 코드 테스트 모드: 성능 자동 진단 포함\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lung_nodule_dataset import LungNoduleSliceDataset\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 3\n",
    "\n",
    "# 커스텀 모델\n",
    "class LungCancerClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        self.base_model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Sequential(nn.Linear(num_features, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n",
    "\n",
    "# 데이터 로드 및 라벨 확인\n",
    "csv_path = \"/data2/lijin/lidc-prep/nodule_matched.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df['binary_label'] = df['malignancy'].astype(int)\n",
    "print(\"✅ 전체 라벨 분포:\")\n",
    "print(df['binary_label'].value_counts())\n",
    "\n",
    "# Stratified split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['binary_label'], random_state=42)\n",
    "print(\"✅ 분할 후 라벨 분포:\")\n",
    "print(\"Train:\", train_df['binary_label'].value_counts())\n",
    "print(\"Test:\", test_df['binary_label'].value_counts())\n",
    "\n",
    "# 증강\n",
    "a_train = A.Compose([A.HorizontalFlip(p=0.7), A.RandomBrightnessContrast(p=0.5), A.Rotate(limit=15, p=0.5)])\n",
    "a_test = A.Compose([])\n",
    "\n",
    "# Dataset\n",
    "train_dataset = LungNoduleSliceDataset(df=train_df, image_root=\"/data2/lijin/lidc-prep/LIDC-IDRI-slices\", transform=a_train)\n",
    "test_dataset = LungNoduleSliceDataset(df=test_df, image_root=\"/data2/lijin/lidc-prep/LIDC-IDRI-slices\", transform=a_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 모델 세팅\n",
    "model = LungCancerClassifier().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 훈련 + 평가 루프\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Train Loss: {total_loss / len(train_loader):.4f}, Accuracy: {(correct/total)*100:.2f}%\")\n",
    "\n",
    "    # 평가\n",
    "    model.eval()\n",
    "    all_preds, all_probs, all_labels = [], [], []\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device).float()\n",
    "            labels = labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            probs = outputs.cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "\n",
    "            all_preds.extend(preds.flatten())\n",
    "            all_probs.extend(probs.flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "    # 성능 지표 출력\n",
    "    try:\n",
    "        f1 = f1_score(all_labels, all_preds)\n",
    "        auc = roc_auc_score(all_labels, all_probs)\n",
    "        print(f\"✅ [Epoch {epoch+1}] Test Loss: {test_loss / len(test_loader):.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "    except ValueError as e:\n",
    "        print(\"⚠️  지표 계산 실패:\", str(e))\n",
    "\n",
    "    print(\"📊 라벨 분포:\", np.unique(all_labels, return_counts=True))\n",
    "    print(\"📈 예측 분포:\", np.unique(all_preds, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 실험 스크립트 (EfficientNet-B0 / DenseNet121 / ResNet34 / ResNet50)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lung_nodule_dataset import LungNoduleSliceDataset\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 16\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 3\n",
    "\n",
    "# 모델 로딩 함수\n",
    "def get_model(name):\n",
    "    if name == 'resnet34':\n",
    "        base = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "        base.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_ftrs = base.fc.in_features\n",
    "        base.fc = nn.Sequential(nn.Linear(num_ftrs, 1), nn.Sigmoid())\n",
    "\n",
    "    elif name == 'resnet50':\n",
    "        base = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        base.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_ftrs = base.fc.in_features\n",
    "        base.fc = nn.Sequential(nn.Linear(num_ftrs, 1), nn.Sigmoid())\n",
    "\n",
    "    elif name == 'densenet121':\n",
    "        base = models.densenet121(weights=models.DenseNet121_Weights.DEFAULT)\n",
    "        base.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        num_ftrs = base.classifier.in_features\n",
    "        base.classifier = nn.Sequential(nn.Linear(num_ftrs, 1), nn.Sigmoid())\n",
    "\n",
    "    elif name == 'efficientnet_b0':\n",
    "        base = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        base.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        num_ftrs = base.classifier[1].in_features\n",
    "        base.classifier = nn.Sequential(nn.Linear(num_ftrs, 1), nn.Sigmoid())\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {name}\")\n",
    "    \n",
    "    return base\n",
    "\n",
    "# 데이터 로딩 및 전처리\n",
    "csv_path = \"/data2/lijin/lidc-prep/nodule_matched.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df['binary_label'] = df['malignancy'].astype(int)\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['binary_label'], random_state=42)\n",
    "\n",
    "a_train = A.Compose([A.HorizontalFlip(p=0.7), A.RandomBrightnessContrast(p=0.5), A.Rotate(limit=15, p=0.5)])\n",
    "a_test = A.Compose([])\n",
    "\n",
    "train_dataset = LungNoduleSliceDataset(df=train_df, image_root=\"/data2/lijin/lidc-prep/LIDC-IDRI-slices\", transform=a_train)\n",
    "test_dataset = LungNoduleSliceDataset(df=test_df, image_root=\"/data2/lijin/lidc-prep/LIDC-IDRI-slices\", transform=a_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 성능 기록\n",
    "df_results = []\n",
    "\n",
    "# 모델별 실험 반복\n",
    "model_names = ['resnet34', 'resnet50', 'densenet121', 'efficientnet_b0']\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"\\n🚀 시작: {model_name}\")\n",
    "    model = get_model(model_name).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device).float()\n",
    "            labels = labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Loss: {total_loss / len(train_loader):.4f}, Accuracy: {(correct/total)*100:.2f}%\")\n",
    "\n",
    "    # 테스트 평가\n",
    "    model.eval()\n",
    "    all_preds, all_probs, all_labels = [], [], []\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device).float()\n",
    "            labels = labels.to(device).float().unsqueeze(1)\n",
    "            outputs = model(images)\n",
    "            probs = outputs.cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            all_preds.extend(preds.flatten())\n",
    "            all_probs.extend(probs.flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs)\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    print(f\"✅ {model_name}: Test Loss: {avg_test_loss:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "    df_results.append({\"model\": model_name, \"f1\": f1, \"auc\": auc, \"test_loss\": avg_test_loss})\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n📊 모델별 결과 비교:\")\n",
    "df_results = pd.DataFrame(df_results)\n",
    "print(df_results.sort_values(by=\"f1\", ascending=False).reset_index(drop=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lungcancer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
