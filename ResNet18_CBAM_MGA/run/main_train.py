import os
import pandas as pd
from datetime import datetime
from glob import glob
import torch
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split

import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../")))

from ResNet18_CBAM_MGA.core.model import ResNet18_CBAM
from ResNet18_CBAM_MGA.core.dataset import CTDataset, load_bbox_dict, extract_label
from ResNet18_CBAM_MGA.core.transforms import train_transform, val_transform
from ResNet18_CBAM_MGA.train.train_mga import train_one_epoch, validate

from ResNet18_CBAM_MGA.core.config import CFG
CFG.use_mga = False
# CFG.model_save_name = "r18_cbam_sc_weight.pth"
# ì„¤ì • íŒŒì¼ (config.py > CFG)ì—ì„œ MGA ì‚¬ìš© ë¹„í™œì„±í™”

from ResNet18_CBAM_MGA.core.utils import generate_run_name

# ì˜ˆ: MGA O, íšŒì „ X, focal loss, soft class weight
model_name, log_name = generate_run_name(
    mga=False,
    rotate_mask=False,
    loss="ce",
    weight="sc",
    note="no_mask_no_rotate"
) # ì‹¤í—˜ ì„¤ì • ê¸°ë°˜ìœ¼ë¡œ ê³ ìœ  ëª¨ë¸ ì´ë¦„ê³¼ ë¡œê·¸ íŒŒì¼ ì´ë¦„ ìƒì„±

CFG.model_save_name = model_name  # ğŸ“¦ ìë™ ì €ì¥ ê²½ë¡œ
log_path = os.path.join("logs", log_name)

def main(): # ë©”ì¸ í•™ìŠµ í•¨ìˆ˜ ì •ì˜
    # ğŸ”¹ ì‹œë“œ ê³ ì •, ì €ì¥ í´ë” í™•ë³´
    CFG.ensure_dirs()
    os.makedirs("logs", exist_ok=True)
    # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´ ë§Œë“¤ì–´ì¤Œ)

    # ğŸ”¹ ë°ì´í„° ë¡œë”© ë° ë¶„í• 
    all_files = glob(os.path.join(CFG.data_root, "**/*.npy"), recursive=True)
    file_label_pairs = [(f, extract_label(f)) for f in all_files if extract_label(f) is not None]
    # ì „ì²´ CT ìŠ¬ë¼ì´ìŠ¤ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê³ , ë¼ë²¨(score 3 ì œì™¸) ë¶™ì´ê¸°
    files, labels = zip(*file_label_pairs)
    # íŒŒì¼ ê²½ë¡œì™€ ë¼ë²¨ ë¶„ë¦¬

    train_files, val_files, train_labels, val_labels = train_test_split(
        files, labels, test_size=0.2, random_state=CFG.seed
    )   # í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í•  (8:2)
    bbox_dict = load_bbox_dict(CFG.bbox_csv)
    # BBox ì¢Œí‘œ csvë¥¼ dictë¡œ ë¡œë”©

    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    train_dataset = CTDataset(train_files, train_labels, bbox_dict, transform=train_transform)
    val_dataset   = CTDataset(val_files,   val_labels,   bbox_dict, transform=val_transform)

    # ë°ì´í„° ë¡œë” (í•™ìŠµì€ shuffle on, ê²€ì¦ì€ ê³ ì •)
    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True,
                              num_workers=CFG.num_workers, pin_memory=CFG.pin_memory)
    val_loader   = DataLoader(val_dataset,   batch_size=CFG.batch_size, shuffle=False,
                              num_workers=CFG.num_workers, pin_memory=CFG.pin_memory)

    # ğŸ”¹ ëª¨ë¸ ë° í•™ìŠµ ì„¸íŒ…
    model = ResNet18_CBAM(num_classes=CFG.num_classes).to(CFG.device)   # ResNet18 + CBAM ëª¨ë¸ ì •ì˜ ë° GPUë¡œ ë³´ë‚´ê¸°
    criterion = torch.nn.CrossEntropyLoss(weight=torch.tensor([0.6653, 0.3347], device=CFG.device))
    # Soft class weight ì ìš©í•œ CrossEntropyLoss ì •ì˜
    # ì™œ???? ë°ì´í„°ê°€ ë¶ˆê· í˜•í•´ì„œ 
    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.learning_rate)
    # Adam ì˜µí‹°ë§ˆì´ì € ì„¤ì •

    # ğŸ”¹ ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •
    if CFG.scheduler == "cosine":
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG.epochs)
    elif CFG.scheduler == "step":
        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)
    else:
        scheduler = None
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì¢…ë¥˜ì— ë”°ë¼ í•™ìŠµë¥  ì¡°ì ˆ ë°©ì‹ ì„¤ì •

    # ğŸ”¹ í•™ìŠµ ë£¨í”„
    best_acc = 0.0
    history = []
    # ìµœê³  ì •í™•ë„ ì €ì¥ìš© ë³€ìˆ˜ì™€ ë¡œê·¸ ì €ì¥ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”

    for epoch in range(CFG.epochs): # ì „ì²´ epoch ë§Œí¼ ë°˜ë³µ
        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, epoch)
        val_acc = validate(model, val_loader)
        # 1 epoch í•™ìŠµí•˜ê³  ê²€ì¦ ì •í™•ë„ ê³„ì‚°

        print(f"ğŸ“Œ Epoch {epoch+1}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}")
        # epoch ë‹¹ ê²°ê³¼ ì¶œë ¥

        # ğŸ”¹ ëª¨ë¸ ì €ì¥
        if val_acc > best_acc:
            best_acc = val_acc
            save_path = os.path.join(CFG.save_dir, CFG.model_save_name)
            torch.save(model.state_dict(), save_path)
            print(f"âœ… Best model saved to: {save_path}")
            # ì´ì „ë³´ë‹¤ ì„±ëŠ¥ ì¢‹ìœ¼ë©´ ëª¨ë¸ ì €ì¥

        # ğŸ”¹ ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸ (ì—í­ ëë‚  ë•Œ)
        if scheduler is not None:
            scheduler.step()
            # ìŠ¤ì¼€ì¤„ëŸ¬ ì ìš©

        history.append({
            "epoch": epoch + 1,
            "train_acc": train_acc,
            "val_acc": val_acc,
            "train_loss": train_loss,
        })  # ë¡œê·¸ ê¸°ë¡ ì €ì¥

    # ğŸ”¹ ë¡œê·¸ ì €ì¥
    df = pd.DataFrame(history)
    df["timestamp"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    df.to_csv("logs/train_log1.csv", index=False)
    # ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥

    print("ğŸ“ logs/train_log1.csv ì €ì¥ ì™„ë£Œ")
    print("ğŸ‰ í•™ìŠµ ì¢…ë£Œ")
    # ì™„ë£Œ ë©”ì‹œì§€ ì¶œë ¥

    
if __name__ == "__main__":
    main()
# ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ main() í˜¸ì¶œ